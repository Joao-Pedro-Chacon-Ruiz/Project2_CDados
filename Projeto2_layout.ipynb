{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nome: Breno Marti**\n",
    "\n",
    "**Nome: João Pedro Chacon Ruiz**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Serão permitidos grupos de três pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisarão fazer um questionário de avaliação de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Classificador automático de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando o ambiente no jupyter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "#Instalando o tweepy\n",
    "!pip install tweepy\n",
    "!pip install emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Autenticando no  Twitter\n",
    "\n",
    "* Conta: ***[Preencha aqui o id da sua conta. Ex: @fulano ]***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#Dados de autenticação do twitter:\\n\\n#Coloque aqui o identificador da conta no twitter: @fulano\\n\\n#leitura do arquivo no formato JSON\\nwith open('auth.pass') as fp:    \\n    data = json.load(fp)\\n\\n#Configurando a biblioteca. Não modificar\\nauth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\\nauth.set_access_token(data['access_token'], data['access_token_secret'])\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#Dados de autenticação do twitter:\n",
    "\n",
    "#Coloque aqui o identificador da conta no twitter: @fulano\n",
    "\n",
    "#leitura do arquivo no formato JSON\n",
    "with open('auth.pass') as fp:    \n",
    "    data = json.load(fp)\n",
    "\n",
    "#Configurando a biblioteca. Não modificar\n",
    "auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "auth.set_access_token(data['access_token'], data['access_token_secret'])\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Etapas do projeto:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escolha de um produto e coleta das mensagens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Produto escolhido:\n",
    "produto = 'Bugatti'\n",
    "\n",
    "#Quantidade mínima de mensagens capturadas:\n",
    "n = 500\n",
    "#Quantidade mínima de mensagens para a base de treinamento:\n",
    "t = 300\n",
    "\n",
    "#Filtro de língua, escolha uma na tabela ISO 639-1.\n",
    "lang = 'pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturando os dados do twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#Cria um objeto para a captura\\napi = tweepy.API(auth)\\n\\n#Inicia a captura, para mais detalhes: ver a documentação do tweepy\\ni = 1\\nmsgs = []\\nfor msg in tweepy.Cursor(api.search, q=produto, lang=lang, tweet_mode=\"extended\").items():\\n    if (not msg.retweeted) and (\\'RT\\' not in msg.full_text):\\n        msgs.append(msg.full_text.lower())\\n        i += 1\\n    if i > n:\\n        break\\n\\n#Embaralhando as mensagens para reduzir um possível viés\\nshuffle(msgs\\'\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#Cria um objeto para a captura\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "#Inicia a captura, para mais detalhes: ver a documentação do tweepy\n",
    "i = 1\n",
    "msgs = []\n",
    "for msg in tweepy.Cursor(api.search, q=produto, lang=lang, tweet_mode=\"extended\").items():\n",
    "    if (not msg.retweeted) and ('RT' not in msg.full_text):\n",
    "        msgs.append(msg.full_text.lower())\n",
    "        i += 1\n",
    "    if i > n:\n",
    "        break\n",
    "\n",
    "#Embaralhando as mensagens para reduzir um possível viés\n",
    "shuffle(msgs'\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando os dados em uma planilha Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#Verifica se o arquivo não existe para não substituir um conjunto pronto\\nif not os.path.isfile('./{0}.xlsx'.format(produto)):\\n    \\n    #Abre o arquivo para escrita\\n    writer = pd.ExcelWriter('{0}.xlsx'.format(produto))\\n\\n    #divide o conjunto de mensagens em duas planilhas\\n    dft = pd.DataFrame({'Treinamento' : pd.Series(msgs[:t])})\\n    dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\\n\\n    dfc = pd.DataFrame({'Teste' : pd.Series(msgs[t:])})\\n    dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\\n\\n    #fecha o arquivo\\n    writer.save()\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#Verifica se o arquivo não existe para não substituir um conjunto pronto\n",
    "if not os.path.isfile('./{0}.xlsx'.format(produto)):\n",
    "    \n",
    "    #Abre o arquivo para escrita\n",
    "    writer = pd.ExcelWriter('{0}.xlsx'.format(produto))\n",
    "\n",
    "    #divide o conjunto de mensagens em duas planilhas\n",
    "    dft = pd.DataFrame({'Treinamento' : pd.Series(msgs[:t])})\n",
    "    dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "\n",
    "    dfc = pd.DataFrame({'Teste' : pd.Series(msgs[t:])})\n",
    "    dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\n",
    "\n",
    "    #fecha o arquivo\n",
    "    writer.save()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Classificando as mensagens na coragem\n",
    "\n",
    "Esta etapa é manual. Faça a mesma pelo Excel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando o Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = pd.read_excel('Bugatti_treino.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevante_treino_raw = raw[raw['Relevância'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nao_relevante_treino_raw = raw[raw[\"Relevância\"] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funções de limpeza de texto:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "def cleanup(text):\n",
    "    \"\"\"\n",
    "        Função de limpeza muito simples que troca alguns sinais básicos por espaços\n",
    "    \"\"\"\n",
    "    punctuation = '[#@,!\\()-.€\":?;]' # Note que os sinais [] são delimitadores de um conjunto.\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, ' ', text)\n",
    "    return text_subbed   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_emojis(text):\n",
    "    clean = emojis.decode(text)\n",
    "    return clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Limpando e transformando os dataframes em séries para a análise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = ['\\n','https','//t','co/']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = []\n",
    "for tweet in relevante_treino_raw['Treinamento']:\n",
    "    texto = transform_emojis(tweet)\n",
    "    list1.append(cleanup(texto))\n",
    "    \n",
    "relevante_treino = pd.Series(list1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nota do professor: explicar como o código abaixo funciona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     mds cade a koenigsegg pra bater esses 500km/h ...\n",
       "1     bugatti bate recorde de velocidade com um carr...\n",
       "2     depois de bater o próprio recorde de 490 km/h ...\n",
       "3     podem não ser os mais bonitos  mas os carros d...\n",
       "4     parece que teremos o bugatti chiron super spor...\n",
       "5     bugatti descobriu o quão rápido o chiron é  fl...\n",
       "6     bugatti chiron com velocidade final de 490 km/...\n",
       "7      quase 500 kph em um carro  absurdo    cahutq6joi\n",
       "8     tô pesquisando uns carros luxuosos aqui e perc...\n",
       "9     após 490 km/h do chiron  bugatti anuncia que n...\n",
       "10    bugatti chiron super sport 300   versão  civil...\n",
       "11    bugatti ultrapassa a marca dos 480 km/h – e de...\n",
       "12    bugatti quebra o recorde de velocidade com um ...\n",
       "13    bugatti chiron chega a 490 km/h e bate recorde...\n",
       "14    carro mais rápido do mundo  nova bugatti terá ...\n",
       "15    williamenb outra coisa  porque aquele bugatti ...\n",
       "16    wow  a bugatti chiron chegou a 490 km/h    iss...\n",
       "17    bugatti chiron  levemente modificada  chegou a...\n",
       "18    bugatti chiron super sport 300  chega a 440 km...\n",
       "19    williamenb agora tá ficando divertido essa bri...\n",
       "20    bugatti chiron super sport 300  chega a 440 km...\n",
       "21    veja como o bugatti chiron quase bateu a barre...\n",
       "22    bugatti chiron chega aos 490 48 km/h e quebra ...\n",
       "23    mano    490 km/h    chegou um momento que eu a...\n",
       "24    um carro  de rua  que atingiu 490 48 km/h    p...\n",
       "25    williamenb mas será que esses 483 km/h não são...\n",
       "26       e o bugatti chiron que chegou a 490 km/h   o o\n",
       "27    eu to incrédulo que a bugatti conseguiu chegar...\n",
       "28    a bugatti alterou um chiron para bater os 490 ...\n",
       "29    o piloto de testes da bugatti  andy wallace  a...\n",
       "                            ...                        \n",
       "44    assista ao bugatti chiron esmagar a mítica bar...\n",
       "45    o bugatti chiron sport acabou de bater o recor...\n",
       "46    fg_genuino  pauloramos1 o carro mais caro do m...\n",
       "47     o novo bugatti chiron bateu só 490 km/h está bom\n",
       "48    não da nem pra acreditar que o bugatti chiron ...\n",
       "49    segundou com recordes   red_car o bugatti chir...\n",
       "50    acabei de descobrir q uma bugatti conseguiu ch...\n",
       "51    menino christian tomando coro da bugatti mais ...\n",
       "52    pqq a bugatti não fabrica avião logo  a porra ...\n",
       "53    parabéns a bugatti por fazer 490 48km/h cm o c...\n",
       "54    curiosidades  você sabia que bugatti chiron é ...\n",
       "55    bugatti bateu novamente o recorde de velocidad...\n",
       "56    recordista mundial de velocidade em versão “ci...\n",
       "57    bugatti falando que a velocidade do protótipo ...\n",
       "58    williamenb esse bugatti é alguma versão especi...\n",
       "59    bugatti chiron alcança 490 km/h e bate recorde...\n",
       "60             a bugatti sabe fazer carro  vai se fuder\n",
       "61    como assim a bugatti chegou aos 490km/h com o ...\n",
       "62    sadeiji mano koenigsegg q é feio mano  bugatti...\n",
       "63    a bugatti anunciou q n vai mais quebrar o reco...\n",
       "64    bem    a bugatti bateu novamente o recorde de ...\n",
       "65    bugatti chiron chega a 490 km/h e bate recorde...\n",
       "66    bugatti bateu o record de velocidade     490km...\n",
       "67    alguém precisa demitir o designer seja lá nome...\n",
       "68    bugatti chiron super sport 300  chega a 440 km...\n",
       "69    a quase 500 km/h  bugatti chiron vira o carro ...\n",
       "70    recorde mundial para bugatti   um veículo de p...\n",
       "71    williamenb sei que sou fan boy da bugatti  mas...\n",
       "72    me pergunto que tipo de pneu usaram no chiron ...\n",
       "73    o bugatti chiron é de novo o carro mais rápido...\n",
       "Length: 74, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevante_treino = relevante_treino.str.replace('|'.join(l),'',regex=True).str.strip()\n",
    "relevante_treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "list2 = []\n",
    "for tweet in nao_relevante_treino_raw['Treinamento']:\n",
    "    texto = transform_emojis(tweet)\n",
    "    list2.append(cleanup(texto))\n",
    "    \n",
    "nao_relevante_treino = pd.Series(list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      talla 42 eu  bugatti 3 11382e 11  botas clasic...\n",
       "1      talla 40 eu  bugatti 3 11384e 11  botas clasic...\n",
       "2      carolinaazered2  junior__bugatti com o bumbum ...\n",
       "3                fuga de bugatti com ela depois das três\n",
       "4      bugatti verón supersport motor triturbo 8 0 l ...\n",
       "5      el nuevo récord de velocidad del bugatti chiro...\n",
       "6      se continuar esse calor vai todo mundo derrete...\n",
       "7                                 lleobertodo menino bom\n",
       "8      gente vamos jogar stop  não vale olhar na inte...\n",
       "9      aberto até de madrugada  bugatti chiron chega ...\n",
       "10     gente vamos jogar stop  não vale olhar na inte...\n",
       "11     luaracaastro desse jeito  daqui a pouco volta ...\n",
       "12                    jenniferbraaga uma delicinha kkkkk\n",
       "13                              paloma_souza18 foi ontem\n",
       "14     ballerichh claro q  lembro alugamos um  bugatt...\n",
       "15     mas eu conseguiria trazer um suco gástrico esp...\n",
       "16              ofereçam me um bugatti  não peço mais xd\n",
       "17     iamthebrunao tomara q não  acho bugatti mais foda\n",
       "18          ir ou não ir no bugatti sexta  eis a questão\n",
       "19        quero foder num bugatti e um dia vai acontecer\n",
       "20     gente vamos jogar stop  não vale olhar na inte...\n",
       "21     talla 43 eu  bugatti 3 11384e 11  botas clasic...\n",
       "22           karist0n pq seu apelido tinha q ser bugatti\n",
       "23     talla 43 eu  bugatti 3 11384e 11  botas clasic...\n",
       "24            fhbugatti carai bugatti ce ja jogou inside\n",
       "25     paloma_souza18  ribeirohthais  igorrealequatro...\n",
       "26     luaracaastro enquanto isso vou bebendo minha c...\n",
       "27     use a primeira letra do seu nome e responda  n...\n",
       "28     ahhh  também tem 2 sons nossos que tão beirand...\n",
       "29     manoooos eu quero um gtr também portanto podem...\n",
       "                             ...                        \n",
       "196    bbrendabreu quem usa isso não sabe nem oq é bi...\n",
       "197                       yuri_bugatti vc e exceção more\n",
       "198    opatata22 só acho que você está muito sóbria f...\n",
       "199             yuri_bugatti  arrasou kkkkk   11hlk7jwm6\n",
       "200    gente vamos jogar stop  não vale olhar na inte...\n",
       "201    nome  brunalugar  barbebida  bacardicomida  ba...\n",
       "202    fredsilvered se bugatti fosse boa se chamaria ...\n",
       "203    a gente tenta né  joy  cold_sweat  car  arte  ...\n",
       "204                               aguiiarr_ kkkkkk pleno\n",
       "205      preciozoroberta decepção  facepalm 🏽‍ male_sign\n",
       "206                 junior__bugatti kkkkkkkkkkk sem mais\n",
       "207    nome  beatrizlugar  brasil bebida  balalaikaco...\n",
       "208    vai na festa dia 13  — mas isso é certo       ...\n",
       "209          queria estar dirigindo o bugatti q eu gosto\n",
       "210    ferrari 812gts  bugatti  ferrari  porsche  car...\n",
       "211    pqp bugatti conseguiu quebrar o recorde de vel...\n",
       "212    gente vamos jogar stop  não vale olhar na inte...\n",
       "213    yuri_bugatti olocooo logo ele que não batia em...\n",
       "214    a amiga me falou um bglh hj e a vontade foi de...\n",
       "215    fuga de bugatti com ela depois das 3  ela me p...\n",
       "216    crl2m  alanalves899  alvesmaary82 qual é o teu...\n",
       "217    dr_diogorocha_ o bugatti não tem hipótese cont...\n",
       "218    davidakabadao gostas de meter a 7 ª mudança é ...\n",
       "219    primeira vitória de um monegasco na itália des...\n",
       "220    já peguei ônibus lotado  agora eu quero bugatt...\n",
       "221                                  bom dia é o caralho\n",
       "222                        vai ser de enjoar das bugatti\n",
       "223    quer dá um role a 490 km/h      hfizt7txki bug...\n",
       "224    ponteiro da bugatti estourou esse final de semana\n",
       "225    kotabrunoag só mesmo  tocar “mocita”  “pintin”...\n",
       "Length: 226, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nao_relevante_treino = nao_relevante_treino.str.replace('|'.join(l),'',regex=True).str.strip()\n",
    "nao_relevante_treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "list3 = []\n",
    "for tweet in raw['Treinamento']:\n",
    "    texto = transform_emojis(tweet)\n",
    "    list3.append(cleanup(texto))\n",
    "    \n",
    "tudo = pd.Series(list3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      talla 42 eu  bugatti 3 11382e 11  botas clasic...\n",
       "1      talla 40 eu  bugatti 3 11384e 11  botas clasic...\n",
       "2      carolinaazered2  junior__bugatti com o bumbum ...\n",
       "3      mds cade a koenigsegg pra bater esses 500km/h ...\n",
       "4      bugatti bate recorde de velocidade com um carr...\n",
       "5                fuga de bugatti com ela depois das três\n",
       "6      bugatti verón supersport motor triturbo 8 0 l ...\n",
       "7      el nuevo récord de velocidad del bugatti chiro...\n",
       "8      se continuar esse calor vai todo mundo derrete...\n",
       "9      depois de bater o próprio recorde de 490 km/h ...\n",
       "10                                lleobertodo menino bom\n",
       "11     gente vamos jogar stop  não vale olhar na inte...\n",
       "12     podem não ser os mais bonitos  mas os carros d...\n",
       "13     aberto até de madrugada  bugatti chiron chega ...\n",
       "14     gente vamos jogar stop  não vale olhar na inte...\n",
       "15     luaracaastro desse jeito  daqui a pouco volta ...\n",
       "16                    jenniferbraaga uma delicinha kkkkk\n",
       "17                              paloma_souza18 foi ontem\n",
       "18     parece que teremos o bugatti chiron super spor...\n",
       "19     ballerichh claro q  lembro alugamos um  bugatt...\n",
       "20     mas eu conseguiria trazer um suco gástrico esp...\n",
       "21              ofereçam me um bugatti  não peço mais xd\n",
       "22     iamthebrunao tomara q não  acho bugatti mais foda\n",
       "23          ir ou não ir no bugatti sexta  eis a questão\n",
       "24        quero foder num bugatti e um dia vai acontecer\n",
       "25     bugatti descobriu o quão rápido o chiron é  fl...\n",
       "26     gente vamos jogar stop  não vale olhar na inte...\n",
       "27     talla 43 eu  bugatti 3 11384e 11  botas clasic...\n",
       "28           karist0n pq seu apelido tinha q ser bugatti\n",
       "29     bugatti chiron com velocidade final de 490 km/...\n",
       "                             ...                        \n",
       "270    vai na festa dia 13  — mas isso é certo       ...\n",
       "271    sadeiji mano koenigsegg q é feio mano  bugatti...\n",
       "272    a bugatti anunciou q n vai mais quebrar o reco...\n",
       "273          queria estar dirigindo o bugatti q eu gosto\n",
       "274    bem    a bugatti bateu novamente o recorde de ...\n",
       "275    ferrari 812gts  bugatti  ferrari  porsche  car...\n",
       "276    pqp bugatti conseguiu quebrar o recorde de vel...\n",
       "277    bugatti chiron chega a 490 km/h e bate recorde...\n",
       "278    gente vamos jogar stop  não vale olhar na inte...\n",
       "279    yuri_bugatti olocooo logo ele que não batia em...\n",
       "280    a amiga me falou um bglh hj e a vontade foi de...\n",
       "281    fuga de bugatti com ela depois das 3  ela me p...\n",
       "282    crl2m  alanalves899  alvesmaary82 qual é o teu...\n",
       "283    dr_diogorocha_ o bugatti não tem hipótese cont...\n",
       "284    bugatti bateu o record de velocidade     490km...\n",
       "285    alguém precisa demitir o designer seja lá nome...\n",
       "286    bugatti chiron super sport 300  chega a 440 km...\n",
       "287    a quase 500 km/h  bugatti chiron vira o carro ...\n",
       "288    recorde mundial para bugatti   um veículo de p...\n",
       "289    davidakabadao gostas de meter a 7 ª mudança é ...\n",
       "290    primeira vitória de um monegasco na itália des...\n",
       "291    já peguei ônibus lotado  agora eu quero bugatt...\n",
       "292                                  bom dia é o caralho\n",
       "293    williamenb sei que sou fan boy da bugatti  mas...\n",
       "294                        vai ser de enjoar das bugatti\n",
       "295    me pergunto que tipo de pneu usaram no chiron ...\n",
       "296    quer dá um role a 490 km/h      hfizt7txki bug...\n",
       "297    ponteiro da bugatti estourou esse final de semana\n",
       "298    kotabrunoag só mesmo  tocar “mocita”  “pintin”...\n",
       "299    o bugatti chiron é de novo o carro mais rápido...\n",
       "Length: 300, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tudo = tudo.str.replace('|'.join(l),'',regex=True).str.strip()\n",
    "tudo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contando o número de aparições de cada palavra :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bugatti         223\n",
       "de              128\n",
       "a               124\n",
       "o               119\n",
       "que              75\n",
       "um               74\n",
       "e                69\n",
       "do               67\n",
       "chiron           65\n",
       "não              62\n",
       "na               55\n",
       "carro            46\n",
       "km/h             46\n",
       "nome             40\n",
       "490              40\n",
       "eu               39\n",
       "é                39\n",
       "com              37\n",
       "em               35\n",
       "primeira         33\n",
       "mais             33\n",
       "seu              30\n",
       "gente            26\n",
       "letra            26\n",
       "para             26\n",
       "por              25\n",
       "velocidade       24\n",
       "da               24\n",
       "recorde          23\n",
       "bananaobjeto     23\n",
       "               ... \n",
       "parado            1\n",
       "montadora         1\n",
       "cv0ohmpumh        1\n",
       "vbxefpqkkh        1\n",
       "more              1\n",
       "velocity          1\n",
       "sugado            1\n",
       "duda_bri          1\n",
       "percebi           1\n",
       "pet               1\n",
       "enjoar            1\n",
       "conselho          1\n",
       "grupo             1\n",
       "diáriomotor       1\n",
       "euros             1\n",
       "browniecarro      1\n",
       "vira              1\n",
       "mrohdwwf4w        1\n",
       "existiam          1\n",
       "prontos           1\n",
       "barca             1\n",
       "olocooo           1\n",
       "acordando         1\n",
       "process           1\n",
       "hq5l2ra3jj        1\n",
       "velhos            1\n",
       "trabalho          1\n",
       "ruicouto7311      1\n",
       "🏾‍                1\n",
       "yagnvcmbnh        1\n",
       "Length: 1676, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list4 = []\n",
    "for tweet in tudo:\n",
    "    list4 = list4 + tweet.split()\n",
    "\n",
    "universo = pd.Series(list4)\n",
    "universo.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bugatti           76\n",
       "o                 55\n",
       "a                 53\n",
       "de                52\n",
       "chiron            45\n",
       "km/h              38\n",
       "que               31\n",
       "490               31\n",
       "carro             27\n",
       "um                26\n",
       "do                23\n",
       "em                22\n",
       "velocidade        20\n",
       "mais              20\n",
       "recorde           19\n",
       "e                 17\n",
       "é                 15\n",
       "com               15\n",
       "não               14\n",
       "da                13\n",
       "300               11\n",
       "mph               10\n",
       "sport             10\n",
       "os                 9\n",
       "super              8\n",
       "chega              8\n",
       "mundial            8\n",
       "para               7\n",
       "por                7\n",
       "eu                 7\n",
       "                  ..\n",
       "pergunto           1\n",
       "coro               1\n",
       "alguém             1\n",
       "conhecidos         1\n",
       "título             1\n",
       "percam             1\n",
       "h6skmuy1ow         1\n",
       "demitir            1\n",
       "cv0ohmpumh         1\n",
       "bonitos            1\n",
       "ntipvegqfw         1\n",
       "esmagar            1\n",
       "absurdamente       1\n",
       "primeira           1\n",
       "estrondosos        1\n",
       "está               1\n",
       "lamborghiniaté     1\n",
       "pauloramos1        1\n",
       "homologado         1\n",
       "porsche            1\n",
       "rocket             1\n",
       "helicóptero        1\n",
       "falando            1\n",
       "têm                1\n",
       "sou                1\n",
       "conceito           1\n",
       "d6jjf0unes         1\n",
       "às                 1\n",
       "lbwtnqyh07         1\n",
       "wow                1\n",
       "Length: 522, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list5 = []\n",
    "for tweet in relevante_treino:\n",
    "    list5 = list5 + tweet.split()\n",
    "\n",
    "palavras_relevantes = pd.Series(list5)\n",
    "palavras_relevantes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bugatti         147\n",
       "de               76\n",
       "a                71\n",
       "o                64\n",
       "e                52\n",
       "na               49\n",
       "não              48\n",
       "um               48\n",
       "do               44\n",
       "que              44\n",
       "nome             39\n",
       "primeira         32\n",
       "eu               32\n",
       "seu              29\n",
       "letra            26\n",
       "gente            25\n",
       "é                24\n",
       "bananaobjeto     23\n",
       "vamos            22\n",
       "vale             22\n",
       "jogar            22\n",
       "com              22\n",
       "olhar            22\n",
       "respondanome     21\n",
       "stop             21\n",
       "brancofruta      21\n",
       "bugatticor       20\n",
       "chiron           20\n",
       "para             19\n",
       "carro            19\n",
       "               ... \n",
       "amo               1\n",
       "pensar            1\n",
       "quatrocentos      1\n",
       "itupeva           1\n",
       "mateca            1\n",
       "fxnqayanji        1\n",
       "bolsa             1\n",
       "escolham          1\n",
       "scglfo0s1p        1\n",
       "quebrando         1\n",
       "adesivado         1\n",
       "fefuybnt3l        1\n",
       "aberto            1\n",
       "flagrado          1\n",
       "colocar           1\n",
       "tubarão           1\n",
       "siiiiim           1\n",
       "produto           1\n",
       "thecrew2…         1\n",
       "407               1\n",
       "aparecer          1\n",
       "pzzminujgo        1\n",
       "b                 1\n",
       "mantendo          1\n",
       "big               1\n",
       "palestra          1\n",
       "feliz             1\n",
       "semáforo          1\n",
       "le                1\n",
       "3tzw5cfyey        1\n",
       "Length: 1341, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list6 = []\n",
    "for tweet in nao_relevante_treino:\n",
    "    list6 = list6 + tweet.split()\n",
    "\n",
    "palavras_nao_relevantes = pd.Series(list6)\n",
    "palavras_nao_relevantes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frequência relativa de cada palavra:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bugatti         0.044511\n",
       "de              0.025549\n",
       "a               0.024750\n",
       "o               0.023752\n",
       "que             0.014970\n",
       "um              0.014770\n",
       "e               0.013772\n",
       "do              0.013373\n",
       "chiron          0.012974\n",
       "não             0.012375\n",
       "na              0.010978\n",
       "carro           0.009182\n",
       "km/h            0.009182\n",
       "nome            0.007984\n",
       "490             0.007984\n",
       "eu              0.007784\n",
       "é               0.007784\n",
       "com             0.007385\n",
       "em              0.006986\n",
       "primeira        0.006587\n",
       "mais            0.006587\n",
       "seu             0.005988\n",
       "gente           0.005190\n",
       "letra           0.005190\n",
       "para            0.005190\n",
       "por             0.004990\n",
       "velocidade      0.004790\n",
       "da              0.004790\n",
       "recorde         0.004591\n",
       "bananaobjeto    0.004591\n",
       "                  ...   \n",
       "parado          0.000200\n",
       "montadora       0.000200\n",
       "cv0ohmpumh      0.000200\n",
       "vbxefpqkkh      0.000200\n",
       "more            0.000200\n",
       "velocity        0.000200\n",
       "sugado          0.000200\n",
       "duda_bri        0.000200\n",
       "percebi         0.000200\n",
       "pet             0.000200\n",
       "enjoar          0.000200\n",
       "conselho        0.000200\n",
       "grupo           0.000200\n",
       "diáriomotor     0.000200\n",
       "euros           0.000200\n",
       "browniecarro    0.000200\n",
       "vira            0.000200\n",
       "mrohdwwf4w      0.000200\n",
       "existiam        0.000200\n",
       "prontos         0.000200\n",
       "barca           0.000200\n",
       "olocooo         0.000200\n",
       "acordando       0.000200\n",
       "process         0.000200\n",
       "hq5l2ra3jj      0.000200\n",
       "velhos          0.000200\n",
       "trabalho        0.000200\n",
       "ruicouto7311    0.000200\n",
       "🏾‍              0.000200\n",
       "yagnvcmbnh      0.000200\n",
       "Length: 1676, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "universo.value_counts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bugatti           0.051213\n",
       "o                 0.037062\n",
       "a                 0.035714\n",
       "de                0.035040\n",
       "chiron            0.030323\n",
       "km/h              0.025606\n",
       "que               0.020889\n",
       "490               0.020889\n",
       "carro             0.018194\n",
       "um                0.017520\n",
       "do                0.015499\n",
       "em                0.014825\n",
       "velocidade        0.013477\n",
       "mais              0.013477\n",
       "recorde           0.012803\n",
       "e                 0.011456\n",
       "é                 0.010108\n",
       "com               0.010108\n",
       "não               0.009434\n",
       "da                0.008760\n",
       "300               0.007412\n",
       "mph               0.006739\n",
       "sport             0.006739\n",
       "os                0.006065\n",
       "super             0.005391\n",
       "chega             0.005391\n",
       "mundial           0.005391\n",
       "para              0.004717\n",
       "por               0.004717\n",
       "eu                0.004717\n",
       "                    ...   \n",
       "pergunto          0.000674\n",
       "coro              0.000674\n",
       "alguém            0.000674\n",
       "conhecidos        0.000674\n",
       "título            0.000674\n",
       "percam            0.000674\n",
       "h6skmuy1ow        0.000674\n",
       "demitir           0.000674\n",
       "cv0ohmpumh        0.000674\n",
       "bonitos           0.000674\n",
       "ntipvegqfw        0.000674\n",
       "esmagar           0.000674\n",
       "absurdamente      0.000674\n",
       "primeira          0.000674\n",
       "estrondosos       0.000674\n",
       "está              0.000674\n",
       "lamborghiniaté    0.000674\n",
       "pauloramos1       0.000674\n",
       "homologado        0.000674\n",
       "porsche           0.000674\n",
       "rocket            0.000674\n",
       "helicóptero       0.000674\n",
       "falando           0.000674\n",
       "têm               0.000674\n",
       "sou               0.000674\n",
       "conceito          0.000674\n",
       "d6jjf0unes        0.000674\n",
       "às                0.000674\n",
       "lbwtnqyh07        0.000674\n",
       "wow               0.000674\n",
       "Length: 522, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palavras_relevantes.value_counts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bugatti         0.041690\n",
       "de              0.021554\n",
       "a               0.020136\n",
       "o               0.018151\n",
       "e               0.014748\n",
       "na              0.013897\n",
       "não             0.013613\n",
       "um              0.013613\n",
       "do              0.012479\n",
       "que             0.012479\n",
       "nome            0.011061\n",
       "primeira        0.009075\n",
       "eu              0.009075\n",
       "seu             0.008225\n",
       "letra           0.007374\n",
       "gente           0.007090\n",
       "é               0.006807\n",
       "bananaobjeto    0.006523\n",
       "vamos           0.006239\n",
       "vale            0.006239\n",
       "jogar           0.006239\n",
       "com             0.006239\n",
       "olhar           0.006239\n",
       "respondanome    0.005956\n",
       "stop            0.005956\n",
       "brancofruta     0.005956\n",
       "bugatticor      0.005672\n",
       "chiron          0.005672\n",
       "para            0.005389\n",
       "carro           0.005389\n",
       "                  ...   \n",
       "amo             0.000284\n",
       "pensar          0.000284\n",
       "quatrocentos    0.000284\n",
       "itupeva         0.000284\n",
       "mateca          0.000284\n",
       "fxnqayanji      0.000284\n",
       "bolsa           0.000284\n",
       "escolham        0.000284\n",
       "scglfo0s1p      0.000284\n",
       "quebrando       0.000284\n",
       "adesivado       0.000284\n",
       "fefuybnt3l      0.000284\n",
       "aberto          0.000284\n",
       "flagrado        0.000284\n",
       "colocar         0.000284\n",
       "tubarão         0.000284\n",
       "siiiiim         0.000284\n",
       "produto         0.000284\n",
       "thecrew2…       0.000284\n",
       "407             0.000284\n",
       "aparecer        0.000284\n",
       "pzzminujgo      0.000284\n",
       "b               0.000284\n",
       "mantendo        0.000284\n",
       "big             0.000284\n",
       "palestra        0.000284\n",
       "feliz           0.000284\n",
       "semáforo        0.000284\n",
       "le              0.000284\n",
       "3tzw5cfyey      0.000284\n",
       "Length: 1341, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palavras_nao_relevantes.value_counts(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2962075848303393"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_relevante = palavras_relevantes.size/universo.size\n",
    "P_relevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7037924151696606"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_nao_relevante = palavras_nao_relevantes.size/universo.size\n",
    "P_nao_relevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw2 = pd.read_excel('Bugatti_teste.xlsx')\n",
    "relevante_teste_raw2 = raw2[raw2['Relevância'] == 1]\n",
    "nao_relevante_teste_raw2 = raw2[raw2[\"Relevância\"] == 0]\n",
    "\n",
    "lista1 = []\n",
    "for tweet in relevante_teste_raw2['Teste']:\n",
    "    texto = transform_emojis(tweet)\n",
    "    lista1.append(cleanup(texto))\n",
    "    \n",
    "relevante_teste = pd.Series(lista1)\n",
    "relevante_teste = relevante_teste.str.replace('|'.join(l),'',regex=True).str.strip()\n",
    "\n",
    "lista2 = []\n",
    "for tweet in nao_relevante_teste_raw2['Teste']:\n",
    "    texto = transform_emojis(tweet)\n",
    "    lista2.append(cleanup(texto))\n",
    "    \n",
    "nao_relevante_teste = pd.Series(lista2)\n",
    "nao_relevante_teste = nao_relevante_teste.str.replace('|'.join(l),'',regex=True).str.strip()\n",
    "\n",
    "lista3 = []\n",
    "for tweet in raw2['Teste']:\n",
    "    texto = transform_emojis(tweet)\n",
    "    lista3.append(cleanup(texto))\n",
    "    \n",
    "testudo = pd.Series(lista3)\n",
    "testudo = testudo.str.replace('|'.join(l),'',regex=True).str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lista4 = []\n",
    "for tweet in testudo:\n",
    "    lista4 = lista4 + tweet.split()\n",
    "\n",
    "universo_teste = pd.Series(lista4)\n",
    "universo_teste.value_counts()\n",
    "\n",
    "lista5 = []\n",
    "for tweet in relevante_teste:\n",
    "    lista5 = lista5 + tweet.split()\n",
    "\n",
    "palavras_relevantes_teste = pd.Series(lista5)\n",
    "P_R_T_R = palavras_relevantes_teste.value_counts(True)\n",
    "\n",
    "lista6 = []\n",
    "for tweet in nao_relevante_teste:\n",
    "    lista6 = lista6 + tweet.split()\n",
    "\n",
    "palavras_nao_relevantes_teste = pd.Series(lista6)\n",
    "P_N_R_T_R = palavras_nao_relevantes_teste.value_counts(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Montando o Classificardor Naive Bayes\n",
    "\n",
    "#### Probabilidades de ser relevante ou não relevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3416"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palavras_teste = palavras_relevantes_teste.size + palavras_nao_relevantes_teste.size\n",
    "palavras_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4028103044496487"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pt_relevante = palavras_relevantes_teste.size / palavras_teste\n",
    "Pt_relevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5971896955503513"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ptn_relevante = palavras_nao_relevantes_teste.size / palavras_teste\n",
    "Ptn_relevante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Como o classificador funcionará:\n",
    "\n",
    "Todos os tweets presentes na planilha de testes serão, individualmente, analisados pelo classificador e catalogados, em um loop. Depois de todo esse processo, os resultados de cada tweet analisado, que podem ser ou \"Relevante\" ou \"Irrelevante\", pelo menos neste primeiro momento, serão adicionados a uma lista com o fim de serem comparados com a análise feita à mão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bayes(relevancia,serie1,serie2):\n",
    "    #Criando o loop para o cálculo da probabilidade de ser relevante:\n",
    "\n",
    "    lista_resultados_numericos = []\n",
    "\n",
    "    #selecionando o tweet\n",
    "    for tweets in testudo:\n",
    "    \n",
    "        #Quebra o tweet em uma lista de palavras\n",
    "        tweet = tweets.split()\n",
    "    \n",
    "        # Calculando a probabilidade deste tweet ser relevante dado as suas palavras\n",
    "        log_probabilidade = 0\n",
    "        for palavra in tweet:\n",
    "        \n",
    "            #Não deixa que palavras não pertencentes à série bugem o código\n",
    "            if palavra not in serie1:\n",
    "                log_probabilidade += math.log(1/3416)\n",
    "            else:\n",
    "                log_probabilidade += math.log(serie2[palavra] + 1/3416)\n",
    "        \n",
    "        #Guardando os resultados e resetando a variável probabilidade    \n",
    "        lista_resultados_numericos.append(log_probabilidade + math.log(relevancia))\n",
    "\n",
    "    return lista_resultados_numericos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_resultados_numericos_relevantes = Bayes(Pt_relevante, palavras_relevantes_teste, P_R_T_R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_resultados_numericos_nrelevantes = Bayes(Ptn_relevante, palavras_nao_relevantes_teste, P_N_R_T_R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante',\n",
       " 'Não relevante']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=0\n",
    "lista_resultados = []\n",
    "for tweet in testudo:\n",
    "    \n",
    "    if lista_resultados_numericos_relevantes[i] > lista_resultados_numericos_nrelevantes[i]:\n",
    "           lista_resultados.append(\"Relevante\")\n",
    "            \n",
    "    if lista_resultados_numericos_relevantes[i] == lista_resultados_numericos_nrelevantes[i]:\n",
    "        lista_resultados.append(\"Neutro\")\n",
    "        \n",
    "    if lista_resultados_numericos_relevantes[i] < lista_resultados_numericos_nrelevantes[i]:\n",
    "        lista_resultados.append(\"Não relevante\")\n",
    "        \n",
    "    i += 1\n",
    "    \n",
    "lista_resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aperfeiçoamento:\n",
    "\n",
    "Os trabalhos vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separação de espaços entre palavras e emojis ou emojis e emojis\n",
    "* Propor outras limpezas e transformações que não afetem a qualidade da informação ou classificação\n",
    "* Criar categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que não posso usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cenários para Naïve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que periodicamente realiza análise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
