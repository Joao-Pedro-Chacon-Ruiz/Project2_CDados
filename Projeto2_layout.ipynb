{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nome: Breno Marti**\n",
    "\n",
    "**Nome: João Pedro Chacon Ruiz**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Serão permitidos grupos de três pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisarão fazer um questionário de avaliação de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Classificador automático de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando o ambiente no jupyter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "#Instalando o tweepy\n",
    "!pip install tweepy\n",
    "!pip install emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Autenticando no  Twitter\n",
    "\n",
    "* Conta: ***[Preencha aqui o id da sua conta. Ex: @fulano ]***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'auth.pass'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-1b0f116798ac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#leitura do arquivo no formato JSON\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'auth.pass'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'auth.pass'"
     ]
    }
   ],
   "source": [
    "#Dados de autenticação do twitter:\n",
    "\n",
    "#Coloque aqui o identificador da conta no twitter: @fulano\n",
    "\n",
    "#leitura do arquivo no formato JSON\n",
    "with open('auth.pass') as fp:    \n",
    "    data = json.load(fp)\n",
    "\n",
    "#Configurando a biblioteca. Não modificar\n",
    "auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "auth.set_access_token(data['access_token'], data['access_token_secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Etapas do projeto:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escolha de um produto e coleta das mensagens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Produto escolhido:\n",
    "produto = 'Bugatti'\n",
    "\n",
    "#Quantidade mínima de mensagens capturadas:\n",
    "n = 500\n",
    "#Quantidade mínima de mensagens para a base de treinamento:\n",
    "t = 300\n",
    "\n",
    "#Filtro de língua, escolha uma na tabela ISO 639-1.\n",
    "lang = 'pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturando os dados do twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "#Cria um objeto para a captura\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "#Inicia a captura, para mais detalhes: ver a documentação do tweepy\n",
    "i = 1\n",
    "msgs = []\n",
    "for msg in tweepy.Cursor(api.search, q=produto, lang=lang, tweet_mode=\"extended\").items():\n",
    "    if (not msg.retweeted) and ('RT' not in msg.full_text):\n",
    "        msgs.append(msg.full_text.lower())\n",
    "        i += 1\n",
    "    if i > n:\n",
    "        break\n",
    "\n",
    "#Embaralhando as mensagens para reduzir um possível viés\n",
    "shuffle(msgs'\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando os dados em uma planilha Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "#Verifica se o arquivo não existe para não substituir um conjunto pronto\n",
    "if not os.path.isfile('./{0}.xlsx'.format(produto)):\n",
    "    \n",
    "    #Abre o arquivo para escrita\n",
    "    writer = pd.ExcelWriter('{0}.xlsx'.format(produto))\n",
    "\n",
    "    #divide o conjunto de mensagens em duas planilhas\n",
    "    dft = pd.DataFrame({'Treinamento' : pd.Series(msgs[:t])})\n",
    "    dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "\n",
    "    dfc = pd.DataFrame({'Teste' : pd.Series(msgs[t:])})\n",
    "    dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\n",
    "\n",
    "    #fecha o arquivo\n",
    "    writer.save()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Classificando as mensagens na coragem\n",
    "\n",
    "Esta etapa é manual. Faça a mesma pelo Excel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando o Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = pd.read_excel('Bugatti_treino.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevante_treino_raw = raw[raw['Relevância'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nao_relevante_treino_raw = raw[raw[\"Relevância\"] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funções de limpeza de texto:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "def cleanup(text):\n",
    "    \"\"\"\n",
    "        Função de limpeza muito simples que troca alguns sinais básicos por espaços\n",
    "    \"\"\"\n",
    "    punctuation = '[#@,!\\()-.€\":?;]' # Note que os sinais [] são delimitadores de um conjunto.\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, ' ', text)\n",
    "    return text_subbed   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_emojis(text):\n",
    "    clean = emojis.decode(text)\n",
    "    return clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Limpando e transformando os dataframes em séries para a análise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = ['\\n','https','//t','co/']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = []\n",
    "for tweet in relevante_treino_raw['Treinamento']:\n",
    "    texto = transform_emojis(tweet)\n",
    "    list1.append(cleanup(texto))\n",
    "    \n",
    "relevante_treino = pd.Series(list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     mds cade a koenigsegg pra bater esses 500km/h ...\n",
       "1     bugatti bate recorde de velocidade com um carr...\n",
       "2     depois de bater o próprio recorde de 490 km/h ...\n",
       "3     podem não ser os mais bonitos  mas os carros d...\n",
       "4     parece que teremos o bugatti chiron super spor...\n",
       "5     bugatti descobriu o quão rápido o chiron é  fl...\n",
       "6     bugatti chiron com velocidade final de 490 km/...\n",
       "7      quase 500 kph em um carro  absurdo    cahutq6joi\n",
       "8     tô pesquisando uns carros luxuosos aqui e perc...\n",
       "9     após 490 km/h do chiron  bugatti anuncia que n...\n",
       "10    bugatti chiron super sport 300   versão  civil...\n",
       "11    bugatti ultrapassa a marca dos 480 km/h – e de...\n",
       "12    bugatti quebra o recorde de velocidade com um ...\n",
       "13    bugatti chiron chega a 490 km/h e bate recorde...\n",
       "14    carro mais rápido do mundo  nova bugatti terá ...\n",
       "15    williamenb outra coisa  porque aquele bugatti ...\n",
       "16    wow  a bugatti chiron chegou a 490 km/h    iss...\n",
       "17    bugatti chiron  levemente modificada  chegou a...\n",
       "18    bugatti chiron super sport 300  chega a 440 km...\n",
       "19    williamenb agora tá ficando divertido essa bri...\n",
       "20    bugatti chiron super sport 300  chega a 440 km...\n",
       "21    veja como o bugatti chiron quase bateu a barre...\n",
       "22    bugatti chiron chega aos 490 48 km/h e quebra ...\n",
       "23    mano    490 km/h    chegou um momento que eu a...\n",
       "24    um carro  de rua  que atingiu 490 48 km/h    p...\n",
       "25    williamenb mas será que esses 483 km/h não são...\n",
       "26       e o bugatti chiron que chegou a 490 km/h   o o\n",
       "27    eu to incrédulo que a bugatti conseguiu chegar...\n",
       "28    a bugatti alterou um chiron para bater os 490 ...\n",
       "29    o piloto de testes da bugatti  andy wallace  a...\n",
       "                            ...                        \n",
       "44    assista ao bugatti chiron esmagar a mítica bar...\n",
       "45    o bugatti chiron sport acabou de bater o recor...\n",
       "46    fg_genuino  pauloramos1 o carro mais caro do m...\n",
       "47     o novo bugatti chiron bateu só 490 km/h está bom\n",
       "48    não da nem pra acreditar que o bugatti chiron ...\n",
       "49    segundou com recordes   red_car o bugatti chir...\n",
       "50    acabei de descobrir q uma bugatti conseguiu ch...\n",
       "51    menino christian tomando coro da bugatti mais ...\n",
       "52    pqq a bugatti não fabrica avião logo  a porra ...\n",
       "53    parabéns a bugatti por fazer 490 48km/h cm o c...\n",
       "54    curiosidades  você sabia que bugatti chiron é ...\n",
       "55    bugatti bateu novamente o recorde de velocidad...\n",
       "56    recordista mundial de velocidade em versão “ci...\n",
       "57    bugatti falando que a velocidade do protótipo ...\n",
       "58    williamenb esse bugatti é alguma versão especi...\n",
       "59    bugatti chiron alcança 490 km/h e bate recorde...\n",
       "60             a bugatti sabe fazer carro  vai se fuder\n",
       "61    como assim a bugatti chegou aos 490km/h com o ...\n",
       "62    sadeiji mano koenigsegg q é feio mano  bugatti...\n",
       "63    a bugatti anunciou q n vai mais quebrar o reco...\n",
       "64    bem    a bugatti bateu novamente o recorde de ...\n",
       "65    bugatti chiron chega a 490 km/h e bate recorde...\n",
       "66    bugatti bateu o record de velocidade     490km...\n",
       "67    alguém precisa demitir o designer seja lá nome...\n",
       "68    bugatti chiron super sport 300  chega a 440 km...\n",
       "69    a quase 500 km/h  bugatti chiron vira o carro ...\n",
       "70    recorde mundial para bugatti   um veículo de p...\n",
       "71    williamenb sei que sou fan boy da bugatti  mas...\n",
       "72    me pergunto que tipo de pneu usaram no chiron ...\n",
       "73    o bugatti chiron é de novo o carro mais rápido...\n",
       "Length: 74, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevante_treino = relevante_treino.str.replace('|'.join(l),'',regex=True).str.strip()\n",
    "relevante_treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "list2 = []\n",
    "for tweet in nao_relevante_treino_raw['Treinamento']:\n",
    "    texto = transform_emojis(tweet)\n",
    "    list2.append(cleanup(texto))\n",
    "    \n",
    "nao_relevante_treino = pd.Series(list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      talla 42 eu  bugatti 3 11382e 11  botas clasic...\n",
       "1      talla 40 eu  bugatti 3 11384e 11  botas clasic...\n",
       "2      carolinaazered2  junior__bugatti com o bumbum ...\n",
       "3                fuga de bugatti com ela depois das três\n",
       "4      bugatti verón supersport motor triturbo 8 0 l ...\n",
       "5      el nuevo récord de velocidad del bugatti chiro...\n",
       "6      se continuar esse calor vai todo mundo derrete...\n",
       "7                                 lleobertodo menino bom\n",
       "8      gente vamos jogar stop  não vale olhar na inte...\n",
       "9      aberto até de madrugada  bugatti chiron chega ...\n",
       "10     gente vamos jogar stop  não vale olhar na inte...\n",
       "11     luaracaastro desse jeito  daqui a pouco volta ...\n",
       "12                    jenniferbraaga uma delicinha kkkkk\n",
       "13                              paloma_souza18 foi ontem\n",
       "14     ballerichh claro q  lembro alugamos um  bugatt...\n",
       "15     mas eu conseguiria trazer um suco gástrico esp...\n",
       "16              ofereçam me um bugatti  não peço mais xd\n",
       "17     iamthebrunao tomara q não  acho bugatti mais foda\n",
       "18          ir ou não ir no bugatti sexta  eis a questão\n",
       "19        quero foder num bugatti e um dia vai acontecer\n",
       "20     gente vamos jogar stop  não vale olhar na inte...\n",
       "21     talla 43 eu  bugatti 3 11384e 11  botas clasic...\n",
       "22           karist0n pq seu apelido tinha q ser bugatti\n",
       "23     talla 43 eu  bugatti 3 11384e 11  botas clasic...\n",
       "24            fhbugatti carai bugatti ce ja jogou inside\n",
       "25     paloma_souza18  ribeirohthais  igorrealequatro...\n",
       "26     luaracaastro enquanto isso vou bebendo minha c...\n",
       "27     use a primeira letra do seu nome e responda  n...\n",
       "28     ahhh  também tem 2 sons nossos que tão beirand...\n",
       "29     manoooos eu quero um gtr também portanto podem...\n",
       "                             ...                        \n",
       "196    bbrendabreu quem usa isso não sabe nem oq é bi...\n",
       "197                       yuri_bugatti vc e exceção more\n",
       "198    opatata22 só acho que você está muito sóbria f...\n",
       "199             yuri_bugatti  arrasou kkkkk   11hlk7jwm6\n",
       "200    gente vamos jogar stop  não vale olhar na inte...\n",
       "201    nome  brunalugar  barbebida  bacardicomida  ba...\n",
       "202    fredsilvered se bugatti fosse boa se chamaria ...\n",
       "203    a gente tenta né  joy  cold_sweat  car  arte  ...\n",
       "204                               aguiiarr_ kkkkkk pleno\n",
       "205      preciozoroberta decepção  facepalm 🏽‍ male_sign\n",
       "206                 junior__bugatti kkkkkkkkkkk sem mais\n",
       "207    nome  beatrizlugar  brasil bebida  balalaikaco...\n",
       "208    vai na festa dia 13  — mas isso é certo       ...\n",
       "209          queria estar dirigindo o bugatti q eu gosto\n",
       "210    ferrari 812gts  bugatti  ferrari  porsche  car...\n",
       "211    pqp bugatti conseguiu quebrar o recorde de vel...\n",
       "212    gente vamos jogar stop  não vale olhar na inte...\n",
       "213    yuri_bugatti olocooo logo ele que não batia em...\n",
       "214    a amiga me falou um bglh hj e a vontade foi de...\n",
       "215    fuga de bugatti com ela depois das 3  ela me p...\n",
       "216    crl2m  alanalves899  alvesmaary82 qual é o teu...\n",
       "217    dr_diogorocha_ o bugatti não tem hipótese cont...\n",
       "218    davidakabadao gostas de meter a 7 ª mudança é ...\n",
       "219    primeira vitória de um monegasco na itália des...\n",
       "220    já peguei ônibus lotado  agora eu quero bugatt...\n",
       "221                                  bom dia é o caralho\n",
       "222                        vai ser de enjoar das bugatti\n",
       "223    quer dá um role a 490 km/h      hfizt7txki bug...\n",
       "224    ponteiro da bugatti estourou esse final de semana\n",
       "225    kotabrunoag só mesmo  tocar “mocita”  “pintin”...\n",
       "Length: 226, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nao_relevante_treino = nao_relevante_treino.str.replace('|'.join(l),'',regex=True).str.strip()\n",
    "nao_relevante_treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "list3 = []\n",
    "for tweet in raw['Treinamento']:\n",
    "    texto = transform_emojis(tweet)\n",
    "    list3.append(cleanup(texto))\n",
    "    \n",
    "tudo = pd.Series(list3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      talla 42 eu  bugatti 3 11382e 11  botas clasic...\n",
       "1      talla 40 eu  bugatti 3 11384e 11  botas clasic...\n",
       "2      carolinaazered2  junior__bugatti com o bumbum ...\n",
       "3      mds cade a koenigsegg pra bater esses 500km/h ...\n",
       "4      bugatti bate recorde de velocidade com um carr...\n",
       "5                fuga de bugatti com ela depois das três\n",
       "6      bugatti verón supersport motor triturbo 8 0 l ...\n",
       "7      el nuevo récord de velocidad del bugatti chiro...\n",
       "8      se continuar esse calor vai todo mundo derrete...\n",
       "9      depois de bater o próprio recorde de 490 km/h ...\n",
       "10                                lleobertodo menino bom\n",
       "11     gente vamos jogar stop  não vale olhar na inte...\n",
       "12     podem não ser os mais bonitos  mas os carros d...\n",
       "13     aberto até de madrugada  bugatti chiron chega ...\n",
       "14     gente vamos jogar stop  não vale olhar na inte...\n",
       "15     luaracaastro desse jeito  daqui a pouco volta ...\n",
       "16                    jenniferbraaga uma delicinha kkkkk\n",
       "17                              paloma_souza18 foi ontem\n",
       "18     parece que teremos o bugatti chiron super spor...\n",
       "19     ballerichh claro q  lembro alugamos um  bugatt...\n",
       "20     mas eu conseguiria trazer um suco gástrico esp...\n",
       "21              ofereçam me um bugatti  não peço mais xd\n",
       "22     iamthebrunao tomara q não  acho bugatti mais foda\n",
       "23          ir ou não ir no bugatti sexta  eis a questão\n",
       "24        quero foder num bugatti e um dia vai acontecer\n",
       "25     bugatti descobriu o quão rápido o chiron é  fl...\n",
       "26     gente vamos jogar stop  não vale olhar na inte...\n",
       "27     talla 43 eu  bugatti 3 11384e 11  botas clasic...\n",
       "28           karist0n pq seu apelido tinha q ser bugatti\n",
       "29     bugatti chiron com velocidade final de 490 km/...\n",
       "                             ...                        \n",
       "270    vai na festa dia 13  — mas isso é certo       ...\n",
       "271    sadeiji mano koenigsegg q é feio mano  bugatti...\n",
       "272    a bugatti anunciou q n vai mais quebrar o reco...\n",
       "273          queria estar dirigindo o bugatti q eu gosto\n",
       "274    bem    a bugatti bateu novamente o recorde de ...\n",
       "275    ferrari 812gts  bugatti  ferrari  porsche  car...\n",
       "276    pqp bugatti conseguiu quebrar o recorde de vel...\n",
       "277    bugatti chiron chega a 490 km/h e bate recorde...\n",
       "278    gente vamos jogar stop  não vale olhar na inte...\n",
       "279    yuri_bugatti olocooo logo ele que não batia em...\n",
       "280    a amiga me falou um bglh hj e a vontade foi de...\n",
       "281    fuga de bugatti com ela depois das 3  ela me p...\n",
       "282    crl2m  alanalves899  alvesmaary82 qual é o teu...\n",
       "283    dr_diogorocha_ o bugatti não tem hipótese cont...\n",
       "284    bugatti bateu o record de velocidade     490km...\n",
       "285    alguém precisa demitir o designer seja lá nome...\n",
       "286    bugatti chiron super sport 300  chega a 440 km...\n",
       "287    a quase 500 km/h  bugatti chiron vira o carro ...\n",
       "288    recorde mundial para bugatti   um veículo de p...\n",
       "289    davidakabadao gostas de meter a 7 ª mudança é ...\n",
       "290    primeira vitória de um monegasco na itália des...\n",
       "291    já peguei ônibus lotado  agora eu quero bugatt...\n",
       "292                                  bom dia é o caralho\n",
       "293    williamenb sei que sou fan boy da bugatti  mas...\n",
       "294                        vai ser de enjoar das bugatti\n",
       "295    me pergunto que tipo de pneu usaram no chiron ...\n",
       "296    quer dá um role a 490 km/h      hfizt7txki bug...\n",
       "297    ponteiro da bugatti estourou esse final de semana\n",
       "298    kotabrunoag só mesmo  tocar “mocita”  “pintin”...\n",
       "299    o bugatti chiron é de novo o carro mais rápido...\n",
       "Length: 300, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tudo = tudo.str.replace('|'.join(l),'',regex=True).str.strip()\n",
    "tudo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contando o número de aparições de cada palavra :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bugatti              223\n",
       "de                   128\n",
       "a                    124\n",
       "o                    119\n",
       "que                   75\n",
       "um                    74\n",
       "e                     69\n",
       "do                    67\n",
       "chiron                65\n",
       "não                   62\n",
       "na                    55\n",
       "km/h                  46\n",
       "carro                 46\n",
       "490                   40\n",
       "nome                  40\n",
       "é                     39\n",
       "eu                    39\n",
       "com                   37\n",
       "em                    35\n",
       "mais                  33\n",
       "primeira              33\n",
       "seu                   30\n",
       "para                  26\n",
       "gente                 26\n",
       "letra                 26\n",
       "por                   25\n",
       "velocidade            24\n",
       "da                    24\n",
       "recorde               23\n",
       "bananaobjeto          23\n",
       "                    ... \n",
       "lienhardracing         1\n",
       "muda                   1\n",
       "mercedesamgf1          1\n",
       "merecedores            1\n",
       "posto                  1\n",
       "alguns                 1\n",
       "rebola                 1\n",
       "acontecer              1\n",
       "20lngpzvmw             1\n",
       "deixam                 1\n",
       "oi                     1\n",
       "bacaco                 1\n",
       "lança                  1\n",
       "brumadinhobebida       1\n",
       "bacarraocarro          1\n",
       "lindo                  1\n",
       "setembro               1\n",
       "ribeirohthais          1\n",
       "'la                    1\n",
       "música                 1\n",
       "volvemos               1\n",
       "🏾‍                     1\n",
       "490km                  1\n",
       "atentos                1\n",
       "apelido                1\n",
       "sincero                1\n",
       "tava                   1\n",
       "bugatticentodieci      1\n",
       "esmagar                1\n",
       "camila                 1\n",
       "Length: 1676, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list4 = []\n",
    "for tweet in tudo:\n",
    "    list4 = list4 + tweet.split()\n",
    "\n",
    "universo = pd.Series(list4)\n",
    "universo.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bugatti         76\n",
       "o               55\n",
       "a               53\n",
       "de              52\n",
       "chiron          45\n",
       "km/h            38\n",
       "490             31\n",
       "que             31\n",
       "carro           27\n",
       "um              26\n",
       "do              23\n",
       "em              22\n",
       "velocidade      20\n",
       "mais            20\n",
       "recorde         19\n",
       "e               17\n",
       "é               15\n",
       "com             15\n",
       "não             14\n",
       "da              13\n",
       "300             11\n",
       "mph             10\n",
       "sport           10\n",
       "os               9\n",
       "mundial          8\n",
       "super            8\n",
       "chega            8\n",
       "rápido           7\n",
       "para             7\n",
       "500              7\n",
       "                ..\n",
       "vemos            1\n",
       "divertido        1\n",
       "título           1\n",
       "lq6gxsbowr       1\n",
       "90               1\n",
       "mi3wjnnzmw       1\n",
       "romper           1\n",
       "ndotvcxakt       1\n",
       "bohokz5lsp       1\n",
       "forzahorizon     1\n",
       "quatro           1\n",
       "ttytuaiadc       1\n",
       "cahutq6joi       1\n",
       "veyron           1\n",
       "maior            1\n",
       "svvh7ampgn       1\n",
       "teremos          1\n",
       "menos            1\n",
       "venha            1\n",
       "assista          1\n",
       "sacanagem        1\n",
       "simplesmente     1\n",
       "pqp              1\n",
       "aqui             1\n",
       "puro             1\n",
       "apenas           1\n",
       "pbjqzdpzz7       1\n",
       "andy             1\n",
       "era              1\n",
       "atingido         1\n",
       "Length: 522, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list5 = []\n",
    "for tweet in relevante_treino:\n",
    "    list5 = list5 + tweet.split()\n",
    "\n",
    "palavras_relevantes = pd.Series(list5)\n",
    "palavras_relevantes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bugatti                   147\n",
       "de                         76\n",
       "a                          71\n",
       "o                          64\n",
       "e                          52\n",
       "na                         49\n",
       "não                        48\n",
       "um                         48\n",
       "que                        44\n",
       "do                         44\n",
       "nome                       39\n",
       "primeira                   32\n",
       "eu                         32\n",
       "seu                        29\n",
       "letra                      26\n",
       "gente                      25\n",
       "é                          24\n",
       "bananaobjeto               23\n",
       "jogar                      22\n",
       "vale                       22\n",
       "com                        22\n",
       "vamos                      22\n",
       "olhar                      22\n",
       "stop                       21\n",
       "brancofruta                21\n",
       "respondanome               21\n",
       "bugatticor                 20\n",
       "chiron                     20\n",
       "carro                      19\n",
       "internet                   19\n",
       "                         ... \n",
       "saabmzj7us                  1\n",
       "deus                        1\n",
       "caralho                     1\n",
       "03%                         1\n",
       "“sim”                       1\n",
       "kkkkkkkk                    1\n",
       "barcelona/venezabebida      1\n",
       "bro                         1\n",
       "beatriz                     1\n",
       "kkkkkkkkkkkkkkkk            1\n",
       "itupeva                     1\n",
       "homenagem                   1\n",
       "potência                    1\n",
       "swxvmj60od                  1\n",
       "bagre                       1\n",
       "16                          1\n",
       "noooopsssss                 1\n",
       "essas                       1\n",
       "bailey’s                    1\n",
       "pen                         1\n",
       "desse                       1\n",
       "vxxvvh0zqr                  1\n",
       "the                         1\n",
       "amg                         1\n",
       "adorooo                     1\n",
       "recordista                  1\n",
       "57                          1\n",
       "preta                       1\n",
       "nrjlp0gaci                  1\n",
       "“pintin”                    1\n",
       "Length: 1341, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list6 = []\n",
    "for tweet in nao_relevante_treino:\n",
    "    list6 = list6 + tweet.split()\n",
    "\n",
    "palavras_nao_relevantes = pd.Series(list6)\n",
    "palavras_nao_relevantes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frequência relativa de cada palavra:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bugatti              0.044511\n",
       "de                   0.025549\n",
       "a                    0.024750\n",
       "o                    0.023752\n",
       "que                  0.014970\n",
       "um                   0.014770\n",
       "e                    0.013772\n",
       "do                   0.013373\n",
       "chiron               0.012974\n",
       "não                  0.012375\n",
       "na                   0.010978\n",
       "km/h                 0.009182\n",
       "carro                0.009182\n",
       "490                  0.007984\n",
       "nome                 0.007984\n",
       "é                    0.007784\n",
       "eu                   0.007784\n",
       "com                  0.007385\n",
       "em                   0.006986\n",
       "mais                 0.006587\n",
       "primeira             0.006587\n",
       "seu                  0.005988\n",
       "para                 0.005190\n",
       "gente                0.005190\n",
       "letra                0.005190\n",
       "por                  0.004990\n",
       "velocidade           0.004790\n",
       "da                   0.004790\n",
       "recorde              0.004591\n",
       "bananaobjeto         0.004591\n",
       "                       ...   \n",
       "lienhardracing       0.000200\n",
       "muda                 0.000200\n",
       "mercedesamgf1        0.000200\n",
       "merecedores          0.000200\n",
       "posto                0.000200\n",
       "alguns               0.000200\n",
       "rebola               0.000200\n",
       "acontecer            0.000200\n",
       "20lngpzvmw           0.000200\n",
       "deixam               0.000200\n",
       "oi                   0.000200\n",
       "bacaco               0.000200\n",
       "lança                0.000200\n",
       "brumadinhobebida     0.000200\n",
       "bacarraocarro        0.000200\n",
       "lindo                0.000200\n",
       "setembro             0.000200\n",
       "ribeirohthais        0.000200\n",
       "'la                  0.000200\n",
       "música               0.000200\n",
       "volvemos             0.000200\n",
       "🏾‍                   0.000200\n",
       "490km                0.000200\n",
       "atentos              0.000200\n",
       "apelido              0.000200\n",
       "sincero              0.000200\n",
       "tava                 0.000200\n",
       "bugatticentodieci    0.000200\n",
       "esmagar              0.000200\n",
       "camila               0.000200\n",
       "Length: 1676, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "universo.value_counts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bugatti         0.051213\n",
       "o               0.037062\n",
       "a               0.035714\n",
       "de              0.035040\n",
       "chiron          0.030323\n",
       "km/h            0.025606\n",
       "490             0.020889\n",
       "que             0.020889\n",
       "carro           0.018194\n",
       "um              0.017520\n",
       "do              0.015499\n",
       "em              0.014825\n",
       "velocidade      0.013477\n",
       "mais            0.013477\n",
       "recorde         0.012803\n",
       "e               0.011456\n",
       "é               0.010108\n",
       "com             0.010108\n",
       "não             0.009434\n",
       "da              0.008760\n",
       "300             0.007412\n",
       "mph             0.006739\n",
       "sport           0.006739\n",
       "os              0.006065\n",
       "mundial         0.005391\n",
       "super           0.005391\n",
       "chega           0.005391\n",
       "rápido          0.004717\n",
       "para            0.004717\n",
       "500             0.004717\n",
       "                  ...   \n",
       "vemos           0.000674\n",
       "divertido       0.000674\n",
       "título          0.000674\n",
       "lq6gxsbowr      0.000674\n",
       "90              0.000674\n",
       "mi3wjnnzmw      0.000674\n",
       "romper          0.000674\n",
       "ndotvcxakt      0.000674\n",
       "bohokz5lsp      0.000674\n",
       "forzahorizon    0.000674\n",
       "quatro          0.000674\n",
       "ttytuaiadc      0.000674\n",
       "cahutq6joi      0.000674\n",
       "veyron          0.000674\n",
       "maior           0.000674\n",
       "svvh7ampgn      0.000674\n",
       "teremos         0.000674\n",
       "menos           0.000674\n",
       "venha           0.000674\n",
       "assista         0.000674\n",
       "sacanagem       0.000674\n",
       "simplesmente    0.000674\n",
       "pqp             0.000674\n",
       "aqui            0.000674\n",
       "puro            0.000674\n",
       "apenas          0.000674\n",
       "pbjqzdpzz7      0.000674\n",
       "andy            0.000674\n",
       "era             0.000674\n",
       "atingido        0.000674\n",
       "Length: 522, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palavras_relevantes.value_counts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bugatti                   0.041690\n",
       "de                        0.021554\n",
       "a                         0.020136\n",
       "o                         0.018151\n",
       "e                         0.014748\n",
       "na                        0.013897\n",
       "não                       0.013613\n",
       "um                        0.013613\n",
       "que                       0.012479\n",
       "do                        0.012479\n",
       "nome                      0.011061\n",
       "primeira                  0.009075\n",
       "eu                        0.009075\n",
       "seu                       0.008225\n",
       "letra                     0.007374\n",
       "gente                     0.007090\n",
       "é                         0.006807\n",
       "bananaobjeto              0.006523\n",
       "jogar                     0.006239\n",
       "vale                      0.006239\n",
       "com                       0.006239\n",
       "vamos                     0.006239\n",
       "olhar                     0.006239\n",
       "stop                      0.005956\n",
       "brancofruta               0.005956\n",
       "respondanome              0.005956\n",
       "bugatticor                0.005672\n",
       "chiron                    0.005672\n",
       "carro                     0.005389\n",
       "internet                  0.005389\n",
       "                            ...   \n",
       "saabmzj7us                0.000284\n",
       "deus                      0.000284\n",
       "caralho                   0.000284\n",
       "03%                       0.000284\n",
       "“sim”                     0.000284\n",
       "kkkkkkkk                  0.000284\n",
       "barcelona/venezabebida    0.000284\n",
       "bro                       0.000284\n",
       "beatriz                   0.000284\n",
       "kkkkkkkkkkkkkkkk          0.000284\n",
       "itupeva                   0.000284\n",
       "homenagem                 0.000284\n",
       "potência                  0.000284\n",
       "swxvmj60od                0.000284\n",
       "bagre                     0.000284\n",
       "16                        0.000284\n",
       "noooopsssss               0.000284\n",
       "essas                     0.000284\n",
       "bailey’s                  0.000284\n",
       "pen                       0.000284\n",
       "desse                     0.000284\n",
       "vxxvvh0zqr                0.000284\n",
       "the                       0.000284\n",
       "amg                       0.000284\n",
       "adorooo                   0.000284\n",
       "recordista                0.000284\n",
       "57                        0.000284\n",
       "preta                     0.000284\n",
       "nrjlp0gaci                0.000284\n",
       "“pintin”                  0.000284\n",
       "Length: 1341, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palavras_nao_relevantes.value_counts(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2962075848303393"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_relevante = palavras_relevantes.size/universo.size\n",
    "P_relevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7037924151696606"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_nao_relevante = palavras_nao_relevantes.size/universo.size\n",
    "P_nao_relevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw2 = pd.read_excel('Bugatti_teste.xlsx')\n",
    "relevante_teste_raw2 = raw2[raw2['Relevância'] == 1]\n",
    "nao_relevante_teste_raw2 = raw2[raw2[\"Relevância\"] == 0]\n",
    "\n",
    "lista1 = []\n",
    "for tweet in relevante_teste_raw2['Teste']:\n",
    "    texto = transform_emojis(tweet)\n",
    "    lista1.append(cleanup(texto))\n",
    "    \n",
    "relevante_teste = pd.Series(lista1)\n",
    "relevante_teste = relevante_teste.str.replace('|'.join(l),'',regex=True).str.strip()\n",
    "\n",
    "lista2 = []\n",
    "for tweet in nao_relevante_teste_raw2['Teste']:\n",
    "    texto = transform_emojis(tweet)\n",
    "    lista2.append(cleanup(texto))\n",
    "    \n",
    "nao_relevante_teste = pd.Series(lista2)\n",
    "nao_relevante_teste = nao_relevante_teste.str.replace('|'.join(l),'',regex=True).str.strip()\n",
    "\n",
    "lista3 = []\n",
    "for tweet in raw2['Teste']:\n",
    "    texto = transform_emojis(tweet)\n",
    "    lista3.append(cleanup(texto))\n",
    "    \n",
    "testudo = pd.Series(lista3)\n",
    "testudo = testudo.str.replace('|'.join(l),'',regex=True).str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bugatti    60\n",
       "dtype: int64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista4 = []\n",
    "for tweet in testudo:\n",
    "    lista4 = lista4 + tweet.split()\n",
    "\n",
    "universo_teste = pd.Series(lista4)\n",
    "universo_teste.value_counts()\n",
    "\n",
    "lista5 = []\n",
    "for tweet in relevante_teste:\n",
    "    lista5 = lista5 + tweet.split()\n",
    "\n",
    "palavras_relevantes_teste = pd.Series(lista5)\n",
    "palavras_relevantes_teste.value_counts()\n",
    "\n",
    "lista6 = []\n",
    "for tweet in nao_relevante_teste:\n",
    "    lista6 = lista6 + tweet.split()\n",
    "\n",
    "palavras_nao_relevantes_teste = pd.Series(lista6)\n",
    "palavras_nao_relevantes_teste.value_counts().head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Montando o Classificardor Naive Bayes\n",
    "\n",
    "#### Probabilidades de ser relevante ou não relevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3416"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palavras_teste = palavras_relevantes_teste.size + palavras_nao_relevantes_teste.size\n",
    "palavras_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4028103044496487"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pt_relevante = palavras_relevantes_teste.size / palavras_teste\n",
    "Pt_relevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5971896955503513"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ptn_relevante = palavras_nao_relevantes_teste.size / palavras_teste\n",
    "Ptn_relevante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Como o classificador funcionará:\n",
    "\n",
    "Todos os tweets presentes na planilha de testes serão, individualmente, analisados pelo classificador e catalogados, em um loop. Depois de todo esse processo, os resultados de cada tweet analisado, que podem ser ou \"Relevânte\" ou \"Irrelevânte\", pelo menos neste primeiro momento, serão adicionados a uma lista com o fim de serem comparados com a análise feita à mão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando o loop para o cálculo da probabilidade de ser relevante:\n",
    "\n",
    "probabilidade = 1\n",
    "lista_resultados_numericos_relevantes = []\n",
    "tweet = 0\n",
    "\n",
    "#selecionando o tweet\n",
    "for tweets in testudo:\n",
    "    \n",
    "    #Quebra o tweet em uma lista de palavras\n",
    "    tweet = tweets.split()\n",
    "    \n",
    "    # Calculando a probabilidade deste tweet ser relevante dado as suas palavras\n",
    "    for palavra in tweet:\n",
    "        \n",
    "        #Não deixa que palavras não pertencentes à série bugem o código\n",
    "        if palavra not in palavras_relevantes_teste:\n",
    "            probabilidade *= 1/3416\n",
    "        else:\n",
    "            probabilidade *= (palavras_relevantes_teste[palavra].value_counts(True) + 1/3416)\n",
    "        \n",
    "    #Guardando os resultados e resetando a variável probabilidade    \n",
    "    lista_resultados_numericos_relevantes.append(probabilidade * Pt_relevante)\n",
    "    probabilidade = 1\n",
    "    tweet = []\n",
    "\n",
    "#lista_resultados_numericos_relevantes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_resultados_numericos_nrelevantes = []\n",
    "tweet = 0\n",
    "probabilidade = 1\n",
    "\n",
    "for tweets in testudo:\n",
    "    \n",
    "    #Quebra o tweet em uma lista de palavras\n",
    "    tweet = tweets.split()\n",
    "    \n",
    "    # Calculando a probabilidade deste tweet não ser relevante dado as suas palavras\n",
    "    for palavra in tweet:\n",
    "        \n",
    "        #Não deixa que palavras não pertencentes à série bugem o código\n",
    "        if palavra not in palavras_nao_relevantes_teste:\n",
    "            probabilidade *= 1/3416\n",
    "        else:\n",
    "            probabilidade *= (palavras_nao_relevantes_teste[palavra].value_counts(True) + 1/3416)\n",
    "        \n",
    "    #Guardando os resultados e resetando a variável probabilidade    \n",
    "    lista_resultados_numericos_nrelevantes.append(probabilidade * Ptn_relevante)\n",
    "    probabilidade = 1\n",
    "\n",
    "#lista_resultados_numericos_nrelevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte',\n",
       " 'Não relevânte']"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=0\n",
    "lista_resultados = []\n",
    "for tweet in testudo:\n",
    "    \n",
    "    if lista_resultados_numericos_relevantes[i] > lista_resultados_numericos_nrelevantes[i]:\n",
    "           lista_resultados.append(\"Relevânte\")\n",
    "            \n",
    "    if lista_resultados_numericos_relevantes[i] == lista_resultados_numericos_nrelevantes[i]:\n",
    "        lista_resultados.append(\"Neutro\")\n",
    "        \n",
    "    if lista_resultados_numericos_relevantes[i] < lista_resultados_numericos_nrelevantes[i]:\n",
    "        lista_resultados.append(\"Não relevânte\")\n",
    "        \n",
    "    i += 1\n",
    "    \n",
    "lista_resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aperfeiçoamento:\n",
    "\n",
    "Os trabalhos vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separação de espaços entre palavras e emojis ou emojis e emojis\n",
    "* Propor outras limpezas e transformações que não afetem a qualidade da informação ou classificação\n",
    "* Criar categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que não posso usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cenários para Naïve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que periodicamente realiza análise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
