{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Ci√™ncia dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nome: Breno Marti**\n",
    "\n",
    "**Nome: Jo√£o Pedro Chacon Ruiz**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ser√£o permitidos grupos de tr√™s pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisar√£o fazer um question√°rio de avalia√ß√£o de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Classificador autom√°tico de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando o ambiente no jupyter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "#Instalando o tweepy\n",
    "!pip install tweepy\n",
    "!pip install emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Autenticando no  Twitter\n",
    "\n",
    "* Conta: ***[Preencha aqui o id da sua conta. Ex: @fulano ]***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'auth.pass'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-1b0f116798ac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#leitura do arquivo no formato JSON\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'auth.pass'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'auth.pass'"
     ]
    }
   ],
   "source": [
    "#Dados de autentica√ß√£o do twitter:\n",
    "\n",
    "#Coloque aqui o identificador da conta no twitter: @fulano\n",
    "\n",
    "#leitura do arquivo no formato JSON\n",
    "with open('auth.pass') as fp:    \n",
    "    data = json.load(fp)\n",
    "\n",
    "#Configurando a biblioteca. N√£o modificar\n",
    "auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "auth.set_access_token(data['access_token'], data['access_token_secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Etapas do projeto:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escolha de um produto e coleta das mensagens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Produto escolhido:\n",
    "produto = 'Bugatti'\n",
    "\n",
    "#Quantidade m√≠nima de mensagens capturadas:\n",
    "n = 500\n",
    "#Quantidade m√≠nima de mensagens para a base de treinamento:\n",
    "t = 300\n",
    "\n",
    "#Filtro de l√≠ngua, escolha uma na tabela ISO 639-1.\n",
    "lang = 'pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturando os dados do twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "#Cria um objeto para a captura\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "#Inicia a captura, para mais detalhes: ver a documenta√ß√£o do tweepy\n",
    "i = 1\n",
    "msgs = []\n",
    "for msg in tweepy.Cursor(api.search, q=produto, lang=lang, tweet_mode=\"extended\").items():\n",
    "    if (not msg.retweeted) and ('RT' not in msg.full_text):\n",
    "        msgs.append(msg.full_text.lower())\n",
    "        i += 1\n",
    "    if i > n:\n",
    "        break\n",
    "\n",
    "#Embaralhando as mensagens para reduzir um poss√≠vel vi√©s\n",
    "shuffle(msgs'\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando os dados em uma planilha Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "#Verifica se o arquivo n√£o existe para n√£o substituir um conjunto pronto\n",
    "if not os.path.isfile('./{0}.xlsx'.format(produto)):\n",
    "    \n",
    "    #Abre o arquivo para escrita\n",
    "    writer = pd.ExcelWriter('{0}.xlsx'.format(produto))\n",
    "\n",
    "    #divide o conjunto de mensagens em duas planilhas\n",
    "    dft = pd.DataFrame({'Treinamento' : pd.Series(msgs[:t])})\n",
    "    dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "\n",
    "    dfc = pd.DataFrame({'Teste' : pd.Series(msgs[t:])})\n",
    "    dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\n",
    "\n",
    "    #fecha o arquivo\n",
    "    writer.save()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Classificando as mensagens na coragem\n",
    "\n",
    "Esta etapa √© manual. Fa√ßa a mesma pelo Excel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando o Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = pd.read_excel('Bugatti_treino.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevante_treino_raw = raw[raw['Relev√¢ncia'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nao_relevante_treino_raw = raw[raw[\"Relev√¢ncia\"] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fun√ß√µes de limpeza de texto:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "def cleanup(text):\n",
    "    \"\"\"\n",
    "        Fun√ß√£o de limpeza muito simples que troca alguns sinais b√°sicos por espa√ßos\n",
    "    \"\"\"\n",
    "    punctuation = '[#@,!\\()-.‚Ç¨\":?;]' # Note que os sinais [] s√£o delimitadores de um conjunto.\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, ' ', text)\n",
    "    return text_subbed   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_emojis(text):\n",
    "    clean = emojis.decode(text)\n",
    "    return clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Limpando e transformando os dataframes em s√©ries para a an√°lise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = ['\\n','https','//t','co/']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = []\n",
    "for tweet in relevante_treino_raw['Treinamento']:\n",
    "    texto = transform_emojis(tweet)\n",
    "    list1.append(cleanup(texto))\n",
    "    \n",
    "relevante_treino = pd.Series(list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     mds cade a koenigsegg pra bater esses 500km/h ...\n",
       "1     bugatti bate recorde de velocidade com um carr...\n",
       "2     depois de bater o pr√≥prio recorde de 490 km/h ...\n",
       "3     podem n√£o ser os mais bonitos  mas os carros d...\n",
       "4     parece que teremos o bugatti chiron super spor...\n",
       "5     bugatti descobriu o qu√£o r√°pido o chiron √©  fl...\n",
       "6     bugatti chiron com velocidade final de 490 km/...\n",
       "7      quase 500 kph em um carro  absurdo    cahutq6joi\n",
       "8     t√¥ pesquisando uns carros luxuosos aqui e perc...\n",
       "9     ap√≥s 490 km/h do chiron  bugatti anuncia que n...\n",
       "10    bugatti chiron super sport 300   vers√£o  civil...\n",
       "11    bugatti ultrapassa a marca dos 480 km/h ‚Äì e de...\n",
       "12    bugatti quebra o recorde de velocidade com um ...\n",
       "13    bugatti chiron chega a 490 km/h e bate recorde...\n",
       "14    carro mais r√°pido do mundo  nova bugatti ter√° ...\n",
       "15    williamenb outra coisa  porque aquele bugatti ...\n",
       "16    wow  a bugatti chiron chegou a 490 km/h    iss...\n",
       "17    bugatti chiron  levemente modificada  chegou a...\n",
       "18    bugatti chiron super sport 300  chega a 440 km...\n",
       "19    williamenb agora t√° ficando divertido essa bri...\n",
       "20    bugatti chiron super sport 300  chega a 440 km...\n",
       "21    veja como o bugatti chiron quase bateu a barre...\n",
       "22    bugatti chiron chega aos 490 48 km/h e quebra ...\n",
       "23    mano    490 km/h    chegou um momento que eu a...\n",
       "24    um carro  de rua  que atingiu 490 48 km/h    p...\n",
       "25    williamenb mas ser√° que esses 483 km/h n√£o s√£o...\n",
       "26       e o bugatti chiron que chegou a 490 km/h   o o\n",
       "27    eu to incr√©dulo que a bugatti conseguiu chegar...\n",
       "28    a bugatti alterou um chiron para bater os 490 ...\n",
       "29    o piloto de testes da bugatti  andy wallace  a...\n",
       "                            ...                        \n",
       "44    assista ao bugatti chiron esmagar a m√≠tica bar...\n",
       "45    o bugatti chiron sport acabou de bater o recor...\n",
       "46    fg_genuino  pauloramos1 o carro mais caro do m...\n",
       "47     o novo bugatti chiron bateu s√≥ 490 km/h est√° bom\n",
       "48    n√£o da nem pra acreditar que o bugatti chiron ...\n",
       "49    segundou com recordes   red_car o bugatti chir...\n",
       "50    acabei de descobrir q uma bugatti conseguiu ch...\n",
       "51    menino christian tomando coro da bugatti mais ...\n",
       "52    pqq a bugatti n√£o fabrica avi√£o logo  a porra ...\n",
       "53    parab√©ns a bugatti por fazer 490 48km/h cm o c...\n",
       "54    curiosidades  voc√™ sabia que bugatti chiron √© ...\n",
       "55    bugatti bateu novamente o recorde de velocidad...\n",
       "56    recordista mundial de velocidade em vers√£o ‚Äúci...\n",
       "57    bugatti falando que a velocidade do prot√≥tipo ...\n",
       "58    williamenb esse bugatti √© alguma vers√£o especi...\n",
       "59    bugatti chiron alcan√ßa 490 km/h e bate recorde...\n",
       "60             a bugatti sabe fazer carro  vai se fuder\n",
       "61    como assim a bugatti chegou aos 490km/h com o ...\n",
       "62    sadeiji mano koenigsegg q √© feio mano  bugatti...\n",
       "63    a bugatti anunciou q n vai mais quebrar o reco...\n",
       "64    bem    a bugatti bateu novamente o recorde de ...\n",
       "65    bugatti chiron chega a 490 km/h e bate recorde...\n",
       "66    bugatti bateu o record de velocidade     490km...\n",
       "67    algu√©m precisa demitir o designer seja l√° nome...\n",
       "68    bugatti chiron super sport 300  chega a 440 km...\n",
       "69    a quase 500 km/h  bugatti chiron vira o carro ...\n",
       "70    recorde mundial para¬†bugatti¬†  um ve√≠culo de p...\n",
       "71    williamenb sei que sou fan boy da bugatti  mas...\n",
       "72    me pergunto que tipo de pneu usaram no chiron ...\n",
       "73    o bugatti chiron √© de novo o carro mais r√°pido...\n",
       "Length: 74, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevante_treino = relevante_treino.str.replace('|'.join(l),'',regex=True).str.strip()\n",
    "relevante_treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "list2 = []\n",
    "for tweet in nao_relevante_treino_raw['Treinamento']:\n",
    "    texto = transform_emojis(tweet)\n",
    "    list2.append(cleanup(texto))\n",
    "    \n",
    "nao_relevante_treino = pd.Series(list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      talla 42 eu  bugatti 3 11382e 11  botas clasic...\n",
       "1      talla 40 eu  bugatti 3 11384e 11  botas clasic...\n",
       "2      carolinaazered2  junior__bugatti com o bumbum ...\n",
       "3                fuga de bugatti com ela depois das tr√™s\n",
       "4      bugatti ver√≥n supersport motor triturbo 8 0 l ...\n",
       "5      el nuevo r√©cord de velocidad del bugatti chiro...\n",
       "6      se continuar esse calor vai todo mundo derrete...\n",
       "7                                 lleobertodo menino bom\n",
       "8      gente vamos jogar stop  n√£o vale olhar na inte...\n",
       "9      aberto at√© de madrugada  bugatti chiron chega ...\n",
       "10     gente vamos jogar stop  n√£o vale olhar na inte...\n",
       "11     luaracaastro desse jeito  daqui a pouco volta ...\n",
       "12                    jenniferbraaga uma delicinha kkkkk\n",
       "13                              paloma_souza18 foi ontem\n",
       "14     ballerichh claro q  lembro alugamos um  bugatt...\n",
       "15     mas eu conseguiria trazer um suco g√°strico esp...\n",
       "16              ofere√ßam me um bugatti  n√£o pe√ßo mais xd\n",
       "17     iamthebrunao tomara q n√£o  acho bugatti mais foda\n",
       "18          ir ou n√£o ir no bugatti sexta  eis a quest√£o\n",
       "19        quero foder num bugatti e um dia vai acontecer\n",
       "20     gente vamos jogar stop  n√£o vale olhar na inte...\n",
       "21     talla 43 eu  bugatti 3 11384e 11  botas clasic...\n",
       "22           karist0n pq seu apelido tinha q ser bugatti\n",
       "23     talla 43 eu  bugatti 3 11384e 11  botas clasic...\n",
       "24            fhbugatti carai bugatti ce ja jogou inside\n",
       "25     paloma_souza18  ribeirohthais  igorrealequatro...\n",
       "26     luaracaastro enquanto isso vou bebendo minha c...\n",
       "27     use a primeira letra do seu nome e responda  n...\n",
       "28     ahhh  tamb√©m tem 2 sons nossos que t√£o beirand...\n",
       "29     manoooos eu quero um gtr tamb√©m portanto podem...\n",
       "                             ...                        \n",
       "196    bbrendabreu quem usa isso n√£o sabe nem oq √© bi...\n",
       "197                       yuri_bugatti vc e exce√ß√£o more\n",
       "198    opatata22 s√≥ acho que voc√™ est√° muito s√≥bria f...\n",
       "199             yuri_bugatti  arrasou kkkkk   11hlk7jwm6\n",
       "200    gente vamos jogar stop  n√£o vale olhar na inte...\n",
       "201    nome  brunalugar  barbebida  bacardicomida  ba...\n",
       "202    fredsilvered se bugatti fosse boa se chamaria ...\n",
       "203    a gente tenta n√©  joy  cold_sweat  car  arte  ...\n",
       "204                               aguiiarr_ kkkkkk pleno\n",
       "205      preciozoroberta decep√ß√£o  facepalm üèΩ‚Äç male_sign\n",
       "206                 junior__bugatti kkkkkkkkkkk sem mais\n",
       "207    nome  beatrizlugar  brasil bebida  balalaikaco...\n",
       "208    vai na festa dia 13  ‚Äî mas isso √© certo       ...\n",
       "209          queria estar dirigindo o bugatti q eu gosto\n",
       "210    ferrari 812gts  bugatti  ferrari  porsche  car...\n",
       "211    pqp bugatti conseguiu quebrar o recorde de vel...\n",
       "212    gente vamos jogar stop  n√£o vale olhar na inte...\n",
       "213    yuri_bugatti olocooo logo ele que n√£o batia em...\n",
       "214    a amiga me falou um bglh hj e a vontade foi de...\n",
       "215    fuga de bugatti com ela depois das 3  ela me p...\n",
       "216    crl2m  alanalves899  alvesmaary82 qual √© o teu...\n",
       "217    dr_diogorocha_ o bugatti n√£o tem hip√≥tese cont...\n",
       "218    davidakabadao gostas de meter a 7 ¬™ mudan√ßa √© ...\n",
       "219    primeira vit√≥ria de um monegasco na it√°lia des...\n",
       "220    j√° peguei √¥nibus lotado  agora eu quero bugatt...\n",
       "221                                  bom dia √© o caralho\n",
       "222                        vai ser de enjoar das bugatti\n",
       "223    quer d√° um role a 490 km/h      hfizt7txki bug...\n",
       "224    ponteiro da bugatti estourou esse final de semana\n",
       "225    kotabrunoag s√≥ mesmo  tocar ‚Äúmocita‚Äù  ‚Äúpintin‚Äù...\n",
       "Length: 226, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nao_relevante_treino = nao_relevante_treino.str.replace('|'.join(l),'',regex=True).str.strip()\n",
    "nao_relevante_treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "list3 = []\n",
    "for tweet in raw['Treinamento']:\n",
    "    texto = transform_emojis(tweet)\n",
    "    list3.append(cleanup(texto))\n",
    "    \n",
    "tudo = pd.Series(list3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      talla 42 eu  bugatti 3 11382e 11  botas clasic...\n",
       "1      talla 40 eu  bugatti 3 11384e 11  botas clasic...\n",
       "2      carolinaazered2  junior__bugatti com o bumbum ...\n",
       "3      mds cade a koenigsegg pra bater esses 500km/h ...\n",
       "4      bugatti bate recorde de velocidade com um carr...\n",
       "5                fuga de bugatti com ela depois das tr√™s\n",
       "6      bugatti ver√≥n supersport motor triturbo 8 0 l ...\n",
       "7      el nuevo r√©cord de velocidad del bugatti chiro...\n",
       "8      se continuar esse calor vai todo mundo derrete...\n",
       "9      depois de bater o pr√≥prio recorde de 490 km/h ...\n",
       "10                                lleobertodo menino bom\n",
       "11     gente vamos jogar stop  n√£o vale olhar na inte...\n",
       "12     podem n√£o ser os mais bonitos  mas os carros d...\n",
       "13     aberto at√© de madrugada  bugatti chiron chega ...\n",
       "14     gente vamos jogar stop  n√£o vale olhar na inte...\n",
       "15     luaracaastro desse jeito  daqui a pouco volta ...\n",
       "16                    jenniferbraaga uma delicinha kkkkk\n",
       "17                              paloma_souza18 foi ontem\n",
       "18     parece que teremos o bugatti chiron super spor...\n",
       "19     ballerichh claro q  lembro alugamos um  bugatt...\n",
       "20     mas eu conseguiria trazer um suco g√°strico esp...\n",
       "21              ofere√ßam me um bugatti  n√£o pe√ßo mais xd\n",
       "22     iamthebrunao tomara q n√£o  acho bugatti mais foda\n",
       "23          ir ou n√£o ir no bugatti sexta  eis a quest√£o\n",
       "24        quero foder num bugatti e um dia vai acontecer\n",
       "25     bugatti descobriu o qu√£o r√°pido o chiron √©  fl...\n",
       "26     gente vamos jogar stop  n√£o vale olhar na inte...\n",
       "27     talla 43 eu  bugatti 3 11384e 11  botas clasic...\n",
       "28           karist0n pq seu apelido tinha q ser bugatti\n",
       "29     bugatti chiron com velocidade final de 490 km/...\n",
       "                             ...                        \n",
       "270    vai na festa dia 13  ‚Äî mas isso √© certo       ...\n",
       "271    sadeiji mano koenigsegg q √© feio mano  bugatti...\n",
       "272    a bugatti anunciou q n vai mais quebrar o reco...\n",
       "273          queria estar dirigindo o bugatti q eu gosto\n",
       "274    bem    a bugatti bateu novamente o recorde de ...\n",
       "275    ferrari 812gts  bugatti  ferrari  porsche  car...\n",
       "276    pqp bugatti conseguiu quebrar o recorde de vel...\n",
       "277    bugatti chiron chega a 490 km/h e bate recorde...\n",
       "278    gente vamos jogar stop  n√£o vale olhar na inte...\n",
       "279    yuri_bugatti olocooo logo ele que n√£o batia em...\n",
       "280    a amiga me falou um bglh hj e a vontade foi de...\n",
       "281    fuga de bugatti com ela depois das 3  ela me p...\n",
       "282    crl2m  alanalves899  alvesmaary82 qual √© o teu...\n",
       "283    dr_diogorocha_ o bugatti n√£o tem hip√≥tese cont...\n",
       "284    bugatti bateu o record de velocidade     490km...\n",
       "285    algu√©m precisa demitir o designer seja l√° nome...\n",
       "286    bugatti chiron super sport 300  chega a 440 km...\n",
       "287    a quase 500 km/h  bugatti chiron vira o carro ...\n",
       "288    recorde mundial para¬†bugatti¬†  um ve√≠culo de p...\n",
       "289    davidakabadao gostas de meter a 7 ¬™ mudan√ßa √© ...\n",
       "290    primeira vit√≥ria de um monegasco na it√°lia des...\n",
       "291    j√° peguei √¥nibus lotado  agora eu quero bugatt...\n",
       "292                                  bom dia √© o caralho\n",
       "293    williamenb sei que sou fan boy da bugatti  mas...\n",
       "294                        vai ser de enjoar das bugatti\n",
       "295    me pergunto que tipo de pneu usaram no chiron ...\n",
       "296    quer d√° um role a 490 km/h      hfizt7txki bug...\n",
       "297    ponteiro da bugatti estourou esse final de semana\n",
       "298    kotabrunoag s√≥ mesmo  tocar ‚Äúmocita‚Äù  ‚Äúpintin‚Äù...\n",
       "299    o bugatti chiron √© de novo o carro mais r√°pido...\n",
       "Length: 300, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tudo = tudo.str.replace('|'.join(l),'',regex=True).str.strip()\n",
    "tudo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contando o n√∫mero de apari√ß√µes de cada palavra :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bugatti              223\n",
       "de                   128\n",
       "a                    124\n",
       "o                    119\n",
       "que                   75\n",
       "um                    74\n",
       "e                     69\n",
       "do                    67\n",
       "chiron                65\n",
       "n√£o                   62\n",
       "na                    55\n",
       "km/h                  46\n",
       "carro                 46\n",
       "490                   40\n",
       "nome                  40\n",
       "√©                     39\n",
       "eu                    39\n",
       "com                   37\n",
       "em                    35\n",
       "mais                  33\n",
       "primeira              33\n",
       "seu                   30\n",
       "para                  26\n",
       "gente                 26\n",
       "letra                 26\n",
       "por                   25\n",
       "velocidade            24\n",
       "da                    24\n",
       "recorde               23\n",
       "bananaobjeto          23\n",
       "                    ... \n",
       "lienhardracing         1\n",
       "muda                   1\n",
       "mercedesamgf1          1\n",
       "merecedores            1\n",
       "posto                  1\n",
       "alguns                 1\n",
       "rebola                 1\n",
       "acontecer              1\n",
       "20lngpzvmw             1\n",
       "deixam                 1\n",
       "oi                     1\n",
       "bacaco                 1\n",
       "lan√ßa                  1\n",
       "brumadinhobebida       1\n",
       "bacarraocarro          1\n",
       "lindo                  1\n",
       "setembro               1\n",
       "ribeirohthais          1\n",
       "'la                    1\n",
       "m√∫sica                 1\n",
       "volvemos               1\n",
       "üèæ‚Äç                     1\n",
       "490km                  1\n",
       "atentos                1\n",
       "apelido                1\n",
       "sincero                1\n",
       "tava                   1\n",
       "bugatticentodieci      1\n",
       "esmagar                1\n",
       "camila                 1\n",
       "Length: 1676, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list4 = []\n",
    "for tweet in tudo:\n",
    "    list4 = list4 + tweet.split()\n",
    "\n",
    "universo = pd.Series(list4)\n",
    "universo.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bugatti         76\n",
       "o               55\n",
       "a               53\n",
       "de              52\n",
       "chiron          45\n",
       "km/h            38\n",
       "490             31\n",
       "que             31\n",
       "carro           27\n",
       "um              26\n",
       "do              23\n",
       "em              22\n",
       "velocidade      20\n",
       "mais            20\n",
       "recorde         19\n",
       "e               17\n",
       "√©               15\n",
       "com             15\n",
       "n√£o             14\n",
       "da              13\n",
       "300             11\n",
       "mph             10\n",
       "sport           10\n",
       "os               9\n",
       "mundial          8\n",
       "super            8\n",
       "chega            8\n",
       "r√°pido           7\n",
       "para             7\n",
       "500              7\n",
       "                ..\n",
       "vemos            1\n",
       "divertido        1\n",
       "t√≠tulo           1\n",
       "lq6gxsbowr       1\n",
       "90               1\n",
       "mi3wjnnzmw       1\n",
       "romper           1\n",
       "ndotvcxakt       1\n",
       "bohokz5lsp       1\n",
       "forzahorizon     1\n",
       "quatro           1\n",
       "ttytuaiadc       1\n",
       "cahutq6joi       1\n",
       "veyron           1\n",
       "maior            1\n",
       "svvh7ampgn       1\n",
       "teremos          1\n",
       "menos            1\n",
       "venha            1\n",
       "assista          1\n",
       "sacanagem        1\n",
       "simplesmente     1\n",
       "pqp              1\n",
       "aqui             1\n",
       "puro             1\n",
       "apenas           1\n",
       "pbjqzdpzz7       1\n",
       "andy             1\n",
       "era              1\n",
       "atingido         1\n",
       "Length: 522, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list5 = []\n",
    "for tweet in relevante_treino:\n",
    "    list5 = list5 + tweet.split()\n",
    "\n",
    "palavras_relevantes = pd.Series(list5)\n",
    "palavras_relevantes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bugatti                   147\n",
       "de                         76\n",
       "a                          71\n",
       "o                          64\n",
       "e                          52\n",
       "na                         49\n",
       "n√£o                        48\n",
       "um                         48\n",
       "que                        44\n",
       "do                         44\n",
       "nome                       39\n",
       "primeira                   32\n",
       "eu                         32\n",
       "seu                        29\n",
       "letra                      26\n",
       "gente                      25\n",
       "√©                          24\n",
       "bananaobjeto               23\n",
       "jogar                      22\n",
       "vale                       22\n",
       "com                        22\n",
       "vamos                      22\n",
       "olhar                      22\n",
       "stop                       21\n",
       "brancofruta                21\n",
       "respondanome               21\n",
       "bugatticor                 20\n",
       "chiron                     20\n",
       "carro                      19\n",
       "internet                   19\n",
       "                         ... \n",
       "saabmzj7us                  1\n",
       "deus                        1\n",
       "caralho                     1\n",
       "03%                         1\n",
       "‚Äúsim‚Äù                       1\n",
       "kkkkkkkk                    1\n",
       "barcelona/venezabebida      1\n",
       "bro                         1\n",
       "beatriz                     1\n",
       "kkkkkkkkkkkkkkkk            1\n",
       "itupeva                     1\n",
       "homenagem                   1\n",
       "pot√™ncia                    1\n",
       "swxvmj60od                  1\n",
       "bagre                       1\n",
       "16                          1\n",
       "noooopsssss                 1\n",
       "essas                       1\n",
       "bailey‚Äôs                    1\n",
       "pen                         1\n",
       "desse                       1\n",
       "vxxvvh0zqr                  1\n",
       "the                         1\n",
       "amg                         1\n",
       "adorooo                     1\n",
       "recordista                  1\n",
       "57                          1\n",
       "preta                       1\n",
       "nrjlp0gaci                  1\n",
       "‚Äúpintin‚Äù                    1\n",
       "Length: 1341, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list6 = []\n",
    "for tweet in nao_relevante_treino:\n",
    "    list6 = list6 + tweet.split()\n",
    "\n",
    "palavras_nao_relevantes = pd.Series(list6)\n",
    "palavras_nao_relevantes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frequ√™ncia relativa de cada palavra:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bugatti              0.044511\n",
       "de                   0.025549\n",
       "a                    0.024750\n",
       "o                    0.023752\n",
       "que                  0.014970\n",
       "um                   0.014770\n",
       "e                    0.013772\n",
       "do                   0.013373\n",
       "chiron               0.012974\n",
       "n√£o                  0.012375\n",
       "na                   0.010978\n",
       "km/h                 0.009182\n",
       "carro                0.009182\n",
       "490                  0.007984\n",
       "nome                 0.007984\n",
       "√©                    0.007784\n",
       "eu                   0.007784\n",
       "com                  0.007385\n",
       "em                   0.006986\n",
       "mais                 0.006587\n",
       "primeira             0.006587\n",
       "seu                  0.005988\n",
       "para                 0.005190\n",
       "gente                0.005190\n",
       "letra                0.005190\n",
       "por                  0.004990\n",
       "velocidade           0.004790\n",
       "da                   0.004790\n",
       "recorde              0.004591\n",
       "bananaobjeto         0.004591\n",
       "                       ...   \n",
       "lienhardracing       0.000200\n",
       "muda                 0.000200\n",
       "mercedesamgf1        0.000200\n",
       "merecedores          0.000200\n",
       "posto                0.000200\n",
       "alguns               0.000200\n",
       "rebola               0.000200\n",
       "acontecer            0.000200\n",
       "20lngpzvmw           0.000200\n",
       "deixam               0.000200\n",
       "oi                   0.000200\n",
       "bacaco               0.000200\n",
       "lan√ßa                0.000200\n",
       "brumadinhobebida     0.000200\n",
       "bacarraocarro        0.000200\n",
       "lindo                0.000200\n",
       "setembro             0.000200\n",
       "ribeirohthais        0.000200\n",
       "'la                  0.000200\n",
       "m√∫sica               0.000200\n",
       "volvemos             0.000200\n",
       "üèæ‚Äç                   0.000200\n",
       "490km                0.000200\n",
       "atentos              0.000200\n",
       "apelido              0.000200\n",
       "sincero              0.000200\n",
       "tava                 0.000200\n",
       "bugatticentodieci    0.000200\n",
       "esmagar              0.000200\n",
       "camila               0.000200\n",
       "Length: 1676, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "universo.value_counts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bugatti         0.051213\n",
       "o               0.037062\n",
       "a               0.035714\n",
       "de              0.035040\n",
       "chiron          0.030323\n",
       "km/h            0.025606\n",
       "490             0.020889\n",
       "que             0.020889\n",
       "carro           0.018194\n",
       "um              0.017520\n",
       "do              0.015499\n",
       "em              0.014825\n",
       "velocidade      0.013477\n",
       "mais            0.013477\n",
       "recorde         0.012803\n",
       "e               0.011456\n",
       "√©               0.010108\n",
       "com             0.010108\n",
       "n√£o             0.009434\n",
       "da              0.008760\n",
       "300             0.007412\n",
       "mph             0.006739\n",
       "sport           0.006739\n",
       "os              0.006065\n",
       "mundial         0.005391\n",
       "super           0.005391\n",
       "chega           0.005391\n",
       "r√°pido          0.004717\n",
       "para            0.004717\n",
       "500             0.004717\n",
       "                  ...   \n",
       "vemos           0.000674\n",
       "divertido       0.000674\n",
       "t√≠tulo          0.000674\n",
       "lq6gxsbowr      0.000674\n",
       "90              0.000674\n",
       "mi3wjnnzmw      0.000674\n",
       "romper          0.000674\n",
       "ndotvcxakt      0.000674\n",
       "bohokz5lsp      0.000674\n",
       "forzahorizon    0.000674\n",
       "quatro          0.000674\n",
       "ttytuaiadc      0.000674\n",
       "cahutq6joi      0.000674\n",
       "veyron          0.000674\n",
       "maior           0.000674\n",
       "svvh7ampgn      0.000674\n",
       "teremos         0.000674\n",
       "menos           0.000674\n",
       "venha           0.000674\n",
       "assista         0.000674\n",
       "sacanagem       0.000674\n",
       "simplesmente    0.000674\n",
       "pqp             0.000674\n",
       "aqui            0.000674\n",
       "puro            0.000674\n",
       "apenas          0.000674\n",
       "pbjqzdpzz7      0.000674\n",
       "andy            0.000674\n",
       "era             0.000674\n",
       "atingido        0.000674\n",
       "Length: 522, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palavras_relevantes.value_counts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bugatti                   0.041690\n",
       "de                        0.021554\n",
       "a                         0.020136\n",
       "o                         0.018151\n",
       "e                         0.014748\n",
       "na                        0.013897\n",
       "n√£o                       0.013613\n",
       "um                        0.013613\n",
       "que                       0.012479\n",
       "do                        0.012479\n",
       "nome                      0.011061\n",
       "primeira                  0.009075\n",
       "eu                        0.009075\n",
       "seu                       0.008225\n",
       "letra                     0.007374\n",
       "gente                     0.007090\n",
       "√©                         0.006807\n",
       "bananaobjeto              0.006523\n",
       "jogar                     0.006239\n",
       "vale                      0.006239\n",
       "com                       0.006239\n",
       "vamos                     0.006239\n",
       "olhar                     0.006239\n",
       "stop                      0.005956\n",
       "brancofruta               0.005956\n",
       "respondanome              0.005956\n",
       "bugatticor                0.005672\n",
       "chiron                    0.005672\n",
       "carro                     0.005389\n",
       "internet                  0.005389\n",
       "                            ...   \n",
       "saabmzj7us                0.000284\n",
       "deus                      0.000284\n",
       "caralho                   0.000284\n",
       "03%                       0.000284\n",
       "‚Äúsim‚Äù                     0.000284\n",
       "kkkkkkkk                  0.000284\n",
       "barcelona/venezabebida    0.000284\n",
       "bro                       0.000284\n",
       "beatriz                   0.000284\n",
       "kkkkkkkkkkkkkkkk          0.000284\n",
       "itupeva                   0.000284\n",
       "homenagem                 0.000284\n",
       "pot√™ncia                  0.000284\n",
       "swxvmj60od                0.000284\n",
       "bagre                     0.000284\n",
       "16                        0.000284\n",
       "noooopsssss               0.000284\n",
       "essas                     0.000284\n",
       "bailey‚Äôs                  0.000284\n",
       "pen                       0.000284\n",
       "desse                     0.000284\n",
       "vxxvvh0zqr                0.000284\n",
       "the                       0.000284\n",
       "amg                       0.000284\n",
       "adorooo                   0.000284\n",
       "recordista                0.000284\n",
       "57                        0.000284\n",
       "preta                     0.000284\n",
       "nrjlp0gaci                0.000284\n",
       "‚Äúpintin‚Äù                  0.000284\n",
       "Length: 1341, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palavras_nao_relevantes.value_counts(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance\n",
    "\n",
    "Agora voc√™ deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2962075848303393"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_relevante = palavras_relevantes.size/universo.size\n",
    "P_relevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7037924151696606"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_nao_relevante = palavras_nao_relevantes.size/universo.size\n",
    "P_nao_relevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw2 = pd.read_excel('Bugatti_teste.xlsx')\n",
    "relevante_teste_raw2 = raw2[raw2['Relev√¢ncia'] == 1]\n",
    "nao_relevante_teste_raw2 = raw2[raw2[\"Relev√¢ncia\"] == 0]\n",
    "\n",
    "lista1 = []\n",
    "for tweet in relevante_teste_raw2['Teste']:\n",
    "    texto = transform_emojis(tweet)\n",
    "    lista1.append(cleanup(texto))\n",
    "    \n",
    "relevante_teste = pd.Series(lista1)\n",
    "relevante_teste = relevante_teste.str.replace('|'.join(l),'',regex=True).str.strip()\n",
    "\n",
    "lista2 = []\n",
    "for tweet in nao_relevante_teste_raw2['Teste']:\n",
    "    texto = transform_emojis(tweet)\n",
    "    lista2.append(cleanup(texto))\n",
    "    \n",
    "nao_relevante_teste = pd.Series(lista2)\n",
    "nao_relevante_teste = nao_relevante_teste.str.replace('|'.join(l),'',regex=True).str.strip()\n",
    "\n",
    "lista3 = []\n",
    "for tweet in raw2['Teste']:\n",
    "    texto = transform_emojis(tweet)\n",
    "    lista3.append(cleanup(texto))\n",
    "    \n",
    "testudo = pd.Series(lista3)\n",
    "testudo = testudo.str.replace('|'.join(l),'',regex=True).str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bugatti    60\n",
       "dtype: int64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista4 = []\n",
    "for tweet in testudo:\n",
    "    lista4 = lista4 + tweet.split()\n",
    "\n",
    "universo_teste = pd.Series(lista4)\n",
    "universo_teste.value_counts()\n",
    "\n",
    "lista5 = []\n",
    "for tweet in relevante_teste:\n",
    "    lista5 = lista5 + tweet.split()\n",
    "\n",
    "palavras_relevantes_teste = pd.Series(lista5)\n",
    "palavras_relevantes_teste.value_counts()\n",
    "\n",
    "lista6 = []\n",
    "for tweet in nao_relevante_teste:\n",
    "    lista6 = lista6 + tweet.split()\n",
    "\n",
    "palavras_nao_relevantes_teste = pd.Series(lista6)\n",
    "palavras_nao_relevantes_teste.value_counts().head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Montando o Classificardor Naive Bayes\n",
    "\n",
    "#### Probabilidades de ser relevante ou n√£o relevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3416"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palavras_teste = palavras_relevantes_teste.size + palavras_nao_relevantes_teste.size\n",
    "palavras_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4028103044496487"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pt_relevante = palavras_relevantes_teste.size / palavras_teste\n",
    "Pt_relevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5971896955503513"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ptn_relevante = palavras_nao_relevantes_teste.size / palavras_teste\n",
    "Ptn_relevante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Como o classificador funcionar√°:\n",
    "\n",
    "Todos os tweets presentes na planilha de testes ser√£o, individualmente, analisados pelo classificador e catalogados, em um loop. Depois de todo esse processo, os resultados de cada tweet analisado, que podem ser ou \"Relev√¢nte\" ou \"Irrelev√¢nte\", pelo menos neste primeiro momento, ser√£o adicionados a uma lista com o fim de serem comparados com a an√°lise feita √† m√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando o loop para o c√°lculo da probabilidade de ser relevante:\n",
    "\n",
    "probabilidade = 1\n",
    "lista_resultados_numericos_relevantes = []\n",
    "tweet = 0\n",
    "\n",
    "#selecionando o tweet\n",
    "for tweets in testudo:\n",
    "    \n",
    "    #Quebra o tweet em uma lista de palavras\n",
    "    tweet = tweets.split()\n",
    "    \n",
    "    # Calculando a probabilidade deste tweet ser relevante dado as suas palavras\n",
    "    for palavra in tweet:\n",
    "        \n",
    "        #N√£o deixa que palavras n√£o pertencentes √† s√©rie bugem o c√≥digo\n",
    "        if palavra not in palavras_relevantes_teste:\n",
    "            probabilidade *= 1/3416\n",
    "        else:\n",
    "            probabilidade *= (palavras_relevantes_teste[palavra].value_counts(True) + 1/3416)\n",
    "        \n",
    "    #Guardando os resultados e resetando a vari√°vel probabilidade    \n",
    "    lista_resultados_numericos_relevantes.append(probabilidade * Pt_relevante)\n",
    "    probabilidade = 1\n",
    "    tweet = []\n",
    "\n",
    "#lista_resultados_numericos_relevantes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_resultados_numericos_nrelevantes = []\n",
    "tweet = 0\n",
    "probabilidade = 1\n",
    "\n",
    "for tweets in testudo:\n",
    "    \n",
    "    #Quebra o tweet em uma lista de palavras\n",
    "    tweet = tweets.split()\n",
    "    \n",
    "    # Calculando a probabilidade deste tweet n√£o ser relevante dado as suas palavras\n",
    "    for palavra in tweet:\n",
    "        \n",
    "        #N√£o deixa que palavras n√£o pertencentes √† s√©rie bugem o c√≥digo\n",
    "        if palavra not in palavras_nao_relevantes_teste:\n",
    "            probabilidade *= 1/3416\n",
    "        else:\n",
    "            probabilidade *= (palavras_nao_relevantes_teste[palavra].value_counts(True) + 1/3416)\n",
    "        \n",
    "    #Guardando os resultados e resetando a vari√°vel probabilidade    \n",
    "    lista_resultados_numericos_nrelevantes.append(probabilidade * Ptn_relevante)\n",
    "    probabilidade = 1\n",
    "\n",
    "#lista_resultados_numericos_nrelevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte',\n",
       " 'N√£o relev√¢nte']"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=0\n",
    "lista_resultados = []\n",
    "for tweet in testudo:\n",
    "    \n",
    "    if lista_resultados_numericos_relevantes[i] > lista_resultados_numericos_nrelevantes[i]:\n",
    "           lista_resultados.append(\"Relev√¢nte\")\n",
    "            \n",
    "    if lista_resultados_numericos_relevantes[i] == lista_resultados_numericos_nrelevantes[i]:\n",
    "        lista_resultados.append(\"Neutro\")\n",
    "        \n",
    "    if lista_resultados_numericos_relevantes[i] < lista_resultados_numericos_nrelevantes[i]:\n",
    "        lista_resultados.append(\"N√£o relev√¢nte\")\n",
    "        \n",
    "    i += 1\n",
    "    \n",
    "lista_resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aperfei√ßoamento:\n",
    "\n",
    "Os trabalhos v√£o evoluir em conceito dependendo da quantidade de itens avan√ßados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separa√ß√£o de espa√ßos entre palavras e emojis ou emojis e emojis\n",
    "* Propor outras limpezas e transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o ou classifica√ß√£o\n",
    "* Criar categorias intermedi√°rias de relev√¢ncia baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que n√£o posso usar o pr√≥prio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cen√°rios para Na√Øve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indica√ß√µes concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que periodicamente realiza an√°lise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refer√™ncias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
