{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Ci√™ncia dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nome: Breno Marti**\n",
    "\n",
    "**Nome: Jo√£o Pedro Chacon Ruiz**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ser√£o permitidos grupos de tr√™s pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisar√£o fazer um question√°rio de avalia√ß√£o de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Classificador autom√°tico de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando o ambiente no jupyter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "#Instalando o tweepy\n",
    "!pip install tweepy\n",
    "!pip install emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Autenticando no  Twitter\n",
    "\n",
    "* Conta: ***[Preencha aqui o id da sua conta. Ex: @fulano ]***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#Dados de autentica√ß√£o do twitter:\\n\\n#Coloque aqui o identificador da conta no twitter: @fulano\\n\\n#leitura do arquivo no formato JSON\\nwith open('auth.pass') as fp:    \\n    data = json.load(fp)\\n\\n#Configurando a biblioteca. N√£o modificar\\nauth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\\nauth.set_access_token(data['access_token'], data['access_token_secret'])\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#Dados de autentica√ß√£o do twitter:\n",
    "\n",
    "#Coloque aqui o identificador da conta no twitter: @fulano\n",
    "\n",
    "#leitura do arquivo no formato JSON\n",
    "with open('auth.pass') as fp:    \n",
    "    data = json.load(fp)\n",
    "\n",
    "#Configurando a biblioteca. N√£o modificar\n",
    "auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "auth.set_access_token(data['access_token'], data['access_token_secret'])\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Etapas do projeto:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escolha de um produto e coleta das mensagens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Produto escolhido:\n",
    "produto = 'Bugatti'\n",
    "\n",
    "#Quantidade m√≠nima de mensagens capturadas:\n",
    "n = 500\n",
    "#Quantidade m√≠nima de mensagens para a base de treinamento:\n",
    "t = 300\n",
    "\n",
    "#Filtro de l√≠ngua, escolha uma na tabela ISO 639-1.\n",
    "lang = 'pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturando os dados do twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#Cria um objeto para a captura\\napi = tweepy.API(auth)\\n\\n#Inicia a captura, para mais detalhes: ver a documenta√ß√£o do tweepy\\ni = 1\\nmsgs = []\\nfor msg in tweepy.Cursor(api.search, q=produto, lang=lang, tweet_mode=\"extended\").items():\\n    if (not msg.retweeted) and (\\'RT\\' not in msg.full_text):\\n        msgs.append(msg.full_text.lower())\\n        i += 1\\n    if i > n:\\n        break\\n\\n#Embaralhando as mensagens para reduzir um poss√≠vel vi√©s\\nshuffle(msgs\\'\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#Cria um objeto para a captura\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "#Inicia a captura, para mais detalhes: ver a documenta√ß√£o do tweepy\n",
    "i = 1\n",
    "msgs = []\n",
    "for msg in tweepy.Cursor(api.search, q=produto, lang=lang, tweet_mode=\"extended\").items():\n",
    "    if (not msg.retweeted) and ('RT' not in msg.full_text):\n",
    "        msgs.append(msg.full_text.lower())\n",
    "        i += 1\n",
    "    if i > n:\n",
    "        break\n",
    "\n",
    "#Embaralhando as mensagens para reduzir um poss√≠vel vi√©s\n",
    "shuffle(msgs'\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando os dados em uma planilha Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#Verifica se o arquivo n√£o existe para n√£o substituir um conjunto pronto\\nif not os.path.isfile('./{0}.xlsx'.format(produto)):\\n    \\n    #Abre o arquivo para escrita\\n    writer = pd.ExcelWriter('{0}.xlsx'.format(produto))\\n\\n    #divide o conjunto de mensagens em duas planilhas\\n    dft = pd.DataFrame({'Treinamento' : pd.Series(msgs[:t])})\\n    dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\\n\\n    dfc = pd.DataFrame({'Teste' : pd.Series(msgs[t:])})\\n    dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\\n\\n    #fecha o arquivo\\n    writer.save()\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#Verifica se o arquivo n√£o existe para n√£o substituir um conjunto pronto\n",
    "if not os.path.isfile('./{0}.xlsx'.format(produto)):\n",
    "    \n",
    "    #Abre o arquivo para escrita\n",
    "    writer = pd.ExcelWriter('{0}.xlsx'.format(produto))\n",
    "\n",
    "    #divide o conjunto de mensagens em duas planilhas\n",
    "    dft = pd.DataFrame({'Treinamento' : pd.Series(msgs[:t])})\n",
    "    dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "\n",
    "    dfc = pd.DataFrame({'Teste' : pd.Series(msgs[t:])})\n",
    "    dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\n",
    "\n",
    "    #fecha o arquivo\n",
    "    writer.save()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Classificando as mensagens na coragem\n",
    "\n",
    "Esta etapa √© manual. Fa√ßa a mesma pelo Excel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando o Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = pd.read_excel('Bugatti_treino.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevante_treino_raw = raw[raw['Relev√¢ncia'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nao_relevante_treino_raw = raw[raw[\"Relev√¢ncia\"] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fun√ß√µes de limpeza de texto:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "def cleanup(text):\n",
    "    \"\"\"\n",
    "        Fun√ß√£o de limpeza muito simples que troca alguns sinais b√°sicos por espa√ßos\n",
    "    \"\"\"\n",
    "    punctuation = '[#@,!\\()-.‚Ç¨\":?;]' # Note que os sinais [] s√£o delimitadores de um conjunto.\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, ' ', text)\n",
    "    return text_subbed   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_emojis(text):\n",
    "    clean = emojis.decode(text)\n",
    "    return clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Limpando e transformando os dataframes em s√©ries para a an√°lise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = ['\\n','https','//t','co/']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = []\n",
    "for tweet in relevante_treino_raw['Treinamento']:\n",
    "    texto = transform_emojis(tweet)\n",
    "    list1.append(cleanup(texto))\n",
    "    \n",
    "relevante_treino = pd.Series(list1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nota do professor: explicar como o c√≥digo abaixo funciona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     mds cade a koenigsegg pra bater esses 500km/h ...\n",
       "1     bugatti bate recorde de velocidade com um carr...\n",
       "2     depois de bater o pr√≥prio recorde de 490 km/h ...\n",
       "3     podem n√£o ser os mais bonitos  mas os carros d...\n",
       "4     parece que teremos o bugatti chiron super spor...\n",
       "5     bugatti descobriu o qu√£o r√°pido o chiron √©  fl...\n",
       "6     bugatti chiron com velocidade final de 490 km/...\n",
       "7      quase 500 kph em um carro  absurdo    cahutq6joi\n",
       "8     t√¥ pesquisando uns carros luxuosos aqui e perc...\n",
       "9     ap√≥s 490 km/h do chiron  bugatti anuncia que n...\n",
       "10    bugatti chiron super sport 300   vers√£o  civil...\n",
       "11    bugatti ultrapassa a marca dos 480 km/h ‚Äì e de...\n",
       "12    bugatti quebra o recorde de velocidade com um ...\n",
       "13    bugatti chiron chega a 490 km/h e bate recorde...\n",
       "14    carro mais r√°pido do mundo  nova bugatti ter√° ...\n",
       "15    williamenb outra coisa  porque aquele bugatti ...\n",
       "16    wow  a bugatti chiron chegou a 490 km/h    iss...\n",
       "17    bugatti chiron  levemente modificada  chegou a...\n",
       "18    bugatti chiron super sport 300  chega a 440 km...\n",
       "19    williamenb agora t√° ficando divertido essa bri...\n",
       "20    bugatti chiron super sport 300  chega a 440 km...\n",
       "21    veja como o bugatti chiron quase bateu a barre...\n",
       "22    bugatti chiron chega aos 490 48 km/h e quebra ...\n",
       "23    mano    490 km/h    chegou um momento que eu a...\n",
       "24    um carro  de rua  que atingiu 490 48 km/h    p...\n",
       "25    williamenb mas ser√° que esses 483 km/h n√£o s√£o...\n",
       "26       e o bugatti chiron que chegou a 490 km/h   o o\n",
       "27    eu to incr√©dulo que a bugatti conseguiu chegar...\n",
       "28    a bugatti alterou um chiron para bater os 490 ...\n",
       "29    o piloto de testes da bugatti  andy wallace  a...\n",
       "                            ...                        \n",
       "44    assista ao bugatti chiron esmagar a m√≠tica bar...\n",
       "45    o bugatti chiron sport acabou de bater o recor...\n",
       "46    fg_genuino  pauloramos1 o carro mais caro do m...\n",
       "47     o novo bugatti chiron bateu s√≥ 490 km/h est√° bom\n",
       "48    n√£o da nem pra acreditar que o bugatti chiron ...\n",
       "49    segundou com recordes   red_car o bugatti chir...\n",
       "50    acabei de descobrir q uma bugatti conseguiu ch...\n",
       "51    menino christian tomando coro da bugatti mais ...\n",
       "52    pqq a bugatti n√£o fabrica avi√£o logo  a porra ...\n",
       "53    parab√©ns a bugatti por fazer 490 48km/h cm o c...\n",
       "54    curiosidades  voc√™ sabia que bugatti chiron √© ...\n",
       "55    bugatti bateu novamente o recorde de velocidad...\n",
       "56    recordista mundial de velocidade em vers√£o ‚Äúci...\n",
       "57    bugatti falando que a velocidade do prot√≥tipo ...\n",
       "58    williamenb esse bugatti √© alguma vers√£o especi...\n",
       "59    bugatti chiron alcan√ßa 490 km/h e bate recorde...\n",
       "60             a bugatti sabe fazer carro  vai se fuder\n",
       "61    como assim a bugatti chegou aos 490km/h com o ...\n",
       "62    sadeiji mano koenigsegg q √© feio mano  bugatti...\n",
       "63    a bugatti anunciou q n vai mais quebrar o reco...\n",
       "64    bem    a bugatti bateu novamente o recorde de ...\n",
       "65    bugatti chiron chega a 490 km/h e bate recorde...\n",
       "66    bugatti bateu o record de velocidade     490km...\n",
       "67    algu√©m precisa demitir o designer seja l√° nome...\n",
       "68    bugatti chiron super sport 300  chega a 440 km...\n",
       "69    a quase 500 km/h  bugatti chiron vira o carro ...\n",
       "70    recorde mundial para¬†bugatti¬†  um ve√≠culo de p...\n",
       "71    williamenb sei que sou fan boy da bugatti  mas...\n",
       "72    me pergunto que tipo de pneu usaram no chiron ...\n",
       "73    o bugatti chiron √© de novo o carro mais r√°pido...\n",
       "Length: 74, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevante_treino = relevante_treino.str.replace('|'.join(l),'',regex=True).str.strip()\n",
    "relevante_treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "list2 = []\n",
    "for tweet in nao_relevante_treino_raw['Treinamento']:\n",
    "    texto = transform_emojis(tweet)\n",
    "    list2.append(cleanup(texto))\n",
    "    \n",
    "nao_relevante_treino = pd.Series(list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      talla 42 eu  bugatti 3 11382e 11  botas clasic...\n",
       "1      talla 40 eu  bugatti 3 11384e 11  botas clasic...\n",
       "2      carolinaazered2  junior__bugatti com o bumbum ...\n",
       "3                fuga de bugatti com ela depois das tr√™s\n",
       "4      bugatti ver√≥n supersport motor triturbo 8 0 l ...\n",
       "5      el nuevo r√©cord de velocidad del bugatti chiro...\n",
       "6      se continuar esse calor vai todo mundo derrete...\n",
       "7                                 lleobertodo menino bom\n",
       "8      gente vamos jogar stop  n√£o vale olhar na inte...\n",
       "9      aberto at√© de madrugada  bugatti chiron chega ...\n",
       "10     gente vamos jogar stop  n√£o vale olhar na inte...\n",
       "11     luaracaastro desse jeito  daqui a pouco volta ...\n",
       "12                    jenniferbraaga uma delicinha kkkkk\n",
       "13                              paloma_souza18 foi ontem\n",
       "14     ballerichh claro q  lembro alugamos um  bugatt...\n",
       "15     mas eu conseguiria trazer um suco g√°strico esp...\n",
       "16              ofere√ßam me um bugatti  n√£o pe√ßo mais xd\n",
       "17     iamthebrunao tomara q n√£o  acho bugatti mais foda\n",
       "18          ir ou n√£o ir no bugatti sexta  eis a quest√£o\n",
       "19        quero foder num bugatti e um dia vai acontecer\n",
       "20     gente vamos jogar stop  n√£o vale olhar na inte...\n",
       "21     talla 43 eu  bugatti 3 11384e 11  botas clasic...\n",
       "22           karist0n pq seu apelido tinha q ser bugatti\n",
       "23     talla 43 eu  bugatti 3 11384e 11  botas clasic...\n",
       "24            fhbugatti carai bugatti ce ja jogou inside\n",
       "25     paloma_souza18  ribeirohthais  igorrealequatro...\n",
       "26     luaracaastro enquanto isso vou bebendo minha c...\n",
       "27     use a primeira letra do seu nome e responda  n...\n",
       "28     ahhh  tamb√©m tem 2 sons nossos que t√£o beirand...\n",
       "29     manoooos eu quero um gtr tamb√©m portanto podem...\n",
       "                             ...                        \n",
       "196    bbrendabreu quem usa isso n√£o sabe nem oq √© bi...\n",
       "197                       yuri_bugatti vc e exce√ß√£o more\n",
       "198    opatata22 s√≥ acho que voc√™ est√° muito s√≥bria f...\n",
       "199             yuri_bugatti  arrasou kkkkk   11hlk7jwm6\n",
       "200    gente vamos jogar stop  n√£o vale olhar na inte...\n",
       "201    nome  brunalugar  barbebida  bacardicomida  ba...\n",
       "202    fredsilvered se bugatti fosse boa se chamaria ...\n",
       "203    a gente tenta n√©  joy  cold_sweat  car  arte  ...\n",
       "204                               aguiiarr_ kkkkkk pleno\n",
       "205      preciozoroberta decep√ß√£o  facepalm üèΩ‚Äç male_sign\n",
       "206                 junior__bugatti kkkkkkkkkkk sem mais\n",
       "207    nome  beatrizlugar  brasil bebida  balalaikaco...\n",
       "208    vai na festa dia 13  ‚Äî mas isso √© certo       ...\n",
       "209          queria estar dirigindo o bugatti q eu gosto\n",
       "210    ferrari 812gts  bugatti  ferrari  porsche  car...\n",
       "211    pqp bugatti conseguiu quebrar o recorde de vel...\n",
       "212    gente vamos jogar stop  n√£o vale olhar na inte...\n",
       "213    yuri_bugatti olocooo logo ele que n√£o batia em...\n",
       "214    a amiga me falou um bglh hj e a vontade foi de...\n",
       "215    fuga de bugatti com ela depois das 3  ela me p...\n",
       "216    crl2m  alanalves899  alvesmaary82 qual √© o teu...\n",
       "217    dr_diogorocha_ o bugatti n√£o tem hip√≥tese cont...\n",
       "218    davidakabadao gostas de meter a 7 ¬™ mudan√ßa √© ...\n",
       "219    primeira vit√≥ria de um monegasco na it√°lia des...\n",
       "220    j√° peguei √¥nibus lotado  agora eu quero bugatt...\n",
       "221                                  bom dia √© o caralho\n",
       "222                        vai ser de enjoar das bugatti\n",
       "223    quer d√° um role a 490 km/h      hfizt7txki bug...\n",
       "224    ponteiro da bugatti estourou esse final de semana\n",
       "225    kotabrunoag s√≥ mesmo  tocar ‚Äúmocita‚Äù  ‚Äúpintin‚Äù...\n",
       "Length: 226, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nao_relevante_treino = nao_relevante_treino.str.replace('|'.join(l),'',regex=True).str.strip()\n",
    "nao_relevante_treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "list3 = []\n",
    "for tweet in raw['Treinamento']:\n",
    "    texto = transform_emojis(tweet)\n",
    "    list3.append(cleanup(texto))\n",
    "    \n",
    "tudo = pd.Series(list3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      talla 42 eu  bugatti 3 11382e 11  botas clasic...\n",
       "1      talla 40 eu  bugatti 3 11384e 11  botas clasic...\n",
       "2      carolinaazered2  junior__bugatti com o bumbum ...\n",
       "3      mds cade a koenigsegg pra bater esses 500km/h ...\n",
       "4      bugatti bate recorde de velocidade com um carr...\n",
       "5                fuga de bugatti com ela depois das tr√™s\n",
       "6      bugatti ver√≥n supersport motor triturbo 8 0 l ...\n",
       "7      el nuevo r√©cord de velocidad del bugatti chiro...\n",
       "8      se continuar esse calor vai todo mundo derrete...\n",
       "9      depois de bater o pr√≥prio recorde de 490 km/h ...\n",
       "10                                lleobertodo menino bom\n",
       "11     gente vamos jogar stop  n√£o vale olhar na inte...\n",
       "12     podem n√£o ser os mais bonitos  mas os carros d...\n",
       "13     aberto at√© de madrugada  bugatti chiron chega ...\n",
       "14     gente vamos jogar stop  n√£o vale olhar na inte...\n",
       "15     luaracaastro desse jeito  daqui a pouco volta ...\n",
       "16                    jenniferbraaga uma delicinha kkkkk\n",
       "17                              paloma_souza18 foi ontem\n",
       "18     parece que teremos o bugatti chiron super spor...\n",
       "19     ballerichh claro q  lembro alugamos um  bugatt...\n",
       "20     mas eu conseguiria trazer um suco g√°strico esp...\n",
       "21              ofere√ßam me um bugatti  n√£o pe√ßo mais xd\n",
       "22     iamthebrunao tomara q n√£o  acho bugatti mais foda\n",
       "23          ir ou n√£o ir no bugatti sexta  eis a quest√£o\n",
       "24        quero foder num bugatti e um dia vai acontecer\n",
       "25     bugatti descobriu o qu√£o r√°pido o chiron √©  fl...\n",
       "26     gente vamos jogar stop  n√£o vale olhar na inte...\n",
       "27     talla 43 eu  bugatti 3 11384e 11  botas clasic...\n",
       "28           karist0n pq seu apelido tinha q ser bugatti\n",
       "29     bugatti chiron com velocidade final de 490 km/...\n",
       "                             ...                        \n",
       "270    vai na festa dia 13  ‚Äî mas isso √© certo       ...\n",
       "271    sadeiji mano koenigsegg q √© feio mano  bugatti...\n",
       "272    a bugatti anunciou q n vai mais quebrar o reco...\n",
       "273          queria estar dirigindo o bugatti q eu gosto\n",
       "274    bem    a bugatti bateu novamente o recorde de ...\n",
       "275    ferrari 812gts  bugatti  ferrari  porsche  car...\n",
       "276    pqp bugatti conseguiu quebrar o recorde de vel...\n",
       "277    bugatti chiron chega a 490 km/h e bate recorde...\n",
       "278    gente vamos jogar stop  n√£o vale olhar na inte...\n",
       "279    yuri_bugatti olocooo logo ele que n√£o batia em...\n",
       "280    a amiga me falou um bglh hj e a vontade foi de...\n",
       "281    fuga de bugatti com ela depois das 3  ela me p...\n",
       "282    crl2m  alanalves899  alvesmaary82 qual √© o teu...\n",
       "283    dr_diogorocha_ o bugatti n√£o tem hip√≥tese cont...\n",
       "284    bugatti bateu o record de velocidade     490km...\n",
       "285    algu√©m precisa demitir o designer seja l√° nome...\n",
       "286    bugatti chiron super sport 300  chega a 440 km...\n",
       "287    a quase 500 km/h  bugatti chiron vira o carro ...\n",
       "288    recorde mundial para¬†bugatti¬†  um ve√≠culo de p...\n",
       "289    davidakabadao gostas de meter a 7 ¬™ mudan√ßa √© ...\n",
       "290    primeira vit√≥ria de um monegasco na it√°lia des...\n",
       "291    j√° peguei √¥nibus lotado  agora eu quero bugatt...\n",
       "292                                  bom dia √© o caralho\n",
       "293    williamenb sei que sou fan boy da bugatti  mas...\n",
       "294                        vai ser de enjoar das bugatti\n",
       "295    me pergunto que tipo de pneu usaram no chiron ...\n",
       "296    quer d√° um role a 490 km/h      hfizt7txki bug...\n",
       "297    ponteiro da bugatti estourou esse final de semana\n",
       "298    kotabrunoag s√≥ mesmo  tocar ‚Äúmocita‚Äù  ‚Äúpintin‚Äù...\n",
       "299    o bugatti chiron √© de novo o carro mais r√°pido...\n",
       "Length: 300, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tudo = tudo.str.replace('|'.join(l),'',regex=True).str.strip()\n",
    "tudo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contando o n√∫mero de apari√ß√µes de cada palavra :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bugatti             223\n",
       "de                  128\n",
       "a                   124\n",
       "o                   119\n",
       "que                  75\n",
       "um                   74\n",
       "e                    69\n",
       "do                   67\n",
       "chiron               65\n",
       "n√£o                  62\n",
       "na                   55\n",
       "km/h                 46\n",
       "carro                46\n",
       "nome                 40\n",
       "490                  40\n",
       "eu                   39\n",
       "√©                    39\n",
       "com                  37\n",
       "em                   35\n",
       "mais                 33\n",
       "primeira             33\n",
       "seu                  30\n",
       "letra                26\n",
       "para                 26\n",
       "gente                26\n",
       "por                  25\n",
       "velocidade           24\n",
       "da                   24\n",
       "bananaobjeto         23\n",
       "recorde              23\n",
       "                   ... \n",
       "deitar                1\n",
       "velho                 1\n",
       "jenniferbraaga        1\n",
       "tenta                 1\n",
       "kkkkkkkk              1\n",
       "more                  1\n",
       "impressionante        1\n",
       "exploding_head        1\n",
       "derreter              1\n",
       "y8wid57fjp            1\n",
       "brumadinhobebida      1\n",
       "fixando               1\n",
       "olha                  1\n",
       "afro                  1\n",
       "sorte                 1\n",
       "ontem                 1\n",
       "bacateobjeto          1\n",
       "todas                 1\n",
       "evitar                1\n",
       "ias                   1\n",
       "modificado            1\n",
       "yxhb3smvyb            1\n",
       "obxz73heuf            1\n",
       "tiver                 1\n",
       "breve                 1\n",
       "ngcbjnguf9            1\n",
       "sunglasses            1\n",
       "rica                  1\n",
       "monaa                 1\n",
       "blenheimpalace        1\n",
       "Length: 1676, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list4 = []\n",
    "for tweet in tudo:\n",
    "    list4 = list4 + tweet.split()\n",
    "\n",
    "universo = pd.Series(list4)\n",
    "universo.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bugatti         76\n",
       "o               55\n",
       "a               53\n",
       "de              52\n",
       "chiron          45\n",
       "km/h            38\n",
       "490             31\n",
       "que             31\n",
       "carro           27\n",
       "um              26\n",
       "do              23\n",
       "em              22\n",
       "velocidade      20\n",
       "mais            20\n",
       "recorde         19\n",
       "e               17\n",
       "com             15\n",
       "√©               15\n",
       "n√£o             14\n",
       "da              13\n",
       "300             11\n",
       "mph             10\n",
       "sport           10\n",
       "os               9\n",
       "super            8\n",
       "mundial          8\n",
       "chega            8\n",
       "r√°pido           7\n",
       "por              7\n",
       "500              7\n",
       "                ..\n",
       "distintas        1\n",
       "absurdamente     1\n",
       "cima             1\n",
       "600              1\n",
       "ye7je7pxvg       1\n",
       "83avneux8y       1\n",
       "vendido          1\n",
       "sa√≠das           1\n",
       "andy             1\n",
       "barrier          1\n",
       "tomando          1\n",
       "primeira         1\n",
       "teria            1\n",
       "sem              1\n",
       "conhecidos       1\n",
       "insano           1\n",
       "qse              1\n",
       "out              1\n",
       "parab√©ns         1\n",
       "pqp              1\n",
       "momento          1\n",
       "foda             1\n",
       "repost           1\n",
       "305              1\n",
       "seja             1\n",
       "estrondosos      1\n",
       "fudeeer          1\n",
       "pneu             1\n",
       "pode             1\n",
       "fixando          1\n",
       "Length: 522, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list5 = []\n",
    "for tweet in relevante_treino:\n",
    "    list5 = list5 + tweet.split()\n",
    "\n",
    "palavras_relevantes = pd.Series(list5)\n",
    "palavras_relevantes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bugatti             147\n",
       "de                   76\n",
       "a                    71\n",
       "o                    64\n",
       "e                    52\n",
       "na                   49\n",
       "um                   48\n",
       "n√£o                  48\n",
       "que                  44\n",
       "do                   44\n",
       "nome                 39\n",
       "primeira             32\n",
       "eu                   32\n",
       "seu                  29\n",
       "letra                26\n",
       "gente                25\n",
       "√©                    24\n",
       "bananaobjeto         23\n",
       "vale                 22\n",
       "olhar                22\n",
       "com                  22\n",
       "vamos                22\n",
       "jogar                22\n",
       "stop                 21\n",
       "respondanome         21\n",
       "brancofruta          21\n",
       "chiron               20\n",
       "bugatticor           20\n",
       "para                 19\n",
       "carro                19\n",
       "                   ... \n",
       "botafogo              1\n",
       "gra√ßas                1\n",
       "5e26bo2s25            1\n",
       "pqp                   1\n",
       "mundial               1\n",
       "xkgglqwab4            1\n",
       "bilion√°rios           1\n",
       "oi                    1\n",
       "briguento             1\n",
       "produto               1\n",
       "vem                   1\n",
       "ah                    1\n",
       "fa4euuuew9galera      1\n",
       "palestra              1\n",
       "piatrizz              1\n",
       "00gwich               1\n",
       "sonhos                1\n",
       "ultrapassa            1\n",
       "ol√°                   1\n",
       "recordista            1\n",
       "59%                   1\n",
       "cacete                1\n",
       "s√©rie                 1\n",
       "claro                 1\n",
       "laqueira              1\n",
       "n√∫mero                1\n",
       "vvpa7uhlzf            1\n",
       "7                     1\n",
       "grande                1\n",
       "blenheimpalace        1\n",
       "Length: 1341, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list6 = []\n",
    "for tweet in nao_relevante_treino:\n",
    "    list6 = list6 + tweet.split()\n",
    "\n",
    "palavras_nao_relevantes = pd.Series(list6)\n",
    "palavras_nao_relevantes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frequ√™ncia relativa de cada palavra:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bugatti             0.044511\n",
       "de                  0.025549\n",
       "a                   0.024750\n",
       "o                   0.023752\n",
       "que                 0.014970\n",
       "um                  0.014770\n",
       "e                   0.013772\n",
       "do                  0.013373\n",
       "chiron              0.012974\n",
       "n√£o                 0.012375\n",
       "na                  0.010978\n",
       "km/h                0.009182\n",
       "carro               0.009182\n",
       "nome                0.007984\n",
       "490                 0.007984\n",
       "eu                  0.007784\n",
       "√©                   0.007784\n",
       "com                 0.007385\n",
       "em                  0.006986\n",
       "mais                0.006587\n",
       "primeira            0.006587\n",
       "seu                 0.005988\n",
       "letra               0.005190\n",
       "para                0.005190\n",
       "gente               0.005190\n",
       "por                 0.004990\n",
       "velocidade          0.004790\n",
       "da                  0.004790\n",
       "bananaobjeto        0.004591\n",
       "recorde             0.004591\n",
       "                      ...   \n",
       "deitar              0.000200\n",
       "velho               0.000200\n",
       "jenniferbraaga      0.000200\n",
       "tenta               0.000200\n",
       "kkkkkkkk            0.000200\n",
       "more                0.000200\n",
       "impressionante      0.000200\n",
       "exploding_head      0.000200\n",
       "derreter            0.000200\n",
       "y8wid57fjp          0.000200\n",
       "brumadinhobebida    0.000200\n",
       "fixando             0.000200\n",
       "olha                0.000200\n",
       "afro                0.000200\n",
       "sorte               0.000200\n",
       "ontem               0.000200\n",
       "bacateobjeto        0.000200\n",
       "todas               0.000200\n",
       "evitar              0.000200\n",
       "ias                 0.000200\n",
       "modificado          0.000200\n",
       "yxhb3smvyb          0.000200\n",
       "obxz73heuf          0.000200\n",
       "tiver               0.000200\n",
       "breve               0.000200\n",
       "ngcbjnguf9          0.000200\n",
       "sunglasses          0.000200\n",
       "rica                0.000200\n",
       "monaa               0.000200\n",
       "blenheimpalace      0.000200\n",
       "Length: 1676, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "universo.value_counts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bugatti         0.051213\n",
       "o               0.037062\n",
       "a               0.035714\n",
       "de              0.035040\n",
       "chiron          0.030323\n",
       "km/h            0.025606\n",
       "490             0.020889\n",
       "que             0.020889\n",
       "carro           0.018194\n",
       "um              0.017520\n",
       "do              0.015499\n",
       "em              0.014825\n",
       "velocidade      0.013477\n",
       "mais            0.013477\n",
       "recorde         0.012803\n",
       "e               0.011456\n",
       "com             0.010108\n",
       "√©               0.010108\n",
       "n√£o             0.009434\n",
       "da              0.008760\n",
       "300             0.007412\n",
       "mph             0.006739\n",
       "sport           0.006739\n",
       "os              0.006065\n",
       "super           0.005391\n",
       "mundial         0.005391\n",
       "chega           0.005391\n",
       "r√°pido          0.004717\n",
       "por             0.004717\n",
       "500             0.004717\n",
       "                  ...   \n",
       "distintas       0.000674\n",
       "absurdamente    0.000674\n",
       "cima            0.000674\n",
       "600             0.000674\n",
       "ye7je7pxvg      0.000674\n",
       "83avneux8y      0.000674\n",
       "vendido         0.000674\n",
       "sa√≠das          0.000674\n",
       "andy            0.000674\n",
       "barrier         0.000674\n",
       "tomando         0.000674\n",
       "primeira        0.000674\n",
       "teria           0.000674\n",
       "sem             0.000674\n",
       "conhecidos      0.000674\n",
       "insano          0.000674\n",
       "qse             0.000674\n",
       "out             0.000674\n",
       "parab√©ns        0.000674\n",
       "pqp             0.000674\n",
       "momento         0.000674\n",
       "foda            0.000674\n",
       "repost          0.000674\n",
       "305             0.000674\n",
       "seja            0.000674\n",
       "estrondosos     0.000674\n",
       "fudeeer         0.000674\n",
       "pneu            0.000674\n",
       "pode            0.000674\n",
       "fixando         0.000674\n",
       "Length: 522, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palavras_relevantes.value_counts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bugatti             0.041690\n",
       "de                  0.021554\n",
       "a                   0.020136\n",
       "o                   0.018151\n",
       "e                   0.014748\n",
       "na                  0.013897\n",
       "um                  0.013613\n",
       "n√£o                 0.013613\n",
       "que                 0.012479\n",
       "do                  0.012479\n",
       "nome                0.011061\n",
       "primeira            0.009075\n",
       "eu                  0.009075\n",
       "seu                 0.008225\n",
       "letra               0.007374\n",
       "gente               0.007090\n",
       "√©                   0.006807\n",
       "bananaobjeto        0.006523\n",
       "vale                0.006239\n",
       "olhar               0.006239\n",
       "com                 0.006239\n",
       "vamos               0.006239\n",
       "jogar               0.006239\n",
       "stop                0.005956\n",
       "respondanome        0.005956\n",
       "brancofruta         0.005956\n",
       "chiron              0.005672\n",
       "bugatticor          0.005672\n",
       "para                0.005389\n",
       "carro               0.005389\n",
       "                      ...   \n",
       "botafogo            0.000284\n",
       "gra√ßas              0.000284\n",
       "5e26bo2s25          0.000284\n",
       "pqp                 0.000284\n",
       "mundial             0.000284\n",
       "xkgglqwab4          0.000284\n",
       "bilion√°rios         0.000284\n",
       "oi                  0.000284\n",
       "briguento           0.000284\n",
       "produto             0.000284\n",
       "vem                 0.000284\n",
       "ah                  0.000284\n",
       "fa4euuuew9galera    0.000284\n",
       "palestra            0.000284\n",
       "piatrizz            0.000284\n",
       "00gwich             0.000284\n",
       "sonhos              0.000284\n",
       "ultrapassa          0.000284\n",
       "ol√°                 0.000284\n",
       "recordista          0.000284\n",
       "59%                 0.000284\n",
       "cacete              0.000284\n",
       "s√©rie               0.000284\n",
       "claro               0.000284\n",
       "laqueira            0.000284\n",
       "n√∫mero              0.000284\n",
       "vvpa7uhlzf          0.000284\n",
       "7                   0.000284\n",
       "grande              0.000284\n",
       "blenheimpalace      0.000284\n",
       "Length: 1341, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palavras_nao_relevantes.value_counts(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance\n",
    "\n",
    "Agora voc√™ deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2962075848303393"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_relevante = palavras_relevantes.size/universo.size\n",
    "P_relevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7037924151696606"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_nao_relevante = palavras_nao_relevantes.size/universo.size\n",
    "P_nao_relevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw2 = pd.read_excel('Bugatti_teste.xlsx')\n",
    "relevante_teste_raw2 = raw2[raw2['Relev√¢ncia'] == 1]\n",
    "nao_relevante_teste_raw2 = raw2[raw2[\"Relev√¢ncia\"] == 0]\n",
    "\n",
    "lista1 = []\n",
    "for tweet in relevante_teste_raw2['Teste']:\n",
    "    texto = transform_emojis(tweet)\n",
    "    lista1.append(cleanup(texto))\n",
    "    \n",
    "relevante_teste = pd.Series(lista1)\n",
    "relevante_teste = relevante_teste.str.replace('|'.join(l),'',regex=True).str.strip()\n",
    "\n",
    "lista2 = []\n",
    "for tweet in nao_relevante_teste_raw2['Teste']:\n",
    "    texto = transform_emojis(tweet)\n",
    "    lista2.append(cleanup(texto))\n",
    "    \n",
    "nao_relevante_teste = pd.Series(lista2)\n",
    "nao_relevante_teste = nao_relevante_teste.str.replace('|'.join(l),'',regex=True).str.strip()\n",
    "\n",
    "lista3 = []\n",
    "for tweet in raw2['Teste']:\n",
    "    texto = transform_emojis(tweet)\n",
    "    lista3.append(cleanup(texto))\n",
    "    \n",
    "testudo = pd.Series(lista3)\n",
    "testudo = testudo.str.replace('|'.join(l),'',regex=True).str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lista4 = []\n",
    "for tweet in testudo:\n",
    "    lista4 = lista4 + tweet.split()\n",
    "\n",
    "universo_teste = pd.Series(lista4)\n",
    "universo_teste.value_counts()\n",
    "\n",
    "lista5 = []\n",
    "for tweet in relevante_teste:\n",
    "    lista5 = lista5 + tweet.split()\n",
    "\n",
    "palavras_relevantes_teste = pd.Series(lista5)\n",
    "P_R_T_R = palavras_relevantes_teste.value_counts(True)\n",
    "\n",
    "lista6 = []\n",
    "for tweet in nao_relevante_teste:\n",
    "    lista6 = lista6 + tweet.split()\n",
    "\n",
    "palavras_nao_relevantes_teste = pd.Series(lista6)\n",
    "P_N_R_T_R = palavras_nao_relevantes_teste.value_counts(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Montando o Classificardor Naive Bayes\n",
    "\n",
    "#### Probabilidades de ser relevante ou n√£o relevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              dirigida\n",
       "1                  pelo\n",
       "2                piloto\n",
       "3                  andy\n",
       "4               wallace\n",
       "5              vencedor\n",
       "6                    do\n",
       "7                grande\n",
       "8                pr√™mio\n",
       "9                    de\n",
       "10                   le\n",
       "11                 mans\n",
       "12                   em\n",
       "13                 1988\n",
       "14                  uma\n",
       "15              bugatti\n",
       "16               chiron\n",
       "17           ‚Äúlevemente\n",
       "18          modificada‚Äù\n",
       "19               chegou\n",
       "20                    a\n",
       "21      impressionantes\n",
       "22                  490\n",
       "23                  484\n",
       "24                 km/h\n",
       "25           0lnmllrds9\n",
       "26              bugatti\n",
       "27               chiron\n",
       "28                chega\n",
       "29                    a\n",
       "             ...       \n",
       "1346                ver\n",
       "1347             quanto\n",
       "1348              tempo\n",
       "1349                vai\n",
       "1350              levar\n",
       "1351                pra\n",
       "1352         koenigsegg\n",
       "1353                 se\n",
       "1354         pronunciar\n",
       "1355                  e\n",
       "1356              bater\n",
       "1357               esse\n",
       "1358            recorde\n",
       "1359               hehe\n",
       "1360                  a\n",
       "1361              quase\n",
       "1362                500\n",
       "1363               km/h\n",
       "1364            bugatti\n",
       "1365             chiron\n",
       "1366               vira\n",
       "1367                  o\n",
       "1368              carro\n",
       "1369                 de\n",
       "1370                rua\n",
       "1371               mais\n",
       "1372             r√°pido\n",
       "1373                 do\n",
       "1374              mundo\n",
       "1375         beyzg2gmlw\n",
       "Length: 1376, dtype: object"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palavras_relevantes_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       femalelionisa\n",
       "1             sqnpaty\n",
       "2                 sai\n",
       "3                 dai\n",
       "4              feiosa\n",
       "5                  eu\n",
       "6          represento\n",
       "7                kkkk\n",
       "8               avi√£o\n",
       "9              ahahah\n",
       "10         989k28qply\n",
       "11         kethllyn31\n",
       "12            bugatti\n",
       "13                  e\n",
       "14                uma\n",
       "15              marca\n",
       "16                 de\n",
       "17              carro\n",
       "18                n√£o\n",
       "19                  o\n",
       "20              carro\n",
       "21              geral\n",
       "22                 me\n",
       "23            olhando\n",
       "24                 no\n",
       "25         samuquinha\n",
       "26                 s√≥\n",
       "27                 pq\n",
       "28            cheguei\n",
       "29                com\n",
       "            ...      \n",
       "2010              que\n",
       "2011                √©\n",
       "2012             pior\n",
       "2013           algu√©m\n",
       "2014        acreditar\n",
       "2015              que\n",
       "2016                4\n",
       "2017         sal√°rios\n",
       "2018         incomoda\n",
       "2019       bilion√°rio\n",
       "2020               ou\n",
       "2021            achar\n",
       "2022              que\n",
       "2023               d√°\n",
       "2024              pra\n",
       "2025          comprar\n",
       "2026               um\n",
       "2027          bugatti\n",
       "2028              com\n",
       "2029             essa\n",
       "2030          mixaria\n",
       "2031       bt2rjrkwgx\n",
       "2032             fuga\n",
       "2033               de\n",
       "2034          bugatti\n",
       "2035              com\n",
       "2036              ela\n",
       "2037              dps\n",
       "2038              das\n",
       "2039                3\n",
       "Length: 2040, dtype: object"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palavras_nao_relevantes_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3416"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palavras_teste = palavras_relevantes_teste.size + palavras_nao_relevantes_teste.size\n",
    "palavras_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pt_relevante = relevante_teste.size / testudo.size\n",
    "Pt_relevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.62"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ptn_relevante = nao_relevante_teste.size / testudo.size\n",
    "Ptn_relevante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Como o classificador funcionar√°:\n",
    "\n",
    "Todos os tweets presentes na planilha de testes ser√£o, individualmente, analisados pelo classificador e catalogados, em um loop. Depois de todo esse processo, os resultados de cada tweet analisado, que podem ser ou \"Relevante\" ou \"Irrelevante\", pelo menos neste primeiro momento, ser√£o adicionados a uma lista com o fim de serem comparados com a an√°lise feita √† m√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bayes(relevancia,serie1,serie2):\n",
    "    #Criando o loop para o c√°lculo da probabilidade de ser relevante:\n",
    "    i = 0 \n",
    "    lista_resultados_numericos = []\n",
    "\n",
    "    #selecionando o tweet\n",
    "    for tweets in testudo:\n",
    "        \n",
    "        #transformando em lista de str\n",
    "        tweet = testudo[i]\n",
    "        tweetr = tweet.split()\n",
    "        \n",
    "        # Calculando a probabilidade deste tweet ser relevante dado as suas palavras\n",
    "        log_probabilidade = 0\n",
    "        for palavra in tweetr:\n",
    "        \n",
    "            #N√£o deixa que palavras n√£o pertencentes √† s√©rie bugem o c√≥digo\n",
    "            if palavra not in serie1:\n",
    "                log_probabilidade += math.log(1/3416, 10)\n",
    "            else:\n",
    "                log_probabilidade += math.log(serie2[palavra] + 1/3416, 10)\n",
    "        \n",
    "        #Guardando os resultados e resetando a vari√°vel probabilidade    \n",
    "        lista_resultados_numericos.append(log_probabilidade + math.log(relevancia, 10))\n",
    "        log_probabilidade = 0\n",
    "        i += 1\n",
    "\n",
    "    return lista_resultados_numericos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fuga', 'de', 'bugatti', 'com', 'ela', 'dps', 'das', '3']"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-28.68835929951893,\n",
       " -11.02076998943409,\n",
       " -35.75539502355286,\n",
       " -49.889466471620715,\n",
       " -92.2916808158243,\n",
       " -46.35594860960375,\n",
       " -56.95650219565464,\n",
       " -35.75539502355286,\n",
       " -56.95650219565464,\n",
       " -46.35594860960375,\n",
       " -78.15760936775644,\n",
       " -32.22187716153589,\n",
       " -145.29444874607876,\n",
       " -46.35594860960375,\n",
       " -32.22187716153589,\n",
       " -32.22187716153589,\n",
       " -102.89223440187519,\n",
       " -28.68835929951893,\n",
       " -53.42298433363768,\n",
       " -71.09057364372251,\n",
       " -42.822430747586786,\n",
       " -78.15760936775644,\n",
       " -60.49002005767161,\n",
       " -92.2916808158243,\n",
       " -85.22464509179036,\n",
       " -28.68835929951893,\n",
       " -74.62409150573947,\n",
       " -49.889466471620715,\n",
       " -39.28891288556982,\n",
       " -117.02630584994304,\n",
       " -18.087805713468025,\n",
       " -162.96203805616358,\n",
       " -46.35594860960375,\n",
       " -42.822430747586786,\n",
       " -124.09334157397697,\n",
       " -85.22464509179036,\n",
       " -71.09057364372251,\n",
       " -14.554287851451058,\n",
       " -28.68835929951893,\n",
       " -64.02353791968858,\n",
       " -39.28891288556982,\n",
       " -106.42575226389215,\n",
       " -25.15484143750196,\n",
       " -53.42298433363768,\n",
       " -32.22187716153589,\n",
       " -85.22464509179036,\n",
       " -42.822430747586786,\n",
       " -39.28891288556982,\n",
       " -53.42298433363768,\n",
       " -42.822430747586786,\n",
       " -95.82519867784126,\n",
       " -102.89223440187519,\n",
       " -49.889466471620715,\n",
       " -56.95650219565464,\n",
       " -64.02353791968858,\n",
       " -106.42575226389215,\n",
       " -46.35594860960375,\n",
       " -102.89223440187519,\n",
       " -14.554287851451058,\n",
       " -109.95927012590911,\n",
       " -32.22187716153589,\n",
       " -170.0290737801975,\n",
       " -78.15760936775644,\n",
       " -35.75539502355286,\n",
       " -109.95927012590911,\n",
       " -88.75816295380733,\n",
       " -28.68835929951893,\n",
       " -53.42298433363768,\n",
       " -109.95927012590911,\n",
       " -35.75539502355286,\n",
       " -7.487252127417124,\n",
       " -21.621323575484993,\n",
       " -64.02353791968858,\n",
       " -25.15484143750196,\n",
       " -49.889466471620715,\n",
       " -28.68835929951893,\n",
       " -39.28891288556982,\n",
       " -95.82519867784126,\n",
       " -71.09057364372251,\n",
       " -159.4285201941466,\n",
       " -18.087805713468025,\n",
       " -39.28891288556982,\n",
       " -141.7609308840618,\n",
       " -49.889466471620715,\n",
       " -46.35594860960375,\n",
       " -78.15760936775644,\n",
       " -14.554287851451058,\n",
       " -124.09334157397697,\n",
       " -32.22187716153589,\n",
       " -42.822430747586786,\n",
       " -21.621323575484993,\n",
       " -32.22187716153589,\n",
       " -28.68835929951893,\n",
       " -81.6911272297734,\n",
       " -14.554287851451058,\n",
       " -25.15484143750196,\n",
       " -184.16314522826536,\n",
       " -39.28891288556982,\n",
       " -21.621323575484993,\n",
       " -39.28891288556982,\n",
       " -71.09057364372251,\n",
       " -92.2916808158243,\n",
       " -14.554287851451058,\n",
       " -25.15484143750196,\n",
       " -71.09057364372251,\n",
       " -42.822430747586786,\n",
       " -18.087805713468025,\n",
       " -120.55982371196001,\n",
       " -46.35594860960375,\n",
       " -95.82519867784126,\n",
       " -102.89223440187519,\n",
       " -11.02076998943409,\n",
       " -21.621323575484993,\n",
       " -60.49002005767161,\n",
       " -11.02076998943409,\n",
       " -35.75539502355286,\n",
       " -25.15484143750196,\n",
       " -18.087805713468025,\n",
       " -25.15484143750196,\n",
       " -99.35871653985822,\n",
       " -81.6911272297734,\n",
       " -81.6911272297734,\n",
       " -81.6911272297734,\n",
       " -18.087805713468025,\n",
       " -81.6911272297734,\n",
       " -28.68835929951893,\n",
       " -28.68835929951893,\n",
       " -92.2916808158243,\n",
       " -14.554287851451058,\n",
       " -28.68835929951893,\n",
       " -53.42298433363768,\n",
       " -21.621323575484993,\n",
       " -28.68835929951893,\n",
       " -131.1603772980109,\n",
       " -117.02630584994304,\n",
       " -95.82519867784126,\n",
       " -56.95650219565464,\n",
       " -42.822430747586786,\n",
       " -46.35594860960375,\n",
       " -109.95927012590911,\n",
       " -109.95927012590911,\n",
       " -42.822430747586786,\n",
       " -95.82519867784126,\n",
       " -106.42575226389215,\n",
       " -25.15484143750196,\n",
       " -159.4285201941466,\n",
       " -46.35594860960375,\n",
       " -64.02353791968858,\n",
       " -60.49002005767161,\n",
       " -28.68835929951893,\n",
       " -25.15484143750196,\n",
       " -56.95650219565464,\n",
       " -46.35594860960375,\n",
       " -35.75539502355286,\n",
       " -71.09057364372251,\n",
       " -67.55705578170554,\n",
       " -42.822430747586786,\n",
       " -14.554287851451058,\n",
       " -88.75816295380733,\n",
       " -109.95927012590911,\n",
       " -113.49278798792608,\n",
       " -42.822430747586786,\n",
       " -39.28891288556982,\n",
       " -39.28891288556982,\n",
       " -81.6911272297734,\n",
       " -92.2916808158243,\n",
       " -25.15484143750196,\n",
       " -71.09057364372251,\n",
       " -28.68835929951893,\n",
       " -127.62685943599394,\n",
       " -21.621323575484993,\n",
       " -39.28891288556982,\n",
       " -159.4285201941466,\n",
       " -39.28891288556982,\n",
       " -64.02353791968858,\n",
       " -46.35594860960375,\n",
       " -177.09610950423144,\n",
       " -191.2301809522993,\n",
       " -64.02353791968858,\n",
       " -106.42575226389215,\n",
       " -46.35594860960375,\n",
       " -28.68835929951893,\n",
       " -32.22187716153589,\n",
       " -88.75816295380733,\n",
       " -18.087805713468025,\n",
       " -18.087805713468025,\n",
       " -25.15484143750196,\n",
       " -35.75539502355286,\n",
       " -28.68835929951893,\n",
       " -56.95650219565464,\n",
       " -74.62409150573947,\n",
       " -39.28891288556982,\n",
       " -78.15760936775644,\n",
       " -28.68835929951893,\n",
       " -88.75816295380733,\n",
       " -60.49002005767161,\n",
       " -53.42298433363768,\n",
       " -88.75816295380733,\n",
       " -56.95650219565464,\n",
       " -28.68835929951893]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista_resultados_numericos_relevantes = Bayes(Pt_relevante, palavras_relevantes_teste, P_R_T_R)\n",
    "lista_resultados_numericos_relevantes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-28.475751206637486,\n",
       " -10.808161896552646,\n",
       " -35.54278693067142,\n",
       " -49.676858378739276,\n",
       " -92.07907272294284,\n",
       " -46.14334051672231,\n",
       " -56.743894102773204,\n",
       " -35.54278693067142,\n",
       " -56.743894102773204,\n",
       " -46.14334051672231,\n",
       " -77.94500127487498,\n",
       " -32.009269068654454,\n",
       " -145.0818406531973,\n",
       " -46.14334051672231,\n",
       " -32.009269068654454,\n",
       " -32.009269068654454,\n",
       " -102.67962630899373,\n",
       " -28.475751206637486,\n",
       " -53.21037624075624,\n",
       " -70.87796555084105,\n",
       " -42.60982265470535,\n",
       " -77.94500127487498,\n",
       " -60.27741196479017,\n",
       " -92.07907272294284,\n",
       " -85.01203699890891,\n",
       " -28.475751206637486,\n",
       " -74.41148341285802,\n",
       " -49.676858378739276,\n",
       " -39.07630479268838,\n",
       " -116.81369775706159,\n",
       " -17.875197620586583,\n",
       " -162.74942996328213,\n",
       " -46.14334051672231,\n",
       " -42.60982265470535,\n",
       " -123.88073348109552,\n",
       " -85.01203699890891,\n",
       " -70.87796555084105,\n",
       " -14.341679758569613,\n",
       " -28.475751206637486,\n",
       " -63.81092982680713,\n",
       " -39.07630479268838,\n",
       " -106.2131441710107,\n",
       " -24.94223334462052,\n",
       " -53.21037624075624,\n",
       " -32.009269068654454,\n",
       " -85.01203699890891,\n",
       " -42.60982265470535,\n",
       " -39.07630479268838,\n",
       " -53.21037624075624,\n",
       " -42.60982265470535,\n",
       " -95.6125905849598,\n",
       " -102.67962630899373,\n",
       " -49.676858378739276,\n",
       " -56.743894102773204,\n",
       " -63.81092982680713,\n",
       " -106.2131441710107,\n",
       " -46.14334051672231,\n",
       " -102.67962630899373,\n",
       " -14.341679758569613,\n",
       " -109.74666203302766,\n",
       " -32.009269068654454,\n",
       " -169.81646568731605,\n",
       " -77.94500127487498,\n",
       " -35.54278693067142,\n",
       " -109.74666203302766,\n",
       " -88.54555486092588,\n",
       " -28.475751206637486,\n",
       " -53.21037624075624,\n",
       " -109.74666203302766,\n",
       " -35.54278693067142,\n",
       " -7.2746440345356795,\n",
       " -21.40871548260355,\n",
       " -63.81092982680713,\n",
       " -24.94223334462052,\n",
       " -49.676858378739276,\n",
       " -28.475751206637486,\n",
       " -39.07630479268838,\n",
       " -95.6125905849598,\n",
       " -70.87796555084105,\n",
       " -159.21591210126516,\n",
       " -17.875197620586583,\n",
       " -39.07630479268838,\n",
       " -141.54832279118034,\n",
       " -49.676858378739276,\n",
       " -46.14334051672231,\n",
       " -77.94500127487498,\n",
       " -14.341679758569613,\n",
       " -123.88073348109552,\n",
       " -32.009269068654454,\n",
       " -42.60982265470535,\n",
       " -21.40871548260355,\n",
       " -32.009269068654454,\n",
       " -28.475751206637486,\n",
       " -81.47851913689195,\n",
       " -14.341679758569613,\n",
       " -24.94223334462052,\n",
       " -183.9505371353839,\n",
       " -39.07630479268838,\n",
       " -21.40871548260355,\n",
       " -39.07630479268838,\n",
       " -70.87796555084105,\n",
       " -92.07907272294284,\n",
       " -14.341679758569613,\n",
       " -24.94223334462052,\n",
       " -70.87796555084105,\n",
       " -42.60982265470535,\n",
       " -17.875197620586583,\n",
       " -120.34721561907855,\n",
       " -46.14334051672231,\n",
       " -95.6125905849598,\n",
       " -102.67962630899373,\n",
       " -10.808161896552646,\n",
       " -21.40871548260355,\n",
       " -60.27741196479017,\n",
       " -10.808161896552646,\n",
       " -35.54278693067142,\n",
       " -24.94223334462052,\n",
       " -17.875197620586583,\n",
       " -24.94223334462052,\n",
       " -99.14610844697677,\n",
       " -81.47851913689195,\n",
       " -81.47851913689195,\n",
       " -81.47851913689195,\n",
       " -17.875197620586583,\n",
       " -81.47851913689195,\n",
       " -28.475751206637486,\n",
       " -28.475751206637486,\n",
       " -92.07907272294284,\n",
       " -14.341679758569613,\n",
       " -28.475751206637486,\n",
       " -53.21037624075624,\n",
       " -21.40871548260355,\n",
       " -28.475751206637486,\n",
       " -130.94776920512945,\n",
       " -116.81369775706159,\n",
       " -95.6125905849598,\n",
       " -56.743894102773204,\n",
       " -42.60982265470535,\n",
       " -46.14334051672231,\n",
       " -109.74666203302766,\n",
       " -109.74666203302766,\n",
       " -42.60982265470535,\n",
       " -95.6125905849598,\n",
       " -106.2131441710107,\n",
       " -24.94223334462052,\n",
       " -159.21591210126516,\n",
       " -46.14334051672231,\n",
       " -63.81092982680713,\n",
       " -60.27741196479017,\n",
       " -28.475751206637486,\n",
       " -24.94223334462052,\n",
       " -56.743894102773204,\n",
       " -46.14334051672231,\n",
       " -35.54278693067142,\n",
       " -70.87796555084105,\n",
       " -67.34444768882409,\n",
       " -42.60982265470535,\n",
       " -14.341679758569613,\n",
       " -88.54555486092588,\n",
       " -109.74666203302766,\n",
       " -113.28017989504463,\n",
       " -42.60982265470535,\n",
       " -39.07630479268838,\n",
       " -39.07630479268838,\n",
       " -81.47851913689195,\n",
       " -92.07907272294284,\n",
       " -24.94223334462052,\n",
       " -70.87796555084105,\n",
       " -28.475751206637486,\n",
       " -127.41425134311248,\n",
       " -21.40871548260355,\n",
       " -39.07630479268838,\n",
       " -159.21591210126516,\n",
       " -39.07630479268838,\n",
       " -63.81092982680713,\n",
       " -46.14334051672231,\n",
       " -176.88350141134998,\n",
       " -191.01757285941784,\n",
       " -63.81092982680713,\n",
       " -106.2131441710107,\n",
       " -46.14334051672231,\n",
       " -28.475751206637486,\n",
       " -32.009269068654454,\n",
       " -88.54555486092588,\n",
       " -17.875197620586583,\n",
       " -17.875197620586583,\n",
       " -24.94223334462052,\n",
       " -35.54278693067142,\n",
       " -28.475751206637486,\n",
       " -56.743894102773204,\n",
       " -74.41148341285802,\n",
       " -39.07630479268838,\n",
       " -77.94500127487498,\n",
       " -28.475751206637486,\n",
       " -88.54555486092588,\n",
       " -60.27741196479017,\n",
       " -53.21037624075624,\n",
       " -88.54555486092588,\n",
       " -56.743894102773204,\n",
       " -28.475751206637486]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista_resultados_numericos_nrelevantes = Bayes(Ptn_relevante, palavras_nao_relevantes_teste, P_N_R_T_R)\n",
    "lista_resultados_numericos_nrelevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "lista_resultados = []\n",
    "for tweet in testudo:\n",
    "    \n",
    "    if lista_resultados_numericos_relevantes[i] > lista_resultados_numericos_nrelevantes[i]:\n",
    "           lista_resultados.append(\"Relevante\")\n",
    "            \n",
    "    if lista_resultados_numericos_relevantes[i] == lista_resultados_numericos_nrelevantes[i]:\n",
    "        lista_resultados.append(\"Neutro\")\n",
    "        \n",
    "    if lista_resultados_numericos_relevantes[i] < lista_resultados_numericos_nrelevantes[i]:\n",
    "        lista_resultados.append(\"N√£o relevante\")\n",
    "        \n",
    "    i += 1\n",
    "    \n",
    "#lista_resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "i=0\n",
    "cu=[]\n",
    "\n",
    "for tweet in testudo:\n",
    "    cu.append(lista_resultados_numericos_relevantes[i] / lista_resultados_numericos_nrelevantes[i])\n",
    "cu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aperfei√ßoamento:\n",
    "\n",
    "Os trabalhos v√£o evoluir em conceito dependendo da quantidade de itens avan√ßados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separa√ß√£o de espa√ßos entre palavras e emojis ou emojis e emojis\n",
    "* Propor outras limpezas e transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o ou classifica√ß√£o\n",
    "* Criar categorias intermedi√°rias de relev√¢ncia baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que n√£o posso usar o pr√≥prio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cen√°rios para Na√Øve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indica√ß√µes concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que periodicamente realiza an√°lise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refer√™ncias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
