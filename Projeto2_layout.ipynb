{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nome: Breno Marti**\n",
    "\n",
    "**Nome: João Pedro Chacon Ruiz**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Serão permitidos grupos de três pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisarão fazer um questionário de avaliação de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Classificador automático de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando o ambiente no jupyter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "#Instalando o tweepy\n",
    "!pip install tweepy\n",
    "!pip install emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Autenticando no  Twitter\n",
    "\n",
    "* Conta: ***[Preencha aqui o id da sua conta. Ex: @fulano ]***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#Dados de autenticação do twitter:\\n\\n#Coloque aqui o identificador da conta no twitter: @fulano\\n\\n#leitura do arquivo no formato JSON\\nwith open('auth.pass') as fp:    \\n    data = json.load(fp)\\n\\n#Configurando a biblioteca. Não modificar\\nauth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\\nauth.set_access_token(data['access_token'], data['access_token_secret'])\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#Dados de autenticação do twitter:\n",
    "\n",
    "#Coloque aqui o identificador da conta no twitter: @fulano\n",
    "\n",
    "#leitura do arquivo no formato JSON\n",
    "with open('auth.pass') as fp:    \n",
    "    data = json.load(fp)\n",
    "\n",
    "#Configurando a biblioteca. Não modificar\n",
    "auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "auth.set_access_token(data['access_token'], data['access_token_secret'])\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Etapas do projeto:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escolha de um produto e coleta das mensagens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Produto escolhido:\n",
    "produto = 'Bugatti'\n",
    "\n",
    "#Quantidade mínima de mensagens capturadas:\n",
    "n = 500\n",
    "#Quantidade mínima de mensagens para a base de treinamento:\n",
    "t = 300\n",
    "\n",
    "#Filtro de língua, escolha uma na tabela ISO 639-1.\n",
    "lang = 'pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturando os dados do twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#Cria um objeto para a captura\\napi = tweepy.API(auth)\\n\\n#Inicia a captura, para mais detalhes: ver a documentação do tweepy\\ni = 1\\nmsgs = []\\nfor msg in tweepy.Cursor(api.search, q=produto, lang=lang, tweet_mode=\"extended\").items():\\n    if (not msg.retweeted) and (\\'RT\\' not in msg.full_text):\\n        msgs.append(msg.full_text.lower())\\n        i += 1\\n    if i > n:\\n        break\\n\\n#Embaralhando as mensagens para reduzir um possível viés\\nshuffle(msgs\\'\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#Cria um objeto para a captura\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "#Inicia a captura, para mais detalhes: ver a documentação do tweepy\n",
    "i = 1\n",
    "msgs = []\n",
    "for msg in tweepy.Cursor(api.search, q=produto, lang=lang, tweet_mode=\"extended\").items():\n",
    "    if (not msg.retweeted) and ('RT' not in msg.full_text):\n",
    "        msgs.append(msg.full_text.lower())\n",
    "        i += 1\n",
    "    if i > n:\n",
    "        break\n",
    "\n",
    "#Embaralhando as mensagens para reduzir um possível viés\n",
    "shuffle(msgs'\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando os dados em uma planilha Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#Verifica se o arquivo não existe para não substituir um conjunto pronto\\nif not os.path.isfile('./{0}.xlsx'.format(produto)):\\n    \\n    #Abre o arquivo para escrita\\n    writer = pd.ExcelWriter('{0}.xlsx'.format(produto))\\n\\n    #divide o conjunto de mensagens em duas planilhas\\n    dft = pd.DataFrame({'Treinamento' : pd.Series(msgs[:t])})\\n    dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\\n\\n    dfc = pd.DataFrame({'Teste' : pd.Series(msgs[t:])})\\n    dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\\n\\n    #fecha o arquivo\\n    writer.save()\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#Verifica se o arquivo não existe para não substituir um conjunto pronto\n",
    "if not os.path.isfile('./{0}.xlsx'.format(produto)):\n",
    "    \n",
    "    #Abre o arquivo para escrita\n",
    "    writer = pd.ExcelWriter('{0}.xlsx'.format(produto))\n",
    "\n",
    "    #divide o conjunto de mensagens em duas planilhas\n",
    "    dft = pd.DataFrame({'Treinamento' : pd.Series(msgs[:t])})\n",
    "    dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "\n",
    "    dfc = pd.DataFrame({'Teste' : pd.Series(msgs[t:])})\n",
    "    dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\n",
    "\n",
    "    #fecha o arquivo\n",
    "    writer.save()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Classificando as mensagens na coragem\n",
    "\n",
    "Esta etapa é manual. Faça a mesma pelo Excel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando o Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = pd.read_excel('Bugatti_treino.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevante_treino_raw = raw[raw['Relevância'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nao_relevante_treino_raw = raw[raw[\"Relevância\"] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funções de limpeza de texto:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "def cleanup(text):\n",
    "    \"\"\"\n",
    "        Função de limpeza muito simples que troca alguns sinais básicos por espaços\n",
    "    \"\"\"\n",
    "    punctuation = '[#@,!\\()-.€\":?;]' # Note que os sinais [] são delimitadores de um conjunto.\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, ' ', text)\n",
    "    return text_subbed   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_emojis(text):\n",
    "    clean = emojis.decode(text)\n",
    "    return clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Limpando e transformando os dataframes em séries para a análise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = ['\\n','https','//t','co/']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = []\n",
    "for tweet in relevante_treino_raw['Treinamento']:\n",
    "    texto = transform_emojis(tweet)\n",
    "    list1.append(cleanup(texto))\n",
    "    \n",
    "relevante_treino = pd.Series(list1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nota do professor: explicar como o código abaixo funciona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     mds cade a koenigsegg pra bater esses 500km/h ...\n",
       "1     bugatti bate recorde de velocidade com um carr...\n",
       "2     depois de bater o próprio recorde de 490 km/h ...\n",
       "3     podem não ser os mais bonitos  mas os carros d...\n",
       "4     parece que teremos o bugatti chiron super spor...\n",
       "5     bugatti descobriu o quão rápido o chiron é  fl...\n",
       "6     bugatti chiron com velocidade final de 490 km/...\n",
       "7      quase 500 kph em um carro  absurdo    cahutq6joi\n",
       "8     tô pesquisando uns carros luxuosos aqui e perc...\n",
       "9     após 490 km/h do chiron  bugatti anuncia que n...\n",
       "10    bugatti chiron super sport 300   versão  civil...\n",
       "11    bugatti ultrapassa a marca dos 480 km/h – e de...\n",
       "12    bugatti quebra o recorde de velocidade com um ...\n",
       "13    bugatti chiron chega a 490 km/h e bate recorde...\n",
       "14    carro mais rápido do mundo  nova bugatti terá ...\n",
       "15    williamenb outra coisa  porque aquele bugatti ...\n",
       "16    wow  a bugatti chiron chegou a 490 km/h    iss...\n",
       "17    bugatti chiron  levemente modificada  chegou a...\n",
       "18    bugatti chiron super sport 300  chega a 440 km...\n",
       "19    williamenb agora tá ficando divertido essa bri...\n",
       "20    bugatti chiron super sport 300  chega a 440 km...\n",
       "21    veja como o bugatti chiron quase bateu a barre...\n",
       "22    bugatti chiron chega aos 490 48 km/h e quebra ...\n",
       "23    mano    490 km/h    chegou um momento que eu a...\n",
       "24    um carro  de rua  que atingiu 490 48 km/h    p...\n",
       "25    williamenb mas será que esses 483 km/h não são...\n",
       "26       e o bugatti chiron que chegou a 490 km/h   o o\n",
       "27    eu to incrédulo que a bugatti conseguiu chegar...\n",
       "28    a bugatti alterou um chiron para bater os 490 ...\n",
       "29    o piloto de testes da bugatti  andy wallace  a...\n",
       "                            ...                        \n",
       "44    assista ao bugatti chiron esmagar a mítica bar...\n",
       "45    o bugatti chiron sport acabou de bater o recor...\n",
       "46    fg_genuino  pauloramos1 o carro mais caro do m...\n",
       "47     o novo bugatti chiron bateu só 490 km/h está bom\n",
       "48    não da nem pra acreditar que o bugatti chiron ...\n",
       "49    segundou com recordes   red_car o bugatti chir...\n",
       "50    acabei de descobrir q uma bugatti conseguiu ch...\n",
       "51    menino christian tomando coro da bugatti mais ...\n",
       "52    pqq a bugatti não fabrica avião logo  a porra ...\n",
       "53    parabéns a bugatti por fazer 490 48km/h cm o c...\n",
       "54    curiosidades  você sabia que bugatti chiron é ...\n",
       "55    bugatti bateu novamente o recorde de velocidad...\n",
       "56    recordista mundial de velocidade em versão “ci...\n",
       "57    bugatti falando que a velocidade do protótipo ...\n",
       "58    williamenb esse bugatti é alguma versão especi...\n",
       "59    bugatti chiron alcança 490 km/h e bate recorde...\n",
       "60             a bugatti sabe fazer carro  vai se fuder\n",
       "61    como assim a bugatti chegou aos 490km/h com o ...\n",
       "62    sadeiji mano koenigsegg q é feio mano  bugatti...\n",
       "63    a bugatti anunciou q n vai mais quebrar o reco...\n",
       "64    bem    a bugatti bateu novamente o recorde de ...\n",
       "65    bugatti chiron chega a 490 km/h e bate recorde...\n",
       "66    bugatti bateu o record de velocidade     490km...\n",
       "67    alguém precisa demitir o designer seja lá nome...\n",
       "68    bugatti chiron super sport 300  chega a 440 km...\n",
       "69    a quase 500 km/h  bugatti chiron vira o carro ...\n",
       "70    recorde mundial para bugatti   um veículo de p...\n",
       "71    williamenb sei que sou fan boy da bugatti  mas...\n",
       "72    me pergunto que tipo de pneu usaram no chiron ...\n",
       "73    o bugatti chiron é de novo o carro mais rápido...\n",
       "Length: 74, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevante_treino = relevante_treino.str.replace('|'.join(l),'',regex=True).str.strip()\n",
    "relevante_treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "list2 = []\n",
    "for tweet in nao_relevante_treino_raw['Treinamento']:\n",
    "    texto = transform_emojis(tweet)\n",
    "    list2.append(cleanup(texto))\n",
    "    \n",
    "nao_relevante_treino = pd.Series(list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      talla 42 eu  bugatti 3 11382e 11  botas clasic...\n",
       "1      talla 40 eu  bugatti 3 11384e 11  botas clasic...\n",
       "2      carolinaazered2  junior__bugatti com o bumbum ...\n",
       "3                fuga de bugatti com ela depois das três\n",
       "4      bugatti verón supersport motor triturbo 8 0 l ...\n",
       "5      el nuevo récord de velocidad del bugatti chiro...\n",
       "6      se continuar esse calor vai todo mundo derrete...\n",
       "7                                 lleobertodo menino bom\n",
       "8      gente vamos jogar stop  não vale olhar na inte...\n",
       "9      aberto até de madrugada  bugatti chiron chega ...\n",
       "10     gente vamos jogar stop  não vale olhar na inte...\n",
       "11     luaracaastro desse jeito  daqui a pouco volta ...\n",
       "12                    jenniferbraaga uma delicinha kkkkk\n",
       "13                              paloma_souza18 foi ontem\n",
       "14     ballerichh claro q  lembro alugamos um  bugatt...\n",
       "15     mas eu conseguiria trazer um suco gástrico esp...\n",
       "16              ofereçam me um bugatti  não peço mais xd\n",
       "17     iamthebrunao tomara q não  acho bugatti mais foda\n",
       "18          ir ou não ir no bugatti sexta  eis a questão\n",
       "19        quero foder num bugatti e um dia vai acontecer\n",
       "20     gente vamos jogar stop  não vale olhar na inte...\n",
       "21     talla 43 eu  bugatti 3 11384e 11  botas clasic...\n",
       "22           karist0n pq seu apelido tinha q ser bugatti\n",
       "23     talla 43 eu  bugatti 3 11384e 11  botas clasic...\n",
       "24            fhbugatti carai bugatti ce ja jogou inside\n",
       "25     paloma_souza18  ribeirohthais  igorrealequatro...\n",
       "26     luaracaastro enquanto isso vou bebendo minha c...\n",
       "27     use a primeira letra do seu nome e responda  n...\n",
       "28     ahhh  também tem 2 sons nossos que tão beirand...\n",
       "29     manoooos eu quero um gtr também portanto podem...\n",
       "                             ...                        \n",
       "196    bbrendabreu quem usa isso não sabe nem oq é bi...\n",
       "197                       yuri_bugatti vc e exceção more\n",
       "198    opatata22 só acho que você está muito sóbria f...\n",
       "199             yuri_bugatti  arrasou kkkkk   11hlk7jwm6\n",
       "200    gente vamos jogar stop  não vale olhar na inte...\n",
       "201    nome  brunalugar  barbebida  bacardicomida  ba...\n",
       "202    fredsilvered se bugatti fosse boa se chamaria ...\n",
       "203    a gente tenta né  joy  cold_sweat  car  arte  ...\n",
       "204                               aguiiarr_ kkkkkk pleno\n",
       "205      preciozoroberta decepção  facepalm 🏽‍ male_sign\n",
       "206                 junior__bugatti kkkkkkkkkkk sem mais\n",
       "207    nome  beatrizlugar  brasil bebida  balalaikaco...\n",
       "208    vai na festa dia 13  — mas isso é certo       ...\n",
       "209          queria estar dirigindo o bugatti q eu gosto\n",
       "210    ferrari 812gts  bugatti  ferrari  porsche  car...\n",
       "211    pqp bugatti conseguiu quebrar o recorde de vel...\n",
       "212    gente vamos jogar stop  não vale olhar na inte...\n",
       "213    yuri_bugatti olocooo logo ele que não batia em...\n",
       "214    a amiga me falou um bglh hj e a vontade foi de...\n",
       "215    fuga de bugatti com ela depois das 3  ela me p...\n",
       "216    crl2m  alanalves899  alvesmaary82 qual é o teu...\n",
       "217    dr_diogorocha_ o bugatti não tem hipótese cont...\n",
       "218    davidakabadao gostas de meter a 7 ª mudança é ...\n",
       "219    primeira vitória de um monegasco na itália des...\n",
       "220    já peguei ônibus lotado  agora eu quero bugatt...\n",
       "221                                  bom dia é o caralho\n",
       "222                        vai ser de enjoar das bugatti\n",
       "223    quer dá um role a 490 km/h      hfizt7txki bug...\n",
       "224    ponteiro da bugatti estourou esse final de semana\n",
       "225    kotabrunoag só mesmo  tocar “mocita”  “pintin”...\n",
       "Length: 226, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nao_relevante_treino = nao_relevante_treino.str.replace('|'.join(l),'',regex=True).str.strip()\n",
    "nao_relevante_treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "list3 = []\n",
    "for tweet in raw['Treinamento']:\n",
    "    texto = transform_emojis(tweet)\n",
    "    list3.append(cleanup(texto))\n",
    "    \n",
    "tudo = pd.Series(list3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      talla 42 eu  bugatti 3 11382e 11  botas clasic...\n",
       "1      talla 40 eu  bugatti 3 11384e 11  botas clasic...\n",
       "2      carolinaazered2  junior__bugatti com o bumbum ...\n",
       "3      mds cade a koenigsegg pra bater esses 500km/h ...\n",
       "4      bugatti bate recorde de velocidade com um carr...\n",
       "5                fuga de bugatti com ela depois das três\n",
       "6      bugatti verón supersport motor triturbo 8 0 l ...\n",
       "7      el nuevo récord de velocidad del bugatti chiro...\n",
       "8      se continuar esse calor vai todo mundo derrete...\n",
       "9      depois de bater o próprio recorde de 490 km/h ...\n",
       "10                                lleobertodo menino bom\n",
       "11     gente vamos jogar stop  não vale olhar na inte...\n",
       "12     podem não ser os mais bonitos  mas os carros d...\n",
       "13     aberto até de madrugada  bugatti chiron chega ...\n",
       "14     gente vamos jogar stop  não vale olhar na inte...\n",
       "15     luaracaastro desse jeito  daqui a pouco volta ...\n",
       "16                    jenniferbraaga uma delicinha kkkkk\n",
       "17                              paloma_souza18 foi ontem\n",
       "18     parece que teremos o bugatti chiron super spor...\n",
       "19     ballerichh claro q  lembro alugamos um  bugatt...\n",
       "20     mas eu conseguiria trazer um suco gástrico esp...\n",
       "21              ofereçam me um bugatti  não peço mais xd\n",
       "22     iamthebrunao tomara q não  acho bugatti mais foda\n",
       "23          ir ou não ir no bugatti sexta  eis a questão\n",
       "24        quero foder num bugatti e um dia vai acontecer\n",
       "25     bugatti descobriu o quão rápido o chiron é  fl...\n",
       "26     gente vamos jogar stop  não vale olhar na inte...\n",
       "27     talla 43 eu  bugatti 3 11384e 11  botas clasic...\n",
       "28           karist0n pq seu apelido tinha q ser bugatti\n",
       "29     bugatti chiron com velocidade final de 490 km/...\n",
       "                             ...                        \n",
       "270    vai na festa dia 13  — mas isso é certo       ...\n",
       "271    sadeiji mano koenigsegg q é feio mano  bugatti...\n",
       "272    a bugatti anunciou q n vai mais quebrar o reco...\n",
       "273          queria estar dirigindo o bugatti q eu gosto\n",
       "274    bem    a bugatti bateu novamente o recorde de ...\n",
       "275    ferrari 812gts  bugatti  ferrari  porsche  car...\n",
       "276    pqp bugatti conseguiu quebrar o recorde de vel...\n",
       "277    bugatti chiron chega a 490 km/h e bate recorde...\n",
       "278    gente vamos jogar stop  não vale olhar na inte...\n",
       "279    yuri_bugatti olocooo logo ele que não batia em...\n",
       "280    a amiga me falou um bglh hj e a vontade foi de...\n",
       "281    fuga de bugatti com ela depois das 3  ela me p...\n",
       "282    crl2m  alanalves899  alvesmaary82 qual é o teu...\n",
       "283    dr_diogorocha_ o bugatti não tem hipótese cont...\n",
       "284    bugatti bateu o record de velocidade     490km...\n",
       "285    alguém precisa demitir o designer seja lá nome...\n",
       "286    bugatti chiron super sport 300  chega a 440 km...\n",
       "287    a quase 500 km/h  bugatti chiron vira o carro ...\n",
       "288    recorde mundial para bugatti   um veículo de p...\n",
       "289    davidakabadao gostas de meter a 7 ª mudança é ...\n",
       "290    primeira vitória de um monegasco na itália des...\n",
       "291    já peguei ônibus lotado  agora eu quero bugatt...\n",
       "292                                  bom dia é o caralho\n",
       "293    williamenb sei que sou fan boy da bugatti  mas...\n",
       "294                        vai ser de enjoar das bugatti\n",
       "295    me pergunto que tipo de pneu usaram no chiron ...\n",
       "296    quer dá um role a 490 km/h      hfizt7txki bug...\n",
       "297    ponteiro da bugatti estourou esse final de semana\n",
       "298    kotabrunoag só mesmo  tocar “mocita”  “pintin”...\n",
       "299    o bugatti chiron é de novo o carro mais rápido...\n",
       "Length: 300, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tudo = tudo.str.replace('|'.join(l),'',regex=True).str.strip()\n",
    "tudo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contando o número de aparições de cada palavra :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bugatti             223\n",
       "de                  128\n",
       "a                   124\n",
       "o                   119\n",
       "que                  75\n",
       "um                   74\n",
       "e                    69\n",
       "do                   67\n",
       "chiron               65\n",
       "não                  62\n",
       "na                   55\n",
       "km/h                 46\n",
       "carro                46\n",
       "nome                 40\n",
       "490                  40\n",
       "eu                   39\n",
       "é                    39\n",
       "com                  37\n",
       "em                   35\n",
       "mais                 33\n",
       "primeira             33\n",
       "seu                  30\n",
       "letra                26\n",
       "para                 26\n",
       "gente                26\n",
       "por                  25\n",
       "velocidade           24\n",
       "da                   24\n",
       "bananaobjeto         23\n",
       "recorde              23\n",
       "                   ... \n",
       "deitar                1\n",
       "velho                 1\n",
       "jenniferbraaga        1\n",
       "tenta                 1\n",
       "kkkkkkkk              1\n",
       "more                  1\n",
       "impressionante        1\n",
       "exploding_head        1\n",
       "derreter              1\n",
       "y8wid57fjp            1\n",
       "brumadinhobebida      1\n",
       "fixando               1\n",
       "olha                  1\n",
       "afro                  1\n",
       "sorte                 1\n",
       "ontem                 1\n",
       "bacateobjeto          1\n",
       "todas                 1\n",
       "evitar                1\n",
       "ias                   1\n",
       "modificado            1\n",
       "yxhb3smvyb            1\n",
       "obxz73heuf            1\n",
       "tiver                 1\n",
       "breve                 1\n",
       "ngcbjnguf9            1\n",
       "sunglasses            1\n",
       "rica                  1\n",
       "monaa                 1\n",
       "blenheimpalace        1\n",
       "Length: 1676, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list4 = []\n",
    "for tweet in tudo:\n",
    "    list4 = list4 + tweet.split()\n",
    "\n",
    "universo = pd.Series(list4)\n",
    "universo.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bugatti         76\n",
       "o               55\n",
       "a               53\n",
       "de              52\n",
       "chiron          45\n",
       "km/h            38\n",
       "490             31\n",
       "que             31\n",
       "carro           27\n",
       "um              26\n",
       "do              23\n",
       "em              22\n",
       "velocidade      20\n",
       "mais            20\n",
       "recorde         19\n",
       "e               17\n",
       "com             15\n",
       "é               15\n",
       "não             14\n",
       "da              13\n",
       "300             11\n",
       "mph             10\n",
       "sport           10\n",
       "os               9\n",
       "super            8\n",
       "mundial          8\n",
       "chega            8\n",
       "rápido           7\n",
       "por              7\n",
       "500              7\n",
       "                ..\n",
       "distintas        1\n",
       "absurdamente     1\n",
       "cima             1\n",
       "600              1\n",
       "ye7je7pxvg       1\n",
       "83avneux8y       1\n",
       "vendido          1\n",
       "saídas           1\n",
       "andy             1\n",
       "barrier          1\n",
       "tomando          1\n",
       "primeira         1\n",
       "teria            1\n",
       "sem              1\n",
       "conhecidos       1\n",
       "insano           1\n",
       "qse              1\n",
       "out              1\n",
       "parabéns         1\n",
       "pqp              1\n",
       "momento          1\n",
       "foda             1\n",
       "repost           1\n",
       "305              1\n",
       "seja             1\n",
       "estrondosos      1\n",
       "fudeeer          1\n",
       "pneu             1\n",
       "pode             1\n",
       "fixando          1\n",
       "Length: 522, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list5 = []\n",
    "for tweet in relevante_treino:\n",
    "    list5 = list5 + tweet.split()\n",
    "\n",
    "palavras_relevantes = pd.Series(list5)\n",
    "palavras_relevantes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bugatti             147\n",
       "de                   76\n",
       "a                    71\n",
       "o                    64\n",
       "e                    52\n",
       "na                   49\n",
       "um                   48\n",
       "não                  48\n",
       "que                  44\n",
       "do                   44\n",
       "nome                 39\n",
       "primeira             32\n",
       "eu                   32\n",
       "seu                  29\n",
       "letra                26\n",
       "gente                25\n",
       "é                    24\n",
       "bananaobjeto         23\n",
       "vale                 22\n",
       "olhar                22\n",
       "com                  22\n",
       "vamos                22\n",
       "jogar                22\n",
       "stop                 21\n",
       "respondanome         21\n",
       "brancofruta          21\n",
       "chiron               20\n",
       "bugatticor           20\n",
       "para                 19\n",
       "carro                19\n",
       "                   ... \n",
       "botafogo              1\n",
       "graças                1\n",
       "5e26bo2s25            1\n",
       "pqp                   1\n",
       "mundial               1\n",
       "xkgglqwab4            1\n",
       "bilionários           1\n",
       "oi                    1\n",
       "briguento             1\n",
       "produto               1\n",
       "vem                   1\n",
       "ah                    1\n",
       "fa4euuuew9galera      1\n",
       "palestra              1\n",
       "piatrizz              1\n",
       "00gwich               1\n",
       "sonhos                1\n",
       "ultrapassa            1\n",
       "olá                   1\n",
       "recordista            1\n",
       "59%                   1\n",
       "cacete                1\n",
       "série                 1\n",
       "claro                 1\n",
       "laqueira              1\n",
       "número                1\n",
       "vvpa7uhlzf            1\n",
       "7                     1\n",
       "grande                1\n",
       "blenheimpalace        1\n",
       "Length: 1341, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list6 = []\n",
    "for tweet in nao_relevante_treino:\n",
    "    list6 = list6 + tweet.split()\n",
    "\n",
    "palavras_nao_relevantes = pd.Series(list6)\n",
    "palavras_nao_relevantes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frequência relativa de cada palavra:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bugatti             0.044511\n",
       "de                  0.025549\n",
       "a                   0.024750\n",
       "o                   0.023752\n",
       "que                 0.014970\n",
       "um                  0.014770\n",
       "e                   0.013772\n",
       "do                  0.013373\n",
       "chiron              0.012974\n",
       "não                 0.012375\n",
       "na                  0.010978\n",
       "km/h                0.009182\n",
       "carro               0.009182\n",
       "nome                0.007984\n",
       "490                 0.007984\n",
       "eu                  0.007784\n",
       "é                   0.007784\n",
       "com                 0.007385\n",
       "em                  0.006986\n",
       "mais                0.006587\n",
       "primeira            0.006587\n",
       "seu                 0.005988\n",
       "letra               0.005190\n",
       "para                0.005190\n",
       "gente               0.005190\n",
       "por                 0.004990\n",
       "velocidade          0.004790\n",
       "da                  0.004790\n",
       "bananaobjeto        0.004591\n",
       "recorde             0.004591\n",
       "                      ...   \n",
       "deitar              0.000200\n",
       "velho               0.000200\n",
       "jenniferbraaga      0.000200\n",
       "tenta               0.000200\n",
       "kkkkkkkk            0.000200\n",
       "more                0.000200\n",
       "impressionante      0.000200\n",
       "exploding_head      0.000200\n",
       "derreter            0.000200\n",
       "y8wid57fjp          0.000200\n",
       "brumadinhobebida    0.000200\n",
       "fixando             0.000200\n",
       "olha                0.000200\n",
       "afro                0.000200\n",
       "sorte               0.000200\n",
       "ontem               0.000200\n",
       "bacateobjeto        0.000200\n",
       "todas               0.000200\n",
       "evitar              0.000200\n",
       "ias                 0.000200\n",
       "modificado          0.000200\n",
       "yxhb3smvyb          0.000200\n",
       "obxz73heuf          0.000200\n",
       "tiver               0.000200\n",
       "breve               0.000200\n",
       "ngcbjnguf9          0.000200\n",
       "sunglasses          0.000200\n",
       "rica                0.000200\n",
       "monaa               0.000200\n",
       "blenheimpalace      0.000200\n",
       "Length: 1676, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "universo.value_counts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bugatti         0.051213\n",
       "o               0.037062\n",
       "a               0.035714\n",
       "de              0.035040\n",
       "chiron          0.030323\n",
       "km/h            0.025606\n",
       "490             0.020889\n",
       "que             0.020889\n",
       "carro           0.018194\n",
       "um              0.017520\n",
       "do              0.015499\n",
       "em              0.014825\n",
       "velocidade      0.013477\n",
       "mais            0.013477\n",
       "recorde         0.012803\n",
       "e               0.011456\n",
       "com             0.010108\n",
       "é               0.010108\n",
       "não             0.009434\n",
       "da              0.008760\n",
       "300             0.007412\n",
       "mph             0.006739\n",
       "sport           0.006739\n",
       "os              0.006065\n",
       "super           0.005391\n",
       "mundial         0.005391\n",
       "chega           0.005391\n",
       "rápido          0.004717\n",
       "por             0.004717\n",
       "500             0.004717\n",
       "                  ...   \n",
       "distintas       0.000674\n",
       "absurdamente    0.000674\n",
       "cima            0.000674\n",
       "600             0.000674\n",
       "ye7je7pxvg      0.000674\n",
       "83avneux8y      0.000674\n",
       "vendido         0.000674\n",
       "saídas          0.000674\n",
       "andy            0.000674\n",
       "barrier         0.000674\n",
       "tomando         0.000674\n",
       "primeira        0.000674\n",
       "teria           0.000674\n",
       "sem             0.000674\n",
       "conhecidos      0.000674\n",
       "insano          0.000674\n",
       "qse             0.000674\n",
       "out             0.000674\n",
       "parabéns        0.000674\n",
       "pqp             0.000674\n",
       "momento         0.000674\n",
       "foda            0.000674\n",
       "repost          0.000674\n",
       "305             0.000674\n",
       "seja            0.000674\n",
       "estrondosos     0.000674\n",
       "fudeeer         0.000674\n",
       "pneu            0.000674\n",
       "pode            0.000674\n",
       "fixando         0.000674\n",
       "Length: 522, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palavras_relevantes.value_counts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bugatti             0.041690\n",
       "de                  0.021554\n",
       "a                   0.020136\n",
       "o                   0.018151\n",
       "e                   0.014748\n",
       "na                  0.013897\n",
       "um                  0.013613\n",
       "não                 0.013613\n",
       "que                 0.012479\n",
       "do                  0.012479\n",
       "nome                0.011061\n",
       "primeira            0.009075\n",
       "eu                  0.009075\n",
       "seu                 0.008225\n",
       "letra               0.007374\n",
       "gente               0.007090\n",
       "é                   0.006807\n",
       "bananaobjeto        0.006523\n",
       "vale                0.006239\n",
       "olhar               0.006239\n",
       "com                 0.006239\n",
       "vamos               0.006239\n",
       "jogar               0.006239\n",
       "stop                0.005956\n",
       "respondanome        0.005956\n",
       "brancofruta         0.005956\n",
       "chiron              0.005672\n",
       "bugatticor          0.005672\n",
       "para                0.005389\n",
       "carro               0.005389\n",
       "                      ...   \n",
       "botafogo            0.000284\n",
       "graças              0.000284\n",
       "5e26bo2s25          0.000284\n",
       "pqp                 0.000284\n",
       "mundial             0.000284\n",
       "xkgglqwab4          0.000284\n",
       "bilionários         0.000284\n",
       "oi                  0.000284\n",
       "briguento           0.000284\n",
       "produto             0.000284\n",
       "vem                 0.000284\n",
       "ah                  0.000284\n",
       "fa4euuuew9galera    0.000284\n",
       "palestra            0.000284\n",
       "piatrizz            0.000284\n",
       "00gwich             0.000284\n",
       "sonhos              0.000284\n",
       "ultrapassa          0.000284\n",
       "olá                 0.000284\n",
       "recordista          0.000284\n",
       "59%                 0.000284\n",
       "cacete              0.000284\n",
       "série               0.000284\n",
       "claro               0.000284\n",
       "laqueira            0.000284\n",
       "número              0.000284\n",
       "vvpa7uhlzf          0.000284\n",
       "7                   0.000284\n",
       "grande              0.000284\n",
       "blenheimpalace      0.000284\n",
       "Length: 1341, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palavras_nao_relevantes.value_counts(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2962075848303393"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_relevante = palavras_relevantes.size/universo.size\n",
    "P_relevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7037924151696606"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_nao_relevante = palavras_nao_relevantes.size/universo.size\n",
    "P_nao_relevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw2 = pd.read_excel('Bugatti_teste.xlsx')\n",
    "relevante_teste_raw2 = raw2[raw2['Relevância'] == 1]\n",
    "nao_relevante_teste_raw2 = raw2[raw2[\"Relevância\"] == 0]\n",
    "\n",
    "lista1 = []\n",
    "for tweet in relevante_teste_raw2['Teste']:\n",
    "    texto = transform_emojis(tweet)\n",
    "    lista1.append(cleanup(texto))\n",
    "    \n",
    "relevante_teste = pd.Series(lista1)\n",
    "relevante_teste = relevante_teste.str.replace('|'.join(l),'',regex=True).str.strip()\n",
    "\n",
    "lista2 = []\n",
    "for tweet in nao_relevante_teste_raw2['Teste']:\n",
    "    texto = transform_emojis(tweet)\n",
    "    lista2.append(cleanup(texto))\n",
    "    \n",
    "nao_relevante_teste = pd.Series(lista2)\n",
    "nao_relevante_teste = nao_relevante_teste.str.replace('|'.join(l),'',regex=True).str.strip()\n",
    "\n",
    "lista3 = []\n",
    "for tweet in raw2['Teste']:\n",
    "    texto = transform_emojis(tweet)\n",
    "    lista3.append(cleanup(texto))\n",
    "    \n",
    "testudo = pd.Series(lista3)\n",
    "testudo = testudo.str.replace('|'.join(l),'',regex=True).str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lista4 = []\n",
    "for tweet in testudo:\n",
    "    lista4 = lista4 + tweet.split()\n",
    "\n",
    "universo_teste = pd.Series(lista4)\n",
    "universo_teste.value_counts()\n",
    "\n",
    "lista5 = []\n",
    "for tweet in relevante_teste:\n",
    "    lista5 = lista5 + tweet.split()\n",
    "\n",
    "palavras_relevantes_teste = pd.Series(lista5)\n",
    "P_R_T_R = palavras_relevantes_teste.value_counts(True)\n",
    "\n",
    "lista6 = []\n",
    "for tweet in nao_relevante_teste:\n",
    "    lista6 = lista6 + tweet.split()\n",
    "\n",
    "palavras_nao_relevantes_teste = pd.Series(lista6)\n",
    "P_N_R_T_R = palavras_nao_relevantes_teste.value_counts(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Montando o Classificardor Naive Bayes\n",
    "\n",
    "#### Probabilidades de ser relevante ou não relevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              dirigida\n",
       "1                  pelo\n",
       "2                piloto\n",
       "3                  andy\n",
       "4               wallace\n",
       "5              vencedor\n",
       "6                    do\n",
       "7                grande\n",
       "8                prêmio\n",
       "9                    de\n",
       "10                   le\n",
       "11                 mans\n",
       "12                   em\n",
       "13                 1988\n",
       "14                  uma\n",
       "15              bugatti\n",
       "16               chiron\n",
       "17           “levemente\n",
       "18          modificada”\n",
       "19               chegou\n",
       "20                    a\n",
       "21      impressionantes\n",
       "22                  490\n",
       "23                  484\n",
       "24                 km/h\n",
       "25           0lnmllrds9\n",
       "26              bugatti\n",
       "27               chiron\n",
       "28                chega\n",
       "29                    a\n",
       "             ...       \n",
       "1346                ver\n",
       "1347             quanto\n",
       "1348              tempo\n",
       "1349                vai\n",
       "1350              levar\n",
       "1351                pra\n",
       "1352         koenigsegg\n",
       "1353                 se\n",
       "1354         pronunciar\n",
       "1355                  e\n",
       "1356              bater\n",
       "1357               esse\n",
       "1358            recorde\n",
       "1359               hehe\n",
       "1360                  a\n",
       "1361              quase\n",
       "1362                500\n",
       "1363               km/h\n",
       "1364            bugatti\n",
       "1365             chiron\n",
       "1366               vira\n",
       "1367                  o\n",
       "1368              carro\n",
       "1369                 de\n",
       "1370                rua\n",
       "1371               mais\n",
       "1372             rápido\n",
       "1373                 do\n",
       "1374              mundo\n",
       "1375         beyzg2gmlw\n",
       "Length: 1376, dtype: object"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palavras_relevantes_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       femalelionisa\n",
       "1             sqnpaty\n",
       "2                 sai\n",
       "3                 dai\n",
       "4              feiosa\n",
       "5                  eu\n",
       "6          represento\n",
       "7                kkkk\n",
       "8               avião\n",
       "9              ahahah\n",
       "10         989k28qply\n",
       "11         kethllyn31\n",
       "12            bugatti\n",
       "13                  e\n",
       "14                uma\n",
       "15              marca\n",
       "16                 de\n",
       "17              carro\n",
       "18                não\n",
       "19                  o\n",
       "20              carro\n",
       "21              geral\n",
       "22                 me\n",
       "23            olhando\n",
       "24                 no\n",
       "25         samuquinha\n",
       "26                 só\n",
       "27                 pq\n",
       "28            cheguei\n",
       "29                com\n",
       "            ...      \n",
       "2010              que\n",
       "2011                é\n",
       "2012             pior\n",
       "2013           alguém\n",
       "2014        acreditar\n",
       "2015              que\n",
       "2016                4\n",
       "2017         salários\n",
       "2018         incomoda\n",
       "2019       bilionário\n",
       "2020               ou\n",
       "2021            achar\n",
       "2022              que\n",
       "2023               dá\n",
       "2024              pra\n",
       "2025          comprar\n",
       "2026               um\n",
       "2027          bugatti\n",
       "2028              com\n",
       "2029             essa\n",
       "2030          mixaria\n",
       "2031       bt2rjrkwgx\n",
       "2032             fuga\n",
       "2033               de\n",
       "2034          bugatti\n",
       "2035              com\n",
       "2036              ela\n",
       "2037              dps\n",
       "2038              das\n",
       "2039                3\n",
       "Length: 2040, dtype: object"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palavras_nao_relevantes_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3416"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palavras_teste = palavras_relevantes_teste.size + palavras_nao_relevantes_teste.size\n",
    "palavras_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pt_relevante = relevante_teste.size / testudo.size\n",
    "Pt_relevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.62"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ptn_relevante = nao_relevante_teste.size / testudo.size\n",
    "Ptn_relevante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Como o classificador funcionará:\n",
    "\n",
    "Todos os tweets presentes na planilha de testes serão, individualmente, analisados pelo classificador e catalogados, em um loop. Depois de todo esse processo, os resultados de cada tweet analisado, que podem ser ou \"Relevante\" ou \"Irrelevante\", pelo menos neste primeiro momento, serão adicionados a uma lista com o fim de serem comparados com a análise feita à mão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bayes(relevancia,serie1,serie2):\n",
    "    #Criando o loop para o cálculo da probabilidade de ser relevante:\n",
    "    i = 0 \n",
    "    lista_resultados_numericos = []\n",
    "\n",
    "    #selecionando o tweet\n",
    "    for tweets in testudo:\n",
    "        \n",
    "        #transformando em lista de str\n",
    "        tweet = testudo[i]\n",
    "        tweetr = tweet.split()\n",
    "        \n",
    "        # Calculando a probabilidade deste tweet ser relevante dado as suas palavras\n",
    "        log_probabilidade = 0\n",
    "        for palavra in tweetr:\n",
    "        \n",
    "            #Não deixa que palavras não pertencentes à série bugem o código\n",
    "            if palavra not in serie1:\n",
    "                log_probabilidade += math.log(1/3416, 10)\n",
    "            else:\n",
    "                log_probabilidade += math.log(serie2[palavra] + 1/3416, 10)\n",
    "        \n",
    "        #Guardando os resultados e resetando a variável probabilidade    \n",
    "        lista_resultados_numericos.append(log_probabilidade + math.log(relevancia, 10))\n",
    "        log_probabilidade = 0\n",
    "        i += 1\n",
    "\n",
    "    return lista_resultados_numericos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fuga', 'de', 'bugatti', 'com', 'ela', 'dps', 'das', '3']"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-28.68835929951893,\n",
       " -11.02076998943409,\n",
       " -35.75539502355286,\n",
       " -49.889466471620715,\n",
       " -92.2916808158243,\n",
       " -46.35594860960375,\n",
       " -56.95650219565464,\n",
       " -35.75539502355286,\n",
       " -56.95650219565464,\n",
       " -46.35594860960375,\n",
       " -78.15760936775644,\n",
       " -32.22187716153589,\n",
       " -145.29444874607876,\n",
       " -46.35594860960375,\n",
       " -32.22187716153589,\n",
       " -32.22187716153589,\n",
       " -102.89223440187519,\n",
       " -28.68835929951893,\n",
       " -53.42298433363768,\n",
       " -71.09057364372251,\n",
       " -42.822430747586786,\n",
       " -78.15760936775644,\n",
       " -60.49002005767161,\n",
       " -92.2916808158243,\n",
       " -85.22464509179036,\n",
       " -28.68835929951893,\n",
       " -74.62409150573947,\n",
       " -49.889466471620715,\n",
       " -39.28891288556982,\n",
       " -117.02630584994304,\n",
       " -18.087805713468025,\n",
       " -162.96203805616358,\n",
       " -46.35594860960375,\n",
       " -42.822430747586786,\n",
       " -124.09334157397697,\n",
       " -85.22464509179036,\n",
       " -71.09057364372251,\n",
       " -14.554287851451058,\n",
       " -28.68835929951893,\n",
       " -64.02353791968858,\n",
       " -39.28891288556982,\n",
       " -106.42575226389215,\n",
       " -25.15484143750196,\n",
       " -53.42298433363768,\n",
       " -32.22187716153589,\n",
       " -85.22464509179036,\n",
       " -42.822430747586786,\n",
       " -39.28891288556982,\n",
       " -53.42298433363768,\n",
       " -42.822430747586786,\n",
       " -95.82519867784126,\n",
       " -102.89223440187519,\n",
       " -49.889466471620715,\n",
       " -56.95650219565464,\n",
       " -64.02353791968858,\n",
       " -106.42575226389215,\n",
       " -46.35594860960375,\n",
       " -102.89223440187519,\n",
       " -14.554287851451058,\n",
       " -109.95927012590911,\n",
       " -32.22187716153589,\n",
       " -170.0290737801975,\n",
       " -78.15760936775644,\n",
       " -35.75539502355286,\n",
       " -109.95927012590911,\n",
       " -88.75816295380733,\n",
       " -28.68835929951893,\n",
       " -53.42298433363768,\n",
       " -109.95927012590911,\n",
       " -35.75539502355286,\n",
       " -7.487252127417124,\n",
       " -21.621323575484993,\n",
       " -64.02353791968858,\n",
       " -25.15484143750196,\n",
       " -49.889466471620715,\n",
       " -28.68835929951893,\n",
       " -39.28891288556982,\n",
       " -95.82519867784126,\n",
       " -71.09057364372251,\n",
       " -159.4285201941466,\n",
       " -18.087805713468025,\n",
       " -39.28891288556982,\n",
       " -141.7609308840618,\n",
       " -49.889466471620715,\n",
       " -46.35594860960375,\n",
       " -78.15760936775644,\n",
       " -14.554287851451058,\n",
       " -124.09334157397697,\n",
       " -32.22187716153589,\n",
       " -42.822430747586786,\n",
       " -21.621323575484993,\n",
       " -32.22187716153589,\n",
       " -28.68835929951893,\n",
       " -81.6911272297734,\n",
       " -14.554287851451058,\n",
       " -25.15484143750196,\n",
       " -184.16314522826536,\n",
       " -39.28891288556982,\n",
       " -21.621323575484993,\n",
       " -39.28891288556982,\n",
       " -71.09057364372251,\n",
       " -92.2916808158243,\n",
       " -14.554287851451058,\n",
       " -25.15484143750196,\n",
       " -71.09057364372251,\n",
       " -42.822430747586786,\n",
       " -18.087805713468025,\n",
       " -120.55982371196001,\n",
       " -46.35594860960375,\n",
       " -95.82519867784126,\n",
       " -102.89223440187519,\n",
       " -11.02076998943409,\n",
       " -21.621323575484993,\n",
       " -60.49002005767161,\n",
       " -11.02076998943409,\n",
       " -35.75539502355286,\n",
       " -25.15484143750196,\n",
       " -18.087805713468025,\n",
       " -25.15484143750196,\n",
       " -99.35871653985822,\n",
       " -81.6911272297734,\n",
       " -81.6911272297734,\n",
       " -81.6911272297734,\n",
       " -18.087805713468025,\n",
       " -81.6911272297734,\n",
       " -28.68835929951893,\n",
       " -28.68835929951893,\n",
       " -92.2916808158243,\n",
       " -14.554287851451058,\n",
       " -28.68835929951893,\n",
       " -53.42298433363768,\n",
       " -21.621323575484993,\n",
       " -28.68835929951893,\n",
       " -131.1603772980109,\n",
       " -117.02630584994304,\n",
       " -95.82519867784126,\n",
       " -56.95650219565464,\n",
       " -42.822430747586786,\n",
       " -46.35594860960375,\n",
       " -109.95927012590911,\n",
       " -109.95927012590911,\n",
       " -42.822430747586786,\n",
       " -95.82519867784126,\n",
       " -106.42575226389215,\n",
       " -25.15484143750196,\n",
       " -159.4285201941466,\n",
       " -46.35594860960375,\n",
       " -64.02353791968858,\n",
       " -60.49002005767161,\n",
       " -28.68835929951893,\n",
       " -25.15484143750196,\n",
       " -56.95650219565464,\n",
       " -46.35594860960375,\n",
       " -35.75539502355286,\n",
       " -71.09057364372251,\n",
       " -67.55705578170554,\n",
       " -42.822430747586786,\n",
       " -14.554287851451058,\n",
       " -88.75816295380733,\n",
       " -109.95927012590911,\n",
       " -113.49278798792608,\n",
       " -42.822430747586786,\n",
       " -39.28891288556982,\n",
       " -39.28891288556982,\n",
       " -81.6911272297734,\n",
       " -92.2916808158243,\n",
       " -25.15484143750196,\n",
       " -71.09057364372251,\n",
       " -28.68835929951893,\n",
       " -127.62685943599394,\n",
       " -21.621323575484993,\n",
       " -39.28891288556982,\n",
       " -159.4285201941466,\n",
       " -39.28891288556982,\n",
       " -64.02353791968858,\n",
       " -46.35594860960375,\n",
       " -177.09610950423144,\n",
       " -191.2301809522993,\n",
       " -64.02353791968858,\n",
       " -106.42575226389215,\n",
       " -46.35594860960375,\n",
       " -28.68835929951893,\n",
       " -32.22187716153589,\n",
       " -88.75816295380733,\n",
       " -18.087805713468025,\n",
       " -18.087805713468025,\n",
       " -25.15484143750196,\n",
       " -35.75539502355286,\n",
       " -28.68835929951893,\n",
       " -56.95650219565464,\n",
       " -74.62409150573947,\n",
       " -39.28891288556982,\n",
       " -78.15760936775644,\n",
       " -28.68835929951893,\n",
       " -88.75816295380733,\n",
       " -60.49002005767161,\n",
       " -53.42298433363768,\n",
       " -88.75816295380733,\n",
       " -56.95650219565464,\n",
       " -28.68835929951893]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista_resultados_numericos_relevantes = Bayes(Pt_relevante, palavras_relevantes_teste, P_R_T_R)\n",
    "lista_resultados_numericos_relevantes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-28.475751206637486,\n",
       " -10.808161896552646,\n",
       " -35.54278693067142,\n",
       " -49.676858378739276,\n",
       " -92.07907272294284,\n",
       " -46.14334051672231,\n",
       " -56.743894102773204,\n",
       " -35.54278693067142,\n",
       " -56.743894102773204,\n",
       " -46.14334051672231,\n",
       " -77.94500127487498,\n",
       " -32.009269068654454,\n",
       " -145.0818406531973,\n",
       " -46.14334051672231,\n",
       " -32.009269068654454,\n",
       " -32.009269068654454,\n",
       " -102.67962630899373,\n",
       " -28.475751206637486,\n",
       " -53.21037624075624,\n",
       " -70.87796555084105,\n",
       " -42.60982265470535,\n",
       " -77.94500127487498,\n",
       " -60.27741196479017,\n",
       " -92.07907272294284,\n",
       " -85.01203699890891,\n",
       " -28.475751206637486,\n",
       " -74.41148341285802,\n",
       " -49.676858378739276,\n",
       " -39.07630479268838,\n",
       " -116.81369775706159,\n",
       " -17.875197620586583,\n",
       " -162.74942996328213,\n",
       " -46.14334051672231,\n",
       " -42.60982265470535,\n",
       " -123.88073348109552,\n",
       " -85.01203699890891,\n",
       " -70.87796555084105,\n",
       " -14.341679758569613,\n",
       " -28.475751206637486,\n",
       " -63.81092982680713,\n",
       " -39.07630479268838,\n",
       " -106.2131441710107,\n",
       " -24.94223334462052,\n",
       " -53.21037624075624,\n",
       " -32.009269068654454,\n",
       " -85.01203699890891,\n",
       " -42.60982265470535,\n",
       " -39.07630479268838,\n",
       " -53.21037624075624,\n",
       " -42.60982265470535,\n",
       " -95.6125905849598,\n",
       " -102.67962630899373,\n",
       " -49.676858378739276,\n",
       " -56.743894102773204,\n",
       " -63.81092982680713,\n",
       " -106.2131441710107,\n",
       " -46.14334051672231,\n",
       " -102.67962630899373,\n",
       " -14.341679758569613,\n",
       " -109.74666203302766,\n",
       " -32.009269068654454,\n",
       " -169.81646568731605,\n",
       " -77.94500127487498,\n",
       " -35.54278693067142,\n",
       " -109.74666203302766,\n",
       " -88.54555486092588,\n",
       " -28.475751206637486,\n",
       " -53.21037624075624,\n",
       " -109.74666203302766,\n",
       " -35.54278693067142,\n",
       " -7.2746440345356795,\n",
       " -21.40871548260355,\n",
       " -63.81092982680713,\n",
       " -24.94223334462052,\n",
       " -49.676858378739276,\n",
       " -28.475751206637486,\n",
       " -39.07630479268838,\n",
       " -95.6125905849598,\n",
       " -70.87796555084105,\n",
       " -159.21591210126516,\n",
       " -17.875197620586583,\n",
       " -39.07630479268838,\n",
       " -141.54832279118034,\n",
       " -49.676858378739276,\n",
       " -46.14334051672231,\n",
       " -77.94500127487498,\n",
       " -14.341679758569613,\n",
       " -123.88073348109552,\n",
       " -32.009269068654454,\n",
       " -42.60982265470535,\n",
       " -21.40871548260355,\n",
       " -32.009269068654454,\n",
       " -28.475751206637486,\n",
       " -81.47851913689195,\n",
       " -14.341679758569613,\n",
       " -24.94223334462052,\n",
       " -183.9505371353839,\n",
       " -39.07630479268838,\n",
       " -21.40871548260355,\n",
       " -39.07630479268838,\n",
       " -70.87796555084105,\n",
       " -92.07907272294284,\n",
       " -14.341679758569613,\n",
       " -24.94223334462052,\n",
       " -70.87796555084105,\n",
       " -42.60982265470535,\n",
       " -17.875197620586583,\n",
       " -120.34721561907855,\n",
       " -46.14334051672231,\n",
       " -95.6125905849598,\n",
       " -102.67962630899373,\n",
       " -10.808161896552646,\n",
       " -21.40871548260355,\n",
       " -60.27741196479017,\n",
       " -10.808161896552646,\n",
       " -35.54278693067142,\n",
       " -24.94223334462052,\n",
       " -17.875197620586583,\n",
       " -24.94223334462052,\n",
       " -99.14610844697677,\n",
       " -81.47851913689195,\n",
       " -81.47851913689195,\n",
       " -81.47851913689195,\n",
       " -17.875197620586583,\n",
       " -81.47851913689195,\n",
       " -28.475751206637486,\n",
       " -28.475751206637486,\n",
       " -92.07907272294284,\n",
       " -14.341679758569613,\n",
       " -28.475751206637486,\n",
       " -53.21037624075624,\n",
       " -21.40871548260355,\n",
       " -28.475751206637486,\n",
       " -130.94776920512945,\n",
       " -116.81369775706159,\n",
       " -95.6125905849598,\n",
       " -56.743894102773204,\n",
       " -42.60982265470535,\n",
       " -46.14334051672231,\n",
       " -109.74666203302766,\n",
       " -109.74666203302766,\n",
       " -42.60982265470535,\n",
       " -95.6125905849598,\n",
       " -106.2131441710107,\n",
       " -24.94223334462052,\n",
       " -159.21591210126516,\n",
       " -46.14334051672231,\n",
       " -63.81092982680713,\n",
       " -60.27741196479017,\n",
       " -28.475751206637486,\n",
       " -24.94223334462052,\n",
       " -56.743894102773204,\n",
       " -46.14334051672231,\n",
       " -35.54278693067142,\n",
       " -70.87796555084105,\n",
       " -67.34444768882409,\n",
       " -42.60982265470535,\n",
       " -14.341679758569613,\n",
       " -88.54555486092588,\n",
       " -109.74666203302766,\n",
       " -113.28017989504463,\n",
       " -42.60982265470535,\n",
       " -39.07630479268838,\n",
       " -39.07630479268838,\n",
       " -81.47851913689195,\n",
       " -92.07907272294284,\n",
       " -24.94223334462052,\n",
       " -70.87796555084105,\n",
       " -28.475751206637486,\n",
       " -127.41425134311248,\n",
       " -21.40871548260355,\n",
       " -39.07630479268838,\n",
       " -159.21591210126516,\n",
       " -39.07630479268838,\n",
       " -63.81092982680713,\n",
       " -46.14334051672231,\n",
       " -176.88350141134998,\n",
       " -191.01757285941784,\n",
       " -63.81092982680713,\n",
       " -106.2131441710107,\n",
       " -46.14334051672231,\n",
       " -28.475751206637486,\n",
       " -32.009269068654454,\n",
       " -88.54555486092588,\n",
       " -17.875197620586583,\n",
       " -17.875197620586583,\n",
       " -24.94223334462052,\n",
       " -35.54278693067142,\n",
       " -28.475751206637486,\n",
       " -56.743894102773204,\n",
       " -74.41148341285802,\n",
       " -39.07630479268838,\n",
       " -77.94500127487498,\n",
       " -28.475751206637486,\n",
       " -88.54555486092588,\n",
       " -60.27741196479017,\n",
       " -53.21037624075624,\n",
       " -88.54555486092588,\n",
       " -56.743894102773204,\n",
       " -28.475751206637486]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista_resultados_numericos_nrelevantes = Bayes(Ptn_relevante, palavras_nao_relevantes_teste, P_N_R_T_R)\n",
    "lista_resultados_numericos_nrelevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "lista_resultados = []\n",
    "for tweet in testudo:\n",
    "    \n",
    "    if lista_resultados_numericos_relevantes[i] > lista_resultados_numericos_nrelevantes[i]:\n",
    "           lista_resultados.append(\"Relevante\")\n",
    "            \n",
    "    if lista_resultados_numericos_relevantes[i] == lista_resultados_numericos_nrelevantes[i]:\n",
    "        lista_resultados.append(\"Neutro\")\n",
    "        \n",
    "    if lista_resultados_numericos_relevantes[i] < lista_resultados_numericos_nrelevantes[i]:\n",
    "        lista_resultados.append(\"Não relevante\")\n",
    "        \n",
    "    i += 1\n",
    "    \n",
    "#lista_resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346,\n",
       " 1.0074662856596346]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "i=0\n",
    "cu=[]\n",
    "\n",
    "for tweet in testudo:\n",
    "    cu.append(lista_resultados_numericos_relevantes[i] / lista_resultados_numericos_nrelevantes[i])\n",
    "cu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aperfeiçoamento:\n",
    "\n",
    "Os trabalhos vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separação de espaços entre palavras e emojis ou emojis e emojis\n",
    "* Propor outras limpezas e transformações que não afetem a qualidade da informação ou classificação\n",
    "* Criar categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que não posso usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cenários para Naïve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que periodicamente realiza análise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
